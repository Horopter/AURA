2025-12-12 17:28:45 [INFO] [__main__:310] ================================================================================
2025-12-12 17:28:45 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-12 17:28:45 [INFO] [__main__:312] ================================================================================
2025-12-12 17:28:45 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-12 17:28:45 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 17:28:45 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 17:28:45 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 17:28:45 [INFO] [__main__:317] Model types: ['x3d']
2025-12-12 17:28:45 [INFO] [__main__:318] K-fold splits: 5
2025-12-12 17:28:45 [INFO] [__main__:319] Number of frames: 500
2025-12-12 17:28:45 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 17:28:45 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-12 17:28:45 [INFO] [__main__:324] Delete existing: True
2025-12-12 17:28:45 [INFO] [__main__:325] Resume mode: True
2025-12-12 17:28:45 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765578525.log
2025-12-12 17:28:45 [INFO] [__main__:333] ================================================================================
2025-12-12 17:28:45 [INFO] [__main__:334] Checking prerequisites...
2025-12-12 17:28:45 [INFO] [__main__:335] ================================================================================
2025-12-12 17:28:45 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 17:28:45 [INFO] [__main__:352] ✓ All model types are valid
2025-12-12 17:28:45 [INFO] [__main__:358] ================================================================================
2025-12-12 17:28:45 [INFO] [__main__:359] Initial memory statistics:
2025-12-12 17:28:45 [INFO] [__main__:360] ================================================================================
2025-12-12 17:28:45 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.828125, 'cpu_memory_gb': 0.7185821533203125, 'cpu_vms_mb': 10217.56640625, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-12 17:28:45 [INFO] [__main__:364] ================================================================================
2025-12-12 17:28:45 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-12 17:28:45 [INFO] [__main__:366] ================================================================================
2025-12-12 17:28:45 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-12 17:28:45 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-12 17:28:45 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-12 17:28:45 [INFO] [__main__:370] ================================================================================
2025-12-12 17:28:45 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-12 17:28:45 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:490] ================================================================================
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:491] Stage 5: Model Training Pipeline Started
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:492] ================================================================================
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:493] Model types: ['x3d']
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:494] K-fold splits: 5
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:495] Frames per video: 500
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:496] Output directory: data/stage5
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:497] Initializing pipeline...
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:265] ================================================================================
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:266] STAGE 5 PREREQUISITE VALIDATION
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:267] ================================================================================
2025-12-12 17:28:45 [INFO] [lib.training.pipeline:270] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-12 17:28:47 [INFO] [lib.training.pipeline:279] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-12 17:28:47 [INFO] [lib.training.pipeline:280]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 17:28:47 [INFO] [lib.training.pipeline:283] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:291] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:292]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:295] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:303] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:304]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:307] 
================================================================================
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:308] MODEL REQUIREMENTS CHECK
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:309] ================================================================================
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:333] ✓ x3d: CAN RUN
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:336] 
================================================================================
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:337] VALIDATION SUMMARY
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:338] ================================================================================
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:339] Stage 3 (scaled videos): ✓ Available
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:340]   Count: 3278 videos
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:341] Stage 2 (features): ✓ Available
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:342]   Count: 3278 feature rows
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:343] Stage 4 (scaled features): ✓ Available
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:344]   Count: 3277 feature rows
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:345] 
Runnable models: 1/1
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:346]   ['x3d']
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:353] ================================================================================
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:583] 
Stage 5: Loading metadata...
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:609] Loaded metadata: 3278 rows
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:619] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-12 17:28:48 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=834978.92GB, used=1664861.08GB (66.6%)
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:651] Stage 5: Found 3278 scaled videos
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:675] Enabling adaptive chunked frame loading for x3d: initial_chunk_size=200, num_frames=500. Chunk size will adapt automatically based on OOM events (AIMD algorithm).
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:730] Stage 5: Deleting existing model results (clean mode)...
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:739] Deleted existing results for x3d
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:742] Stage 5: Deleted 1 existing model directories
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:747] 
================================================================================
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:748] Stage 5: Training model: x3d
2025-12-12 17:28:48 [INFO] [lib.training.pipeline:749] ================================================================================
2025-12-12 17:28:50 [INFO] [lib.training.pipeline:773] Grid search: 32 hyperparameter combinations to try
2025-12-12 17:28:50 [INFO] [lib.training.pipeline:781] ================================================================================
2025-12-12 17:28:50 [INFO] [lib.training.pipeline:782] HYPERPARAMETER SEARCH: Using 20% stratified sample for efficiency
2025-12-12 17:28:50 [INFO] [lib.training.pipeline:783] ================================================================================
2025-12-12 17:28:51 [INFO] [lib.training.pipeline:792] Hyperparameter search sample: 655 rows (20.0% of 3278 total)
2025-12-12 17:28:53 [INFO] [lib.training.pipeline:805] Using 5-fold stratified cross-validation on 20% sample for hyperparameter search
2025-12-12 17:28:53 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:28:53 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 1/32
2025-12-12 17:28:53 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 17:28:53 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:28:53 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:28:53 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:28:53 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:29:06 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7367867be9704d52b60428f1c07b5ddd (experiment: x3d)
2025-12-12 17:29:06 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:29:17 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:29:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:29:21 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:29:26 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process has 13.96 GiB memory in use. Of the allocated memory 13.55 GiB is allocated by PyTorch, and 49.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:29:26 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process has 13.96 GiB memory in use. Of the allocated memory 13.55 GiB is allocated by PyTorch, and 49.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.80 GiB is free. Including non-PyTorch memory, this process has 13.96 GiB memory in use. Of the allocated memory 13.55 GiB is allocated by PyTorch, and 49.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:29:27 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:29:27 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:29:27 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:29:27 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:29:27 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:29:29 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:29:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:29:34 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:29:37 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.32 GiB is free. Including non-PyTorch memory, this process has 4.44 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 23.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:29:37 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.32 GiB is free. Including non-PyTorch memory, this process has 4.44 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 23.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.32 GiB is free. Including non-PyTorch memory, this process has 4.44 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 23.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:29:38 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:29:38 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:29:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:29:38 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:29:38 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:29:40 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:29:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:29:54 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:29:56 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.29 GiB is free. Including non-PyTorch memory, this process has 4.47 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 63.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:29:56 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.29 GiB is free. Including non-PyTorch memory, this process has 4.47 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 63.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.29 GiB is free. Including non-PyTorch memory, this process has 4.47 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 63.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:29:56 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:29:56 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:29:56 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:29:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:29:57 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:29:59 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:29:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:30:02 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:30:04 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 83.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:30:04 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 83.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 83.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:30:04 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:30:04 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:30:04 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:30:05 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:30:05 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:30:07 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:30:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:30:11 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:30:13 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 13.64 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 105.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:30:13 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 13.64 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 105.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 13.64 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 105.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:30:14 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:30:14 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 2/32
2025-12-12 17:30:14 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 17:30:14 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:30:14 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:30:14 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:30:14 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:30:14 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:30:14 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:30:14 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:30:16 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:30:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:30:25 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:30:33 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.35 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 14.46 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 74.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:30:33 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 6.35 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 14.46 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 74.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.35 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 14.46 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 74.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:30:33 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:30:33 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:30:33 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:30:33 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:30:33 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:30:33 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:30:34 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:30:35 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:30:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:30:41 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:30:46 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:30:46 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:30:47 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:30:47 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:30:47 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:30:47 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:30:47 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:30:47 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:30:49 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:30:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:30:51 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:30:59 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:31:01 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.53 GiB is free. Including non-PyTorch memory, this process has 14.22 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 107.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:31:01 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.53 GiB is free. Including non-PyTorch memory, this process has 14.22 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 107.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.53 GiB is free. Including non-PyTorch memory, this process has 14.22 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 107.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:31:02 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:31:02 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:31:02 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:31:02 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:31:02 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:31:02 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:31:04 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:31:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:31:08 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:31:18 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 14.20 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 87.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:31:18 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 14.20 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 87.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 14.20 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 87.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:31:18 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:31:18 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:31:18 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:31:18 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:31:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:31:18 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:31:20 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:31:20 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:31:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:31:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:31:31 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.33 GiB is free. Including non-PyTorch memory, this process has 13.42 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 108.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:31:31 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.33 GiB is free. Including non-PyTorch memory, this process has 13.42 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 108.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.33 GiB is free. Including non-PyTorch memory, this process has 13.42 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 108.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:31:31 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:31:31 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 3/32
2025-12-12 17:31:31 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 17:31:31 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:31:31 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:31:31 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:31:31 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:31:31 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:31:32 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:31:32 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:31:34 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:31:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:31:36 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:31:40 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:31:40 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:31:40 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:31:40 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:31:40 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:31:40 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:31:41 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:31:41 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:31:42 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:31:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:31:44 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:31:48 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:31:48 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:31:48 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:31:48 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:31:48 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:31:48 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:31:49 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:31:49 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:31:51 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:31:51 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:31:53 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:31:57 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:31:57 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:31:57 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:31:57 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:31:57 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:31:57 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:31:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:31:58 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:32:00 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:32:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:32:03 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:32:08 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:32:08 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:32:09 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:32:09 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:32:09 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:32:09 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:32:09 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:32:09 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:32:11 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:32:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:32:13 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:32:17 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:32:17 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:32:18 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:32:18 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 4/32
2025-12-12 17:32:18 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 17:32:18 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:32:18 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:32:18 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:32:18 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:32:18 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:32:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:32:18 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:32:20 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:32:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:32:22 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:32:27 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:32:30 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:32:30 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:32:30 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:32:30 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:32:30 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:32:30 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:32:31 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:32:31 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:32:32 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:32:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:32:36 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:32:43 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.15 GiB is allocated by PyTorch, and 137.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:32:43 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 6.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.15 GiB is allocated by PyTorch, and 137.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.15 GiB is allocated by PyTorch, and 137.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:32:43 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:32:43 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:32:43 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:32:43 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:32:43 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:32:43 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:32:45 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:32:45 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:32:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:32:56 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:33:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:33:00 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:33:00 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:33:00 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:33:00 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:33:00 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:33:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:33:01 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:33:03 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:33:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:33:05 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:33:10 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:33:13 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:33:13 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:33:13 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:33:13 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:33:13 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:33:13 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:33:14 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:33:14 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:33:15 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:33:16 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:33:20 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:33:32 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:33:32 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:33:33 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:33:33 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 5/32
2025-12-12 17:33:33 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 17:33:33 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:33:33 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:33:33 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:33:33 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:33:33 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:33:33 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:33:33 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:33:34 [INFO] [lib.models.video:417] Chunk size increased from 220 to 230 (after 3 successes, increment: 10)
2025-12-12 17:33:35 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:33:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:33:41 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:33:41 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:33:41 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:33:41 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:33:41 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:33:41 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:33:42 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:33:42 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:33:43 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:33:43 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:33:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:33:49 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:33:49 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:33:50 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:33:50 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:33:50 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:33:50 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:33:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:33:50 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:33:51 [INFO] [lib.models.video:417] Chunk size increased from 230 to 240 (after 3 successes, increment: 10)
2025-12-12 17:33:52 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:33:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:34:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:34:00 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:34:00 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:34:00 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:34:00 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:34:00 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:34:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:34:01 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:34:02 [INFO] [lib.models.video:417] Chunk size increased from 240 to 250 (after 3 successes, increment: 10)
2025-12-12 17:34:03 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:34:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:34:11 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:34:11 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:34:11 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:34:11 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:34:11 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:34:11 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:34:12 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:34:12 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:34:13 [INFO] [lib.models.video:417] Chunk size increased from 250 to 260 (after 3 successes, increment: 10)
2025-12-12 17:34:14 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:34:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:34:20 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:34:20 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:34:20 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:34:20 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 6/32
2025-12-12 17:34:20 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 17:34:20 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:34:20 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:34:20 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:34:20 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:34:20 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:34:21 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:34:21 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:34:22 [INFO] [lib.models.video:417] Chunk size increased from 260 to 270 (after 3 successes, increment: 10)
2025-12-12 17:34:23 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:34:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:34:31 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:34:38 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:34:38 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:34:38 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:34:38 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:34:38 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:34:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:34:38 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:34:38 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:34:40 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:34:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:34:48 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:34:54 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:34:57 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:34:57 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:34:57 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:34:57 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:34:57 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:34:57 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:34:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:34:57 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:34:59 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:35:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:35:03 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:35:09 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:35:09 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:35:10 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:35:10 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:35:10 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:35:10 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:35:10 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:35:10 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:35:11 [INFO] [lib.models.video:417] Chunk size increased from 270 to 280 (after 3 successes, increment: 10)
2025-12-12 17:35:12 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:35:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:35:23 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:35:28 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:35:28 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:35:28 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:35:28 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:35:28 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:35:28 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:35:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:35:28 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:35:30 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:35:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:35:37 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:35:43 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:35:46 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:35:46 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:35:46 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:35:46 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 7/32
2025-12-12 17:35:46 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 17:35:46 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:35:46 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:35:46 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:35:46 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:35:46 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:35:47 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:35:47 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:35:48 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:35:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:35:55 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:35:57 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:35:57 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:35:57 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:35:57 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:35:57 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:35:57 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:35:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:35:58 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:35:59 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:36:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:36:03 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:36:06 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:36:06 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:36:06 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:36:06 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:36:06 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:36:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:36:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:36:06 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:36:08 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:36:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:36:17 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:36:19 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:36:19 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:36:19 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:36:19 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:36:19 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:36:19 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:36:20 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:36:20 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:36:22 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:36:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:36:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:36:28 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:36:28 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:36:28 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:36:28 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:36:28 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:36:28 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:36:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:36:28 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:36:30 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:36:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:36:35 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:36:38 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:36:38 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:36:38 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:36:38 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 8/32
2025-12-12 17:36:38 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 17:36:38 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:36:38 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:36:38 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:36:38 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:36:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:36:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:36:39 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:36:40 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:36:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:36:50 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:36:56 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:36:56 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:36:56 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:36:56 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:36:56 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:36:56 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:36:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:36:57 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:36:57 [INFO] [lib.models.video:417] Chunk size increased from 220 to 230 (after 3 successes, increment: 10)
2025-12-12 17:36:58 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:36:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:37:03 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:37:08 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:37:08 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:37:08 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:37:08 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:37:08 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:37:08 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:37:09 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:37:09 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:37:11 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:37:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:37:15 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:37:21 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:37:23 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:37:23 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:37:24 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:37:24 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:37:24 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:37:24 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:37:24 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:37:24 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:37:26 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:37:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:37:31 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:37:38 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 190.19 MiB is free. Including non-PyTorch memory, this process has 15.57 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 120.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:37:38 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 190.19 MiB is free. Including non-PyTorch memory, this process has 15.57 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 120.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 190.19 MiB is free. Including non-PyTorch memory, this process has 15.57 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 120.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:37:38 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:37:38 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:37:38 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:37:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:37:38 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:37:38 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:37:40 [INFO] [lib.models.video:417] Chunk size increased from 280 to 290 (after 3 successes, increment: 10)
2025-12-12 17:37:40 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:37:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:37:46 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:37:51 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 190.19 MiB is free. Including non-PyTorch memory, this process has 15.57 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 120.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:37:51 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 190.19 MiB is free. Including non-PyTorch memory, this process has 15.57 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 120.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 190.19 MiB is free. Including non-PyTorch memory, this process has 15.57 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 120.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:37:51 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:37:51 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 9/32
2025-12-12 17:37:51 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 17:37:51 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:37:51 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:37:51 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:37:51 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:37:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:37:52 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:37:52 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:37:54 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:37:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:37:56 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:38:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:38:00 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:38:01 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:38:01 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:38:01 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:38:01 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:38:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:38:01 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:38:02 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:38:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:38:04 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:38:08 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:38:08 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:38:08 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:38:08 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:38:08 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:38:08 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:38:09 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:38:09 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:38:11 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:38:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:38:13 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:38:17 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:38:17 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:38:17 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:38:17 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:38:17 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:38:17 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:38:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:38:18 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:38:20 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:38:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:38:23 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:38:28 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:38:28 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:38:28 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:38:28 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:38:28 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:38:28 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:38:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:38:28 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:38:30 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:38:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:38:32 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:38:36 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:38:36 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:38:37 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:38:37 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 10/32
2025-12-12 17:38:37 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 17:38:37 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:38:37 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:38:37 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:38:37 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:38:37 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:38:37 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:38:37 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:38:39 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:38:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:38:41 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:38:53 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:38:56 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:38:56 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:38:56 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:38:56 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:38:56 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:38:56 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:38:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:38:57 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:38:58 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:38:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:39:06 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:39:12 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:39:12 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:39:12 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:39:12 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:39:12 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:39:12 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:39:13 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:39:13 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:39:14 [INFO] [lib.models.video:417] Chunk size increased from 290 to 300 (after 3 successes, increment: 10)
2025-12-12 17:39:15 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:39:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:39:21 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:39:25 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:39:25 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:39:25 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:39:25 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:39:25 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:39:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:39:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:39:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:39:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:39:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:39:30 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:39:42 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:39:44 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:39:44 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:39:44 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:39:44 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:39:44 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:39:44 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:39:44 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:39:44 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:39:46 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:39:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:39:51 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:39:58 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:39:58 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:39:58 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:39:58 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 11/32
2025-12-12 17:39:58 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 17:39:58 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:39:58 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:39:58 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:39:58 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:39:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:39:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:39:58 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:40:00 [INFO] [lib.models.video:417] Chunk size increased from 300 to 310 (after 3 successes, increment: 10)
2025-12-12 17:40:00 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:40:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:40:12 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:40:12 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:40:12 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:40:12 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:40:12 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:40:12 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:40:13 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:40:13 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:40:13 [INFO] [lib.models.video:417] Chunk size increased from 230 to 240 (after 3 successes, increment: 10)
2025-12-12 17:40:14 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:40:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:40:21 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:40:21 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:40:21 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:40:21 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:40:21 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:40:21 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:40:21 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:40:21 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:40:23 [INFO] [lib.models.video:417] Chunk size increased from 310 to 320 (after 3 successes, increment: 10)
2025-12-12 17:40:23 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:40:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:40:35 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:40:35 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:40:35 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:40:35 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:40:35 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:40:35 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:40:35 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:40:35 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:40:37 [INFO] [lib.models.video:417] Chunk size increased from 320 to 330 (after 3 successes, increment: 10)
2025-12-12 17:40:37 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:40:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:40:43 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:40:43 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:40:43 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:40:43 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:40:43 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:40:43 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:40:44 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:40:44 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:40:45 [INFO] [lib.models.video:417] Chunk size increased from 330 to 340 (after 3 successes, increment: 10)
2025-12-12 17:40:46 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:40:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:40:55 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:40:55 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:40:55 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:40:55 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 12/32
2025-12-12 17:40:55 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 17:40:55 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:40:55 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:40:55 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:40:55 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:40:55 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:40:55 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:40:55 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:40:57 [INFO] [lib.models.video:417] Chunk size increased from 340 to 350 (after 3 successes, increment: 10)
2025-12-12 17:40:57 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:40:58 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:41:06 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:41:11 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:41:11 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:41:11 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:41:11 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:41:11 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:41:11 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:41:12 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:41:12 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:41:13 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:41:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:41:15 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:41:21 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:41:24 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:41:24 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:41:24 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:41:24 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:41:24 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:41:24 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:41:24 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:41:24 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:41:26 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:41:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:41:30 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:41:36 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:41:36 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:41:37 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:41:37 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:41:37 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:41:37 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:41:37 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:41:37 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:41:38 [INFO] [lib.models.video:417] Chunk size increased from 350 to 360 (after 3 successes, increment: 10)
2025-12-12 17:41:39 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:41:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:41:45 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:41:50 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:41:50 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:41:51 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:41:51 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:41:51 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:41:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:41:51 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:41:51 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:41:53 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:41:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:41:55 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:42:06 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:42:08 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:42:08 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:42:08 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:42:08 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 13/32
2025-12-12 17:42:08 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 17:42:08 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:42:08 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:42:08 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:42:08 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:42:08 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:42:09 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:42:09 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:42:11 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:42:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:42:14 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:42:16 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:42:16 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:42:17 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:42:17 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:42:17 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:42:17 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:42:17 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:42:17 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:42:18 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:42:19 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:42:22 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:42:24 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:42:24 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:42:25 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:42:25 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:42:25 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:42:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:42:25 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:42:25 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:42:27 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:42:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:42:31 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:42:33 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.08 GiB is free. Including non-PyTorch memory, this process has 13.68 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 145.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:42:33 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.08 GiB is free. Including non-PyTorch memory, this process has 13.68 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 145.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.08 GiB is free. Including non-PyTorch memory, this process has 13.68 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 145.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:42:33 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:42:33 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:42:33 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:42:33 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:42:33 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:42:33 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:42:35 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:42:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:42:39 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:42:41 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:42:41 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:42:41 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:42:41 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:42:41 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:42:41 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:42:42 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:42:42 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:42:44 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:42:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:42:49 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:42:51 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:42:51 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:42:52 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:42:52 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 14/32
2025-12-12 17:42:52 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 17:42:52 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:42:52 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:42:52 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:42:52 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:42:52 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:42:52 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:42:52 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:42:54 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:42:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:42:57 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:43:04 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:43:04 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:43:04 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:43:04 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:43:04 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:43:04 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:43:04 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:43:04 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:43:05 [INFO] [lib.models.video:417] Chunk size increased from 240 to 250 (after 3 successes, increment: 10)
2025-12-12 17:43:06 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:43:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:43:12 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:43:18 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:43:18 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:43:18 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:43:18 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:43:18 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:43:18 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:43:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:43:18 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:43:20 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:43:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:43:23 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:43:34 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:43:37 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:43:37 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:43:37 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:43:37 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:43:37 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:43:37 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:43:37 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:43:37 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:43:39 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:43:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:43:42 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:43:49 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:43:49 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:43:49 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:43:49 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:43:49 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:43:49 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:43:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:43:50 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:43:51 [INFO] [lib.models.video:417] Chunk size increased from 360 to 370 (after 3 successes, increment: 10)
2025-12-12 17:43:51 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:43:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:43:58 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:44:05 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:44:05 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:44:05 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:44:05 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 15/32
2025-12-12 17:44:05 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 17:44:05 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:44:05 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:44:05 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:44:05 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:44:05 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:44:05 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:44:05 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:44:07 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:44:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:44:09 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:44:14 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:44:14 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:44:14 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:44:14 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:44:14 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:44:14 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:44:15 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:44:15 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:44:16 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:44:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:44:18 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:44:22 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:44:22 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:44:22 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:44:22 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:44:22 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:44:22 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:44:22 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:44:22 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:44:24 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:44:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:44:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:44:30 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:44:30 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:44:31 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:44:31 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:44:31 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:44:31 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:44:31 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:44:31 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:44:33 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:44:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:44:40 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:44:44 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:44:44 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:44:44 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:44:44 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:44:44 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:44:44 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:44:45 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:44:45 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:44:47 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:44:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:44:48 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:44:55 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:44:55 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:44:55 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:44:55 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 16/32
2025-12-12 17:44:55 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 17:44:55 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:44:55 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:44:55 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:44:55 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:44:55 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:44:55 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:44:55 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:44:57 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:44:58 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:44:59 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:45:05 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:45:08 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:45:08 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:45:08 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:45:08 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:45:08 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:45:08 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:45:08 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:45:08 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:45:10 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:45:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:45:14 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:45:22 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.14 GiB is free. Including non-PyTorch memory, this process has 13.62 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 171.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:45:22 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.14 GiB is free. Including non-PyTorch memory, this process has 13.62 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 171.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.14 GiB is free. Including non-PyTorch memory, this process has 13.62 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 171.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:45:22 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:45:22 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:45:22 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:45:22 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:45:23 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:45:23 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:45:24 [INFO] [lib.models.video:417] Chunk size increased from 370 to 380 (after 3 successes, increment: 10)
2025-12-12 17:45:24 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:45:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:45:36 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:45:41 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:45:41 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:45:41 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:45:41 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:45:41 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:45:41 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:45:41 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:45:41 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:45:43 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:45:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:45:46 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:45:57 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:46:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:46:00 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:46:01 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:46:01 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:46:01 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:46:01 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:46:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:46:01 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:46:03 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:46:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:46:07 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:46:14 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:46:14 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:46:14 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:46:14 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 17/32
2025-12-12 17:46:14 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 17:46:14 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:46:14 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:46:14 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:46:14 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:46:14 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:46:15 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:46:15 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:46:16 [INFO] [lib.models.video:417] Chunk size increased from 380 to 390 (after 3 successes, increment: 10)
2025-12-12 17:46:17 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:46:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:46:24 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.78 GiB is free. Including non-PyTorch memory, this process has 12.97 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 210.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:46:24 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.78 GiB is free. Including non-PyTorch memory, this process has 12.97 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 210.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.78 GiB is free. Including non-PyTorch memory, this process has 12.97 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 210.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:46:24 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:46:24 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:46:24 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:46:24 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:46:24 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:46:24 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:46:25 [INFO] [lib.models.video:417] Chunk size increased from 250 to 260 (after 3 successes, increment: 10)
2025-12-12 17:46:26 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:46:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:46:34 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:46:34 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:46:34 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:46:34 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:46:34 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:46:34 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:46:34 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:46:34 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:46:36 [INFO] [lib.models.video:417] Chunk size increased from 390 to 400 (after 3 successes, increment: 10)
2025-12-12 17:46:36 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:46:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:46:45 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:46:45 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:46:45 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:46:45 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:46:45 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:46:45 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:46:46 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:46:46 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:46:47 [INFO] [lib.models.video:417] Chunk size increased from 400 to 410 (after 3 successes, increment: 10)
2025-12-12 17:46:48 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:46:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:47:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 850.19 MiB is free. Including non-PyTorch memory, this process has 14.93 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 117.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:47:00 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 850.19 MiB is free. Including non-PyTorch memory, this process has 14.93 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 117.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 850.19 MiB is free. Including non-PyTorch memory, this process has 14.93 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 117.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:47:00 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:47:00 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:47:00 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:47:00 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:47:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:47:01 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:47:02 [INFO] [lib.models.video:417] Chunk size increased from 410 to 420 (after 3 successes, increment: 10)
2025-12-12 17:47:03 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:47:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:47:10 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:47:10 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:47:10 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:47:10 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 18/32
2025-12-12 17:47:10 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 17:47:10 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:47:10 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:47:10 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:47:10 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:47:10 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:47:10 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:47:10 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:47:12 [INFO] [lib.models.video:417] Chunk size increased from 420 to 430 (after 3 successes, increment: 10)
2025-12-12 17:47:12 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:47:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:47:20 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:47:24 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.72 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 118.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:47:24 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.72 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 118.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.72 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 118.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:47:25 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:47:25 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:47:25 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:47:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:47:25 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:47:25 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:47:26 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:47:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:47:28 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:47:41 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:47:44 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:47:44 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:47:44 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:47:44 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:47:44 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:47:44 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:47:45 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:47:45 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:47:46 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:47:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:47:54 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:48:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:48:00 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:48:01 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:48:01 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:48:01 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:48:01 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:48:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:48:01 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:48:02 [INFO] [lib.models.video:417] Chunk size increased from 430 to 440 (after 3 successes, increment: 10)
2025-12-12 17:48:03 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:48:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:48:10 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:48:14 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 14.26 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 147.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:48:14 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 14.26 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 147.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 14.26 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 147.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:48:15 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:48:15 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:48:15 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:48:15 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:48:15 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:48:15 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:48:17 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:48:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:48:20 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:48:26 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:48:28 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:48:28 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:48:29 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:48:29 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 19/32
2025-12-12 17:48:29 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 17:48:29 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:48:29 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:48:29 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:48:29 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:48:29 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:48:29 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:48:29 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:48:31 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:48:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:48:34 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:48:37 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:48:37 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:48:37 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:48:37 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:48:37 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:48:37 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:48:37 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:48:37 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:48:39 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:48:39 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:48:44 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:48:46 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:48:46 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:48:47 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:48:47 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:48:47 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:48:47 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:48:47 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:48:47 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:48:49 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:48:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:48:53 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:48:56 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.01 GiB is free. Including non-PyTorch memory, this process has 5.75 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 196.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:48:56 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.01 GiB is free. Including non-PyTorch memory, this process has 5.75 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 196.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.01 GiB is free. Including non-PyTorch memory, this process has 5.75 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 196.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:48:56 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:48:56 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:48:56 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:48:56 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:48:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:48:57 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:48:59 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:48:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:49:04 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:49:06 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:49:06 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:49:06 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:49:06 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:49:06 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:49:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:49:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:49:07 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:49:08 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:49:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:49:12 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:49:15 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:49:15 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:49:15 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:49:15 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 20/32
2025-12-12 17:49:15 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 17:49:15 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:49:15 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:49:15 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:49:15 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:49:15 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:49:15 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:49:15 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:49:17 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:49:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:49:21 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:49:29 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:49:29 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:49:29 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:49:29 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:49:29 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:49:29 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:49:30 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:49:30 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:49:31 [INFO] [lib.models.video:417] Chunk size increased from 260 to 270 (after 3 successes, increment: 10)
2025-12-12 17:49:31 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:49:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:49:36 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:49:40 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:49:40 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:49:41 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:49:41 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:49:41 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:49:41 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:49:41 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:49:41 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:49:43 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:49:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:49:45 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:49:55 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:49:58 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:49:58 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:49:58 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:49:58 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:49:58 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:49:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:49:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:49:59 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:50:01 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:50:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:50:05 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:50:13 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:50:13 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:50:13 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:50:13 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:50:13 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:50:13 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:50:14 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:50:14 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:50:15 [INFO] [lib.models.video:417] Chunk size increased from 440 to 450 (after 3 successes, increment: 10)
2025-12-12 17:50:16 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:50:16 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:50:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:50:33 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:50:33 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:50:33 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:50:33 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 21/32
2025-12-12 17:50:33 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 17:50:33 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:50:33 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:50:33 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:50:33 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:50:33 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:50:34 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:50:34 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:50:35 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:50:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:50:38 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:50:42 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:50:42 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:50:42 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:50:42 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:50:42 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:50:42 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:50:42 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:50:42 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:50:44 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:50:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:50:46 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:50:49 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:50:49 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:50:49 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:50:49 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:50:49 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:50:49 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:50:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:50:50 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:50:52 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:50:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:50:53 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:50:57 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:50:57 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:50:57 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:50:57 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:50:57 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:50:57 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:50:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:50:58 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:51:00 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:51:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:51:01 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:51:06 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:51:06 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:51:06 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:51:06 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:51:06 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:51:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:51:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:51:06 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:51:08 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:51:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:51:10 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:51:21 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 16.89 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.65 GiB is free. Including non-PyTorch memory, this process has 5.10 GiB memory in use. Of the allocated memory 4.59 GiB is allocated by PyTorch, and 148.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:51:21 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 16.89 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.65 GiB is free. Including non-PyTorch memory, this process has 5.10 GiB memory in use. Of the allocated memory 4.59 GiB is allocated by PyTorch, and 148.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.89 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.65 GiB is free. Including non-PyTorch memory, this process has 5.10 GiB memory in use. Of the allocated memory 4.59 GiB is allocated by PyTorch, and 148.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:51:21 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:51:21 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 22/32
2025-12-12 17:51:21 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 17:51:21 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:51:21 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:51:21 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:51:21 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:51:21 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:51:21 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:51:21 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:51:23 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:51:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:51:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:51:35 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:51:38 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:51:38 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:51:38 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:51:38 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:51:38 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:51:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:51:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:51:39 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:51:40 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:51:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:51:44 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:51:50 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:51:50 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:51:50 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:51:50 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:51:50 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:51:50 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:51:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:51:50 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:51:52 [INFO] [lib.models.video:417] Chunk size increased from 450 to 460 (after 3 successes, increment: 10)
2025-12-12 17:51:52 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:51:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:51:59 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:52:03 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:52:03 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:52:03 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:52:03 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:52:03 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:52:03 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:52:04 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:52:04 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:52:05 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:52:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:52:07 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:52:24 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:52:26 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 189.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:52:26 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 189.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 189.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:52:26 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:52:26 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:52:26 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:52:26 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:52:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:52:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:52:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:52:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:52:33 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:52:48 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 4.46 GiB is free. Including non-PyTorch memory, this process has 11.29 GiB memory in use. Of the allocated memory 10.81 GiB is allocated by PyTorch, and 115.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:52:48 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 4.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 4.46 GiB is free. Including non-PyTorch memory, this process has 11.29 GiB memory in use. Of the allocated memory 10.81 GiB is allocated by PyTorch, and 115.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 4.46 GiB is free. Including non-PyTorch memory, this process has 11.29 GiB memory in use. Of the allocated memory 10.81 GiB is allocated by PyTorch, and 115.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:52:49 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:52:49 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 23/32
2025-12-12 17:52:49 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 17:52:49 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:52:49 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:52:49 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:52:49 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:52:49 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:52:49 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:52:49 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:52:50 [INFO] [lib.models.video:417] Chunk size increased from 460 to 470 (after 3 successes, increment: 10)
2025-12-12 17:52:51 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:52:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:52:59 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:52:59 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:52:59 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:52:59 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:52:59 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:52:59 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:52:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:52:59 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:53:00 [INFO] [lib.models.video:417] Chunk size increased from 270 to 280 (after 3 successes, increment: 10)
2025-12-12 17:53:01 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:53:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:53:06 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:53:06 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:53:06 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:53:06 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:53:06 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:53:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:53:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:53:07 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:53:08 [INFO] [lib.models.video:417] Chunk size increased from 470 to 480 (after 3 successes, increment: 10)
2025-12-12 17:53:09 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:53:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:53:15 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:53:15 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:53:15 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:53:15 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:53:15 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:53:15 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:53:16 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:53:16 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:53:17 [INFO] [lib.models.video:417] Chunk size increased from 480 to 490 (after 3 successes, increment: 10)
2025-12-12 17:53:17 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:53:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:53:25 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:53:25 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:53:25 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:53:25 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:53:25 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:53:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:53:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:53:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:53:27 [INFO] [lib.models.video:417] Chunk size increased from 490 to 500 (after 3 successes, increment: 10)
2025-12-12 17:53:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:53:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:53:33 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:53:33 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:53:34 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:53:34 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 24/32
2025-12-12 17:53:34 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 17:53:34 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:53:34 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:53:34 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:53:34 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:53:34 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:53:34 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:53:34 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:53:36 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:53:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:53:38 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 4 successes, increment: 10)
2025-12-12 17:53:52 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:53:54 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:53:54 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:53:54 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:53:54 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:53:54 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:53:54 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:53:55 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:53:55 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:53:56 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:53:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:54:00 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:54:06 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 14.26 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 147.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:54:06 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 14.26 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 147.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.49 GiB is free. Including non-PyTorch memory, this process has 14.26 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 147.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:54:06 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:54:06 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:54:06 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:54:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:54:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:54:06 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:54:08 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:54:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:54:11 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 4 successes, increment: 10)
2025-12-12 17:54:16 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:54:19 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 170.19 MiB is free. Including non-PyTorch memory, this process has 15.59 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 140.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:54:19 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 170.19 MiB is free. Including non-PyTorch memory, this process has 15.59 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 140.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.84 GiB. GPU 0 has a total capacity of 15.77 GiB of which 170.19 MiB is free. Including non-PyTorch memory, this process has 15.59 GiB memory in use. Of the allocated memory 15.09 GiB is allocated by PyTorch, and 140.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:54:19 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:54:19 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:54:19 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:54:19 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:54:19 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:54:19 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:54:21 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:54:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:54:28 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:54:38 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:54:38 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:54:38 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:54:38 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:54:38 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:54:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:54:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:54:39 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:54:40 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:54:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:54:42 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 4 successes, increment: 10)
2025-12-12 17:54:59 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:55:02 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:55:02 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:55:02 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:55:02 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 25/32
2025-12-12 17:55:02 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 17:55:02 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:55:02 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:55:02 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:55:02 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:55:02 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:55:02 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:55:02 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:55:04 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:55:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:55:10 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:55:12 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:55:12 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:55:13 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:55:13 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:55:13 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:55:13 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:55:13 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:55:13 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:55:14 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:55:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:55:18 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:55:20 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:55:20 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:55:20 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:55:20 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:55:20 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:55:20 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:55:20 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:55:20 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:55:22 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:55:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:55:31 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:55:34 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:55:34 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:55:34 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:55:34 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:55:34 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:55:34 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:55:34 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:55:34 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:55:36 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:55:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:55:44 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:55:46 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.72 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.53 GiB is allocated by PyTorch, and 139.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:55:46 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.72 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.53 GiB is allocated by PyTorch, and 139.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.72 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.53 GiB is allocated by PyTorch, and 139.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:55:46 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:55:46 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:55:46 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:55:46 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:55:47 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:55:47 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:55:49 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:55:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:55:52 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:55:54 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:55:54 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:55:54 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:55:54 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 26/32
2025-12-12 17:55:54 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 17:55:54 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:55:54 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:55:54 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:55:54 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:55:54 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:55:55 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:55:55 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:55:57 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:55:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:56:00 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:56:07 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:56:07 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:56:07 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:56:07 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:56:07 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:56:07 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:56:08 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:56:08 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:56:09 [INFO] [lib.models.video:417] Chunk size increased from 280 to 290 (after 3 successes, increment: 10)
2025-12-12 17:56:09 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:56:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:56:15 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:56:21 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:56:21 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:56:21 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:56:21 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:56:21 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:56:21 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:56:22 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:56:22 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:56:24 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:56:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:56:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:56:32 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:56:34 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:56:34 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:56:34 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:56:34 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:56:34 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:56:34 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:56:35 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:56:35 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:56:37 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:56:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:56:40 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:56:46 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:56:46 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:56:46 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:56:46 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:56:46 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:56:46 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:56:47 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:56:47 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:56:49 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:56:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:56:50 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 4 successes, increment: 10)
2025-12-12 17:56:56 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:56:59 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:56:59 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:56:59 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:56:59 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 27/32
2025-12-12 17:56:59 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 17:56:59 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:56:59 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:56:59 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:56:59 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:56:59 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:56:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:56:59 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:57:01 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:57:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:57:06 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:57:08 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:57:08 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:57:09 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:57:09 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:57:09 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:57:09 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:57:09 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:57:09 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:57:10 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:57:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:57:15 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:57:17 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:57:17 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:57:17 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:57:17 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:57:17 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:57:17 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:57:17 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:57:17 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:57:19 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:57:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:57:23 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:57:25 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:57:25 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:57:25 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:57:25 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:57:25 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:57:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:57:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:57:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:57:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:57:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:57:32 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:57:34 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:57:34 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:57:34 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:57:34 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:57:34 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:57:34 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:57:35 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:57:35 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:57:36 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:57:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:57:41 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:57:43 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:57:43 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:57:43 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:57:43 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 28/32
2025-12-12 17:57:43 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 17:57:43 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:57:43 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:57:43 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:57:43 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:57:43 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:57:43 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:57:43 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:57:45 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:57:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:57:49 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:57:54 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 17:57:54 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 129.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:57:54 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:57:54 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:57:54 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:57:54 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:57:55 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:57:55 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:57:55 [INFO] [lib.models.video:417] Chunk size increased from 290 to 300 (after 3 successes, increment: 10)
2025-12-12 17:57:56 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:57:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:58:00 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:58:04 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 17:58:04 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:58:05 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:58:05 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:58:05 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:58:05 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:58:05 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:58:05 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:58:07 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:58:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:58:14 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:58:23 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:58:26 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 17:58:26 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:58:26 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:58:26 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:58:26 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:58:26 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:58:27 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:58:27 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:58:29 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:58:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:58:33 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:58:39 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 17:58:39 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:58:39 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:58:39 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:58:39 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:58:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:58:40 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:58:40 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:58:41 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:58:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:58:43 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 4 successes, increment: 10)
2025-12-12 17:58:58 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:59:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 4.17 GiB is free. Including non-PyTorch memory, this process has 11.59 GiB memory in use. Of the allocated memory 11.08 GiB is allocated by PyTorch, and 142.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 17:59:00 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 5.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 4.17 GiB is free. Including non-PyTorch memory, this process has 11.59 GiB memory in use. Of the allocated memory 11.08 GiB is allocated by PyTorch, and 142.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 4.17 GiB is free. Including non-PyTorch memory, this process has 11.59 GiB memory in use. Of the allocated memory 11.08 GiB is allocated by PyTorch, and 142.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:59:01 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:59:01 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 29/32
2025-12-12 17:59:01 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 17:59:01 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:59:01 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:59:01 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:59:01 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:59:01 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:59:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:59:01 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:59:03 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:59:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:59:08 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:59:10 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 17:59:10 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:59:10 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 17:59:10 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 17:59:10 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:59:10 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:59:10 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:59:10 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 17:59:12 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:59:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:59:15 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:59:17 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 17:59:17 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:59:18 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 17:59:18 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 17:59:18 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:59:18 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:59:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:59:18 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 17:59:20 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:59:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:59:24 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:59:25 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 17:59:25 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:59:26 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 17:59:26 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 17:59:26 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:59:26 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:59:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:59:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 17:59:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:59:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:59:32 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 17:59:34 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 17:59:34 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:59:34 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 17:59:34 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 17:59:34 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 17:59:34 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:59:35 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:59:35 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 17:59:37 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:59:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 17:59:45 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 17:59:47 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 17:59:47 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 17:59:47 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 17:59:47 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 30/32
2025-12-12 17:59:47 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 17:59:47 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 17:59:47 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 17:59:47 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 17:59:47 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 17:59:47 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 17:59:48 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 17:59:48 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 17:59:50 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 17:59:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:00:17 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:00:26 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 18:00:26 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:00:26 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 18:00:26 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:00:26 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 18:00:26 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:00:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:00:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 18:00:27 [INFO] [lib.models.video:417] Chunk size increased from 300 to 310 (after 3 successes, increment: 10)
2025-12-12 18:00:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:00:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:00:36 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:00:40 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 18:00:40 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:00:40 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 18:00:40 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:00:40 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 18:00:40 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:00:40 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:00:40 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 18:00:42 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:00:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:00:44 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 18:00:50 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:00:52 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 18:00:53 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:00:53 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 18:00:53 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:00:53 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 18:00:53 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:00:53 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:00:53 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 18:00:55 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:00:56 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:00:59 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:01:05 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 18:01:05 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:01:05 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 18:01:05 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:01:05 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 18:01:05 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:01:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:01:06 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 18:01:08 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:01:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:01:11 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 4 successes, increment: 10)
2025-12-12 18:01:16 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:01:18 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 209.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 18:01:18 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 209.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 209.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:01:18 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:01:18 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 31/32
2025-12-12 18:01:18 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 18:01:18 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:01:18 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 18:01:18 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:01:18 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 18:01:18 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:01:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:01:18 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 1...
2025-12-12 18:01:20 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:01:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:01:24 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 18:01:26 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 18:01:26 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:01:26 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 18:01:26 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:01:26 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 18:01:26 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:01:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:01:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 2...
2025-12-12 18:01:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:01:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:01:31 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 18:01:33 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 18:01:33 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:01:33 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 18:01:33 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:01:33 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 18:01:33 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:01:34 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:01:34 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 3...
2025-12-12 18:01:36 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:01:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:01:41 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:01:43 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 18:01:43 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:01:43 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 18:01:43 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:01:43 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 18:01:43 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:01:43 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:01:43 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 4...
2025-12-12 18:01:45 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:01:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:01:49 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:01:50 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 18:01:50 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:01:51 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 18:01:51 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:01:51 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 18:01:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 18:01:51 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 7367867be9704d52b60428f1c07b5ddd is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:01:51 [INFO] [lib.training.pipeline:1022] Training PyTorch model x3d on fold 5...
2025-12-12 18:01:53 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:01:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:01:57 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
