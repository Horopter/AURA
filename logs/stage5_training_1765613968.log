2025-12-13 03:19:28 [INFO] [__main__:310] ================================================================================
2025-12-13 03:19:28 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-13 03:19:28 [INFO] [__main__:312] ================================================================================
2025-12-13 03:19:28 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-13 03:19:28 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-13 03:19:28 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-13 03:19:28 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-13 03:19:28 [INFO] [__main__:317] Model types: ['xgboost_pretrained_inception']
2025-12-13 03:19:28 [INFO] [__main__:318] K-fold splits: 5
2025-12-13 03:19:28 [INFO] [__main__:319] Number of frames: 1000
2025-12-13 03:19:28 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-13 03:19:28 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-13 03:19:28 [INFO] [__main__:324] Delete existing: True
2025-12-13 03:19:28 [INFO] [__main__:325] Resume mode: True
2025-12-13 03:19:28 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765613968.log
2025-12-13 03:19:28 [INFO] [__main__:333] ================================================================================
2025-12-13 03:19:28 [INFO] [__main__:334] Checking prerequisites...
2025-12-13 03:19:28 [INFO] [__main__:335] ================================================================================
2025-12-13 03:19:28 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-13 03:19:28 [INFO] [__main__:352] ✓ All model types are valid
2025-12-13 03:19:28 [INFO] [__main__:358] ================================================================================
2025-12-13 03:19:28 [INFO] [__main__:359] Initial memory statistics:
2025-12-13 03:19:28 [INFO] [__main__:360] ================================================================================
2025-12-13 03:19:28 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.72265625, 'cpu_memory_gb': 0.7184791564941406, 'cpu_vms_mb': 10217.609375, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-13 03:19:28 [INFO] [__main__:364] ================================================================================
2025-12-13 03:19:28 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-13 03:19:28 [INFO] [__main__:366] ================================================================================
2025-12-13 03:19:28 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-13 03:19:28 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-13 03:19:28 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-13 03:19:28 [INFO] [__main__:370] ================================================================================
2025-12-13 03:19:28 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-13 03:19:28 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:497] ================================================================================
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:498] Stage 5: Model Training Pipeline Started
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:499] ================================================================================
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:500] Model types: ['xgboost_pretrained_inception']
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:501] K-fold splits: 5
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:502] Frames per video: 1000
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:503] Output directory: data/stage5
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:504] Initializing pipeline...
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:266] ================================================================================
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:267] STAGE 5 PREREQUISITE VALIDATION
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:268] ================================================================================
2025-12-13 03:19:28 [INFO] [lib.training.pipeline:271] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:280] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:281]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:284] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:292] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:293]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:296] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:304] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:305]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:308] 
================================================================================
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:309] MODEL REQUIREMENTS CHECK
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:310] ================================================================================
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:334] ✓ xgboost_pretrained_inception: CAN RUN
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:337] 
================================================================================
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:338] VALIDATION SUMMARY
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:339] ================================================================================
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:340] Stage 3 (scaled videos): ✓ Available
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:341]   Count: 3278 videos
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:342] Stage 2 (features): ✓ Available
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:343]   Count: 3278 feature rows
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:344] Stage 4 (scaled features): ✓ Available
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:345]   Count: 3277 feature rows
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:346] 
Runnable models: 1/1
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:347]   ['xgboost_pretrained_inception']
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:354] ================================================================================
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:590] 
Stage 5: Loading metadata...
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:616] Loaded metadata: 3278 rows
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:626] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-13 03:19:30 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=828183.33GB, used=1671656.67GB (66.9%)
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:648] Loading Stage 2 and Stage 4 features (required for feature-based models)...
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:658] Stage 5: Found 3278 scaled videos
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:721] Frame caching enabled (default): cache_dir=data/.frame_cache. This will cache processed frames to disk to speed up training. First epoch will be slower (building cache), subsequent epochs will be faster. To disable, set FVC_USE_FRAME_CACHE=0
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:817] Stage 5: Deleting existing model results (clean mode)...
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:826] Deleted existing results for xgboost_pretrained_inception
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:829] Stage 5: Deleted 1 existing model directories
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:834] 
================================================================================
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:835] Stage 5: Training model: xgboost_pretrained_inception
2025-12-13 03:19:30 [INFO] [lib.training.pipeline:836] ================================================================================
2025-12-13 03:19:31 [INFO] [lib.training.pipeline:869] Grid search: 1 hyperparameter combinations to try
2025-12-13 03:19:31 [INFO] [lib.training.pipeline:883] ================================================================================
2025-12-13 03:19:31 [INFO] [lib.training.pipeline:884] HYPERPARAMETER SEARCH: Using 10.0% stratified sample for efficiency
2025-12-13 03:19:31 [INFO] [lib.training.pipeline:885] ================================================================================
2025-12-13 03:19:32 [INFO] [lib.training.pipeline:895] Hyperparameter search sample: 327 rows (10.0% of 3278 total)
2025-12-13 03:19:32 [INFO] [lib.training.pipeline:896] To change sample size, set FVC_GRID_SEARCH_SAMPLE_SIZE environment variable (current: 0.1)
2025-12-13 03:19:33 [INFO] [lib.training.pipeline:909] Using 5-fold stratified cross-validation on 10.0% sample for hyperparameter search
2025-12-13 03:19:33 [INFO] [lib.training.pipeline:922] 
================================================================================
2025-12-13 03:19:33 [INFO] [lib.training.pipeline:923] Grid Search: Hyperparameter combination 1/1
2025-12-13 03:19:33 [INFO] [lib.training.pipeline:924] Parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-13 03:19:33 [INFO] [lib.training.pipeline:925] ================================================================================
2025-12-13 03:19:33 [INFO] [lib.training.pipeline:954] 
Hyperparameter Search - xgboost_pretrained_inception - Fold 1/5 (20% sample)
2025-12-13 03:19:33 [INFO] [lib.training.pipeline:1540] Training XGBoost model xgboost_pretrained_inception on fold 1...
2025-12-13 03:19:33 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:19:33 [INFO] [lib.training._xgboost_pretrained:379] Processing 261 videos...
2025-12-13 03:19:33 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:19:34 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:19:34 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:19:47 [ERROR] [lib.training.pipeline:1608] Error training XGBoost fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.76 GiB is free. Including non-PyTorch memory, this process has 13.00 GiB memory in use. Of the allocated memory 12.61 GiB is allocated by PyTorch, and 28.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1555, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.76 GiB is free. Including non-PyTorch memory, this process has 13.00 GiB memory in use. Of the allocated memory 12.61 GiB is allocated by PyTorch, and 28.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:19:47 [INFO] [lib.training.pipeline:954] 
Hyperparameter Search - xgboost_pretrained_inception - Fold 2/5 (20% sample)
2025-12-13 03:19:47 [INFO] [lib.training.pipeline:1540] Training XGBoost model xgboost_pretrained_inception on fold 2...
2025-12-13 03:19:47 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:19:47 [INFO] [lib.training._xgboost_pretrained:379] Processing 261 videos...
2025-12-13 03:19:47 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:19:48 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:19:48 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:19:52 [ERROR] [lib.training.pipeline:1608] Error training XGBoost fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1555, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:19:52 [INFO] [lib.training.pipeline:954] 
Hyperparameter Search - xgboost_pretrained_inception - Fold 3/5 (20% sample)
2025-12-13 03:19:52 [INFO] [lib.training.pipeline:1540] Training XGBoost model xgboost_pretrained_inception on fold 3...
2025-12-13 03:19:52 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:19:52 [INFO] [lib.training._xgboost_pretrained:379] Processing 262 videos...
2025-12-13 03:19:52 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:19:53 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:19:53 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:19:57 [ERROR] [lib.training.pipeline:1608] Error training XGBoost fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 13.18 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1555, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 13.18 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:19:58 [INFO] [lib.training.pipeline:954] 
Hyperparameter Search - xgboost_pretrained_inception - Fold 4/5 (20% sample)
2025-12-13 03:19:58 [INFO] [lib.training.pipeline:1540] Training XGBoost model xgboost_pretrained_inception on fold 4...
2025-12-13 03:19:58 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:19:58 [INFO] [lib.training._xgboost_pretrained:379] Processing 262 videos...
2025-12-13 03:19:58 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:19:58 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:19:58 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:20:02 [ERROR] [lib.training.pipeline:1608] Error training XGBoost fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 13.18 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1555, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 13.18 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:20:03 [INFO] [lib.training.pipeline:954] 
Hyperparameter Search - xgboost_pretrained_inception - Fold 5/5 (20% sample)
2025-12-13 03:20:03 [INFO] [lib.training.pipeline:1540] Training XGBoost model xgboost_pretrained_inception on fold 5...
2025-12-13 03:20:03 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:20:03 [INFO] [lib.training._xgboost_pretrained:379] Processing 262 videos...
2025-12-13 03:20:03 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:20:03 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:20:03 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:20:07 [ERROR] [lib.training.pipeline:1608] Error training XGBoost fold 5: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 13.18 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1555, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 13.18 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1862] Parameter combination 1 - Mean F1: nan, Mean Acc: nan
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1874] Using single parameter combination: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1877] ================================================================================
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1878] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1879] ================================================================================
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1892] Final training: Using 5-fold stratified cross-validation on full dataset (3278 rows)
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1900] Final training using best hyperparameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1906] 
Final Training - xgboost_pretrained_inception - Fold 1/5 (full dataset)
2025-12-13 03:20:07 [INFO] [lib.training.pipeline:1915] Deleted existing final training fold 1 directory (clean mode)
2025-12-13 03:20:07 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:20:07 [INFO] [lib.training._xgboost_pretrained:379] Processing 2621 videos...
2025-12-13 03:20:07 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:20:07 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:20:07 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:20:11 [ERROR] [lib.training.pipeline:2280] Error training final fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 13.18 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2159, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 13.18 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 47.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:20:11 [INFO] [lib.training.pipeline:1906] 
Final Training - xgboost_pretrained_inception - Fold 2/5 (full dataset)
2025-12-13 03:20:11 [INFO] [lib.training.pipeline:1915] Deleted existing final training fold 2 directory (clean mode)
2025-12-13 03:20:11 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:20:11 [INFO] [lib.training._xgboost_pretrained:379] Processing 2622 videos...
2025-12-13 03:20:11 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:20:12 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:20:12 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:20:15 [ERROR] [lib.training.pipeline:2280] Error training final fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2159, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:20:15 [INFO] [lib.training.pipeline:1906] 
Final Training - xgboost_pretrained_inception - Fold 3/5 (full dataset)
2025-12-13 03:20:15 [INFO] [lib.training.pipeline:1915] Deleted existing final training fold 3 directory (clean mode)
2025-12-13 03:20:15 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:20:15 [INFO] [lib.training._xgboost_pretrained:379] Processing 2623 videos...
2025-12-13 03:20:15 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:20:16 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:20:16 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:20:19 [ERROR] [lib.training.pipeline:2280] Error training final fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2159, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:20:19 [INFO] [lib.training.pipeline:1906] 
Final Training - xgboost_pretrained_inception - Fold 4/5 (full dataset)
2025-12-13 03:20:19 [INFO] [lib.training.pipeline:1915] Deleted existing final training fold 4 directory (clean mode)
2025-12-13 03:20:19 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:20:19 [INFO] [lib.training._xgboost_pretrained:379] Processing 2623 videos...
2025-12-13 03:20:19 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:20:20 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:20:20 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:20:24 [ERROR] [lib.training.pipeline:2280] Error training final fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2159, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:20:24 [INFO] [lib.training.pipeline:1906] 
Final Training - xgboost_pretrained_inception - Fold 5/5 (full dataset)
2025-12-13 03:20:24 [INFO] [lib.training.pipeline:1915] Deleted existing final training fold 5 directory (clean mode)
2025-12-13 03:20:24 [INFO] [lib.training._xgboost_pretrained:378] Training XGBoost on features from pretrained_inception...
2025-12-13 03:20:24 [INFO] [lib.training._xgboost_pretrained:379] Processing 2623 videos...
2025-12-13 03:20:24 [INFO] [lib.training._xgboost_pretrained:325] Loading pretrained model: pretrained_inception
2025-12-13 03:20:24 [ERROR] [lib.models.video:566] CRITICAL ERROR: use_scaled_videos=False in Stage 5! Stage 5 ALWAYS uses scaled videos from Stage 3. This indicates a configuration error - use_scaled_videos should be True. Falling back to scaled video mode (normalization only).
2025-12-13 03:20:24 [INFO] [lib.training._xgboost_pretrained:356] Extracting features using pretrained_inception...
2025-12-13 03:20:28 [ERROR] [lib.training.pipeline:2280] Error training final fold 5: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2159, in stage5_train_models
    model.fit(train_df, project_root=project_root_str_orig)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 388, in fit
    features, y = self._extract_features_batch(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 357, in _extract_features_batch
    features = extract_features_from_pretrained_model(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_xgboost_pretrained.py", line 145, in extract_features_from_pretrained_model
    x = model.layer1(x)
        ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 13.16 GiB memory in use. Of the allocated memory 12.77 GiB is allocated by PyTorch, and 27.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-13 03:20:28 [WARNING] [lib.training.pipeline:119] No model files found in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_pretrained_inception/fold_1 to copy
2025-12-13 03:20:28 [INFO] [lib.training.pipeline:2353] 
xgboost_pretrained_inception - Avg Val Loss: nan, Avg Val Acc: nan, Avg Val F1: nan
2025-12-13 03:20:30 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_pretrained_inception/plots/cv_fold_comparison.png
2025-12-13 03:20:30 [INFO] [lib.training.pipeline:2381] Generated plots for xgboost_pretrained_inception in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_pretrained_inception/plots
2025-12-13 03:20:30 [INFO] [lib.training.pipeline:2418] ================================================================================
2025-12-13 03:20:30 [INFO] [lib.training.pipeline:2419] Stage 5: Model Training Pipeline Completed
2025-12-13 03:20:30 [INFO] [lib.training.pipeline:2420] ================================================================================
2025-12-13 03:20:30 [INFO] [__main__:401] ================================================================================
2025-12-13 03:20:30 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-13 03:20:30 [INFO] [__main__:403] ================================================================================
2025-12-13 03:20:30 [INFO] [__main__:404] Execution time: 61.78 seconds (1.03 minutes)
2025-12-13 03:20:30 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-13 03:20:30 [INFO] [__main__:407] Models trained: ['xgboost_pretrained_inception']
2025-12-13 03:20:30 [INFO] [__main__:408] K-fold splits: 5
2025-12-13 03:20:30 [INFO] [__main__:414] ================================================================================
2025-12-13 03:20:30 [INFO] [__main__:415] Final memory statistics:
2025-12-13 03:20:30 [INFO] [__main__:416] ================================================================================
2025-12-13 03:20:30 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: after training): {'cpu_memory_mb': 2338.3125, 'cpu_memory_gb': 2.28350830078125, 'cpu_vms_mb': 49434.703125, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 13.744734208, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 3.183607808}
2025-12-13 03:20:30 [INFO] [__main__:419] ================================================================================
2025-12-13 03:20:30 [INFO] [__main__:420] Training complete!
2025-12-13 03:20:30 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-13 03:20:30 [INFO] [__main__:422] ================================================================================
