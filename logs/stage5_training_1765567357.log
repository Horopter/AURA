2025-12-12 14:22:37 [INFO] [__main__:310] ================================================================================
2025-12-12 14:22:37 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-12 14:22:37 [INFO] [__main__:312] ================================================================================
2025-12-12 14:22:37 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-12 14:22:37 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 14:22:37 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 14:22:37 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 14:22:37 [INFO] [__main__:317] Model types: ['x3d']
2025-12-12 14:22:37 [INFO] [__main__:318] K-fold splits: 5
2025-12-12 14:22:37 [INFO] [__main__:319] Number of frames: 500
2025-12-12 14:22:37 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 14:22:37 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-12 14:22:37 [INFO] [__main__:324] Delete existing: False
2025-12-12 14:22:37 [INFO] [__main__:325] Resume mode: True
2025-12-12 14:22:37 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765567357.log
2025-12-12 14:22:37 [INFO] [__main__:333] ================================================================================
2025-12-12 14:22:37 [INFO] [__main__:334] Checking prerequisites...
2025-12-12 14:22:37 [INFO] [__main__:335] ================================================================================
2025-12-12 14:22:37 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 14:22:37 [INFO] [__main__:352] ✓ All model types are valid
2025-12-12 14:22:37 [INFO] [__main__:358] ================================================================================
2025-12-12 14:22:37 [INFO] [__main__:359] Initial memory statistics:
2025-12-12 14:22:37 [INFO] [__main__:360] ================================================================================
2025-12-12 14:22:37 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.4921875, 'cpu_memory_gb': 0.7182540893554688, 'cpu_vms_mb': 10217.5703125, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-12 14:22:37 [INFO] [__main__:364] ================================================================================
2025-12-12 14:22:37 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-12 14:22:37 [INFO] [__main__:366] ================================================================================
2025-12-12 14:22:37 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-12 14:22:37 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-12 14:22:37 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-12 14:22:37 [INFO] [__main__:370] ================================================================================
2025-12-12 14:22:37 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-12 14:22:37 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:490] ================================================================================
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:491] Stage 5: Model Training Pipeline Started
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:492] ================================================================================
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:493] Model types: ['x3d']
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:494] K-fold splits: 5
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:495] Frames per video: 500
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:496] Output directory: data/stage5
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:497] Initializing pipeline...
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:265] ================================================================================
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:266] STAGE 5 PREREQUISITE VALIDATION
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:267] ================================================================================
2025-12-12 14:22:37 [INFO] [lib.training.pipeline:270] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:279] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:280]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:283] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:291] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:292]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:295] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:303] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:304]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:307] 
================================================================================
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:308] MODEL REQUIREMENTS CHECK
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:309] ================================================================================
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:333] ✓ x3d: CAN RUN
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:336] 
================================================================================
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:337] VALIDATION SUMMARY
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:338] ================================================================================
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:339] Stage 3 (scaled videos): ✓ Available
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:340]   Count: 3278 videos
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:341] Stage 2 (features): ✓ Available
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:342]   Count: 3278 feature rows
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:343] Stage 4 (scaled features): ✓ Available
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:344]   Count: 3277 feature rows
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:345] 
Runnable models: 1/1
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:346]   ['x3d']
2025-12-12 14:22:40 [INFO] [lib.training.pipeline:353] ================================================================================
2025-12-12 14:22:41 [INFO] [lib.training.pipeline:583] 
Stage 5: Loading metadata...
2025-12-12 14:22:41 [INFO] [lib.training.pipeline:609] Loaded metadata: 3278 rows
2025-12-12 14:22:41 [INFO] [lib.training.pipeline:619] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-12 14:22:41 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=822599.69GB, used=1677240.31GB (67.1%)
2025-12-12 14:22:41 [INFO] [lib.training.pipeline:651] Stage 5: Found 3278 scaled videos
2025-12-12 14:22:41 [INFO] [lib.training.pipeline:725] 
================================================================================
2025-12-12 14:22:41 [INFO] [lib.training.pipeline:726] Stage 5: Training model: x3d
2025-12-12 14:22:41 [INFO] [lib.training.pipeline:727] ================================================================================
2025-12-12 14:22:43 [INFO] [lib.training.pipeline:751] Grid search: 32 hyperparameter combinations to try
2025-12-12 14:22:43 [INFO] [lib.training.pipeline:759] ================================================================================
2025-12-12 14:22:43 [INFO] [lib.training.pipeline:760] HYPERPARAMETER SEARCH: Using 20% stratified sample for efficiency
2025-12-12 14:22:43 [INFO] [lib.training.pipeline:761] ================================================================================
2025-12-12 14:22:45 [INFO] [lib.training.pipeline:770] Hyperparameter search sample: 655 rows (20.0% of 3278 total)
2025-12-12 14:22:49 [INFO] [lib.training.pipeline:783] Using 5-fold stratified cross-validation on 20% sample for hyperparameter search
2025-12-12 14:22:49 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:22:49 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 1/32
2025-12-12 14:22:49 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 14:22:49 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:22:49 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:22:49 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:22:49 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:23:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 21ace6e581584db78a7fe9b09e14ed09 (experiment: x3d)
2025-12-12 14:23:00 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:23:21 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:23:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:23:30 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.81 GiB is free. Including non-PyTorch memory, this process has 12.95 GiB memory in use. Of the allocated memory 12.53 GiB is allocated by PyTorch, and 55.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:23:30 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.81 GiB is free. Including non-PyTorch memory, this process has 12.95 GiB memory in use. Of the allocated memory 12.53 GiB is allocated by PyTorch, and 55.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.81 GiB is free. Including non-PyTorch memory, this process has 12.95 GiB memory in use. Of the allocated memory 12.53 GiB is allocated by PyTorch, and 55.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:23:30 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:23:30 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:23:30 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:23:31 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:23:31 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:23:32 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:23:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:23:39 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.77 GiB is free. Including non-PyTorch memory, this process has 12.99 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 41.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:23:39 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.77 GiB is free. Including non-PyTorch memory, this process has 12.99 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 41.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.77 GiB is free. Including non-PyTorch memory, this process has 12.99 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 41.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:23:39 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:23:39 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:23:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:23:40 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:23:40 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:23:41 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:23:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:23:46 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 81.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:23:46 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 81.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 81.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:23:47 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:23:47 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:23:47 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:23:47 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:23:47 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:23:48 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:23:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:23:59 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 83.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:23:59 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 83.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.73 GiB is free. Including non-PyTorch memory, this process has 13.03 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 83.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:23:59 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:23:59 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:23:59 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:23:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:23:59 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:24:01 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:24:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:24:07 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:24:07 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:24:08 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:24:08 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 2/32
2025-12-12 14:24:08 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 14:24:08 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:24:08 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:24:08 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:24:08 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:24:08 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:24:08 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:24:10 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:24:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:24:22 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.91 GiB is free. Including non-PyTorch memory, this process has 9.85 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 73.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:24:22 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.91 GiB is free. Including non-PyTorch memory, this process has 9.85 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 73.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.91 GiB is free. Including non-PyTorch memory, this process has 9.85 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 73.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:24:22 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:24:22 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:24:22 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:24:23 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:24:23 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:24:23 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:24:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:24:37 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:24:37 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:24:37 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:24:37 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:24:37 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:24:37 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:24:37 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:24:39 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:24:39 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:24:48 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:24:48 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:24:48 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:24:48 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:24:48 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:24:49 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:24:49 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:24:50 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:24:51 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:24:58 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:24:58 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:24:59 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:24:59 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:24:59 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:24:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:24:59 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:25:00 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:25:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:25:16 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:25:16 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:25:16 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:25:16 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 3/32
2025-12-12 14:25:16 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 14:25:16 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:25:16 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:25:16 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:25:16 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:25:17 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:25:17 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:25:18 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:25:19 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:25:23 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:25:23 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:25:24 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:25:24 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:25:24 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:25:24 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:25:24 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:25:25 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:25:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:25:31 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:25:31 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:25:31 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:25:31 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:25:31 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:25:31 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:25:31 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:25:33 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:25:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:25:39 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:25:39 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:25:39 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:25:39 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:25:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:25:40 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:25:40 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:25:41 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:25:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:25:53 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:25:53 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:25:53 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:25:53 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:25:53 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:25:54 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:25:54 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:25:55 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:25:56 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:26:02 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:26:02 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:26:03 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:26:03 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 4/32
2025-12-12 14:26:03 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 14:26:03 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:26:03 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:26:03 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:26:03 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:26:03 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:26:03 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:26:05 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:26:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:26:18 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:26:18 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:26:19 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:26:19 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:26:19 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:26:19 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:26:19 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:26:20 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:26:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:26:35 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:26:35 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:26:35 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:26:35 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:26:35 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:26:36 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:26:36 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:26:37 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:26:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:26:44 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:26:44 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:26:45 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:26:45 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:26:45 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:26:45 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:26:45 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:26:47 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:26:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:26:58 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:26:58 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:26:58 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:26:58 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:26:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:26:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:26:59 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:27:00 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:27:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:27:10 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 189.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:27:10 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 189.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 14.69 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 189.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:27:11 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:27:11 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 5/32
2025-12-12 14:27:11 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 14:27:11 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:27:11 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:27:11 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:27:11 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:27:11 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:27:11 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:27:12 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:27:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:27:17 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:27:17 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:27:18 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:27:18 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:27:18 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:27:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:27:18 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:27:19 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:27:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:27:24 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:27:24 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:27:25 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:27:25 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:27:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:27:25 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:27:25 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:27:26 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:27:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:27:37 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:27:37 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:27:37 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:27:37 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:27:37 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:27:38 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:27:38 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:27:39 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:27:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:27:43 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:27:43 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:27:44 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:27:44 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:27:44 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:27:44 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:27:44 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:27:46 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:27:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:27:51 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.14 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.94 GiB is free. Including non-PyTorch memory, this process has 13.81 GiB memory in use. Of the allocated memory 13.29 GiB is allocated by PyTorch, and 154.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:27:51 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 3.14 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.94 GiB is free. Including non-PyTorch memory, this process has 13.81 GiB memory in use. Of the allocated memory 13.29 GiB is allocated by PyTorch, and 154.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.14 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.94 GiB is free. Including non-PyTorch memory, this process has 13.81 GiB memory in use. Of the allocated memory 13.29 GiB is allocated by PyTorch, and 154.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:27:51 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:27:51 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 6/32
2025-12-12 14:27:51 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 14:27:51 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:27:51 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:27:51 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:27:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:27:52 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:27:52 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:27:53 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:27:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:28:04 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:28:04 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:28:05 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:28:05 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:28:05 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:28:05 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:28:05 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:28:06 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:28:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:28:20 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 13.58 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 131.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:28:20 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 13.58 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 131.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 13.58 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 131.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:28:20 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:28:20 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:28:20 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:28:21 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:28:21 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:28:22 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:28:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:28:36 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:28:36 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:28:36 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:28:36 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:28:36 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:28:37 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:28:37 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:28:38 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:28:39 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:28:49 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:28:49 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:28:50 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:28:50 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:28:50 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:28:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:28:50 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:28:51 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:28:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:29:12 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:29:12 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:29:13 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:29:13 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 7/32
2025-12-12 14:29:13 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 14:29:13 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:29:13 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:29:13 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:29:13 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:29:13 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:29:13 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:29:14 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:29:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:29:19 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.05 GiB is free. Including non-PyTorch memory, this process has 5.71 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 156.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:29:19 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.05 GiB is free. Including non-PyTorch memory, this process has 5.71 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 156.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.05 GiB is free. Including non-PyTorch memory, this process has 5.71 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 156.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:29:19 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:29:20 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:29:20 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:29:20 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:29:20 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:29:21 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:29:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:29:25 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:29:25 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:29:25 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:29:25 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:29:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:29:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:29:26 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:29:27 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:29:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:29:32 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:29:32 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:29:32 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:29:32 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:29:32 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:29:33 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:29:33 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:29:34 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:29:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:29:39 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:29:39 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.88 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 110.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:29:39 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:29:39 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:29:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:29:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:29:39 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:29:41 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:29:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:29:45 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:29:45 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:29:46 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:29:46 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 8/32
2025-12-12 14:29:46 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 14:29:46 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:29:46 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:29:46 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:29:46 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:29:46 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:29:46 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:29:47 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:29:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:30:01 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:30:01 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:30:02 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:30:02 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:30:02 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:30:02 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:30:02 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:30:03 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:30:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:30:12 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:30:12 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:30:12 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:30:12 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:30:12 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:30:13 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:30:13 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:30:14 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:30:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:30:25 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:30:25 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:30:25 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:30:25 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:30:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:30:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:30:26 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:30:27 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:30:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:30:47 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:30:47 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:30:48 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:30:48 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:30:48 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:30:48 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:30:48 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:30:49 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:30:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:30:57 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:30:57 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:30:58 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:30:58 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 9/32
2025-12-12 14:30:58 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 14:30:58 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:30:58 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:30:58 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:30:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:30:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:30:58 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:30:59 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:31:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:31:04 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:31:04 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:31:05 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:31:05 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:31:05 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:31:05 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:31:05 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:31:06 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:31:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:31:14 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:31:14 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.26 GiB is free. Including non-PyTorch memory, this process has 4.50 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 85.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:31:14 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:31:14 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:31:14 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:31:15 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:31:15 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:31:16 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:31:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:31:20 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:31:20 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:31:21 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:31:21 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:31:21 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:31:21 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:31:21 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:31:22 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:31:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:31:27 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:31:27 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:31:28 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:31:28 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:31:28 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:31:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:31:28 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:31:29 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:31:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:31:42 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:31:42 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:31:42 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:31:42 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 10/32
2025-12-12 14:31:42 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 14:31:42 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:31:42 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:31:42 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:31:42 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:31:43 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:31:43 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:31:44 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:31:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:31:53 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:31:53 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:31:53 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:31:53 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:31:53 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:31:54 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:31:54 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:31:54 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:31:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:32:05 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:32:05 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:32:05 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:32:05 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:32:05 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:32:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:32:06 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:32:07 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:32:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:32:17 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 138.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:32:17 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 138.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 138.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:32:18 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:32:18 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:32:18 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:32:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:32:18 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:32:19 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:32:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:32:35 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:32:35 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:32:36 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:32:36 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:32:36 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:32:36 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:32:36 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:32:37 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:32:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:32:51 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 178.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:32:51 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 178.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 178.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:32:51 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:32:51 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 11/32
2025-12-12 14:32:51 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 14:32:51 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:32:51 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:32:51 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:32:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:32:51 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:32:51 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:32:53 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:32:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:32:57 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:32:57 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:32:58 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:32:58 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:32:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:32:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:32:58 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:32:59 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:32:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:33:06 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:33:06 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:33:06 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:33:06 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:33:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:33:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:33:07 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:33:08 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:33:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:33:15 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:33:15 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:33:15 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:33:15 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:33:15 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:33:16 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:33:16 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:33:17 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:33:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:33:23 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:33:23 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:33:23 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:33:23 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:33:23 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:33:23 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:33:23 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:33:25 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:33:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:33:29 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:33:29 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:33:30 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:33:30 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 12/32
2025-12-12 14:33:30 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 14:33:30 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:33:30 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:33:30 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:33:30 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:33:30 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:33:30 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:33:31 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:33:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:33:38 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:33:38 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:33:38 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:33:38 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:33:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:33:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:33:39 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:33:39 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:33:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:33:51 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 169.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:33:51 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 169.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 169.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:33:51 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:33:51 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:33:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:33:52 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:33:52 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:33:53 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:33:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:34:01 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 14.20 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 87.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:34:01 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 14.20 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 87.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.55 GiB is free. Including non-PyTorch memory, this process has 14.20 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 87.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:34:01 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:34:01 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:34:01 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:34:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:34:01 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:34:02 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:34:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:34:11 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:34:11 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:34:11 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:34:11 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:34:11 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:34:12 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:34:12 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:34:13 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:34:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:34:24 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:34:24 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:34:25 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:34:25 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 13/32
2025-12-12 14:34:25 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 14:34:25 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:34:25 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:34:25 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:34:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:34:25 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:34:25 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:34:26 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:34:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:34:31 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:34:31 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:34:31 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:34:31 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:34:31 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:34:32 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:34:32 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:34:32 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:34:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:34:37 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:34:37 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:34:37 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:34:37 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:34:37 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:34:38 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:34:38 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:34:39 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:34:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:34:50 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:34:50 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:34:51 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:34:51 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:34:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:34:51 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:34:51 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:34:52 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:34:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:35:09 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.79 GiB is free. Including non-PyTorch memory, this process has 4.96 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 119.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:35:09 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.79 GiB is free. Including non-PyTorch memory, this process has 4.96 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 119.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.79 GiB is free. Including non-PyTorch memory, this process has 4.96 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 119.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:35:10 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:35:10 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:35:10 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:35:10 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:35:10 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:35:11 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:35:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:35:16 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:35:16 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:35:16 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:35:16 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 14/32
2025-12-12 14:35:16 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 14:35:16 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:35:16 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:35:16 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:35:16 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:35:17 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:35:17 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:35:18 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:35:19 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:35:26 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.15 GiB is allocated by PyTorch, and 117.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:35:26 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 6.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.15 GiB is allocated by PyTorch, and 117.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 14.63 GiB memory in use. Of the allocated memory 14.15 GiB is allocated by PyTorch, and 117.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:35:27 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:35:27 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:35:27 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:35:27 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:35:27 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:35:28 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:35:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:35:42 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:35:42 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:35:42 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:35:42 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:35:42 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:35:43 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:35:43 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:35:44 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:35:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:35:55 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:35:55 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:35:55 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:35:55 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:35:55 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:35:56 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:35:56 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:35:57 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:35:58 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:36:06 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:36:06 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:36:07 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:36:07 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:36:07 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:36:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:36:07 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:36:08 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:36:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:36:20 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:36:20 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:36:20 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:36:20 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 15/32
2025-12-12 14:36:20 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 14:36:20 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:36:20 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:36:20 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:36:20 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:36:21 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:36:21 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:36:22 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:36:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:36:27 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:36:27 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:36:27 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:36:27 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:36:27 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:36:27 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:36:27 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:36:28 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:36:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:36:38 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:36:38 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:36:38 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:36:38 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:36:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:36:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:36:39 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:36:40 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:36:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:36:47 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:36:47 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:36:47 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:36:47 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:36:47 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:36:48 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:36:48 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:36:49 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:36:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:36:57 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:36:57 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:36:58 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:36:58 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:36:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:36:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:36:58 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:37:00 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:37:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:37:06 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:37:06 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:37:06 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:37:06 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 16/32
2025-12-12 14:37:06 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 14:37:06 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:37:06 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:37:06 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:37:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:37:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:37:07 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:37:08 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:37:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:37:17 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:37:17 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:37:18 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:37:18 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:37:18 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:37:18 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:37:18 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:37:19 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:37:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:37:27 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:37:27 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:37:27 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:37:27 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:37:27 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:37:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:37:28 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:37:29 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:37:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:37:39 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:37:39 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 14.65 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 149.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:37:39 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:37:39 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:37:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:37:40 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:37:40 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:37:41 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:37:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:37:54 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:37:54 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:37:54 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:37:54 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:37:54 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:37:55 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:37:55 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:37:56 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:37:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:38:05 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:38:05 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:38:06 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:38:06 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 17/32
2025-12-12 14:38:06 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 14:38:06 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:38:06 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:38:06 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:38:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:38:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:38:06 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:38:08 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:38:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:38:13 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.16 GiB is free. Including non-PyTorch memory, this process has 4.59 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 185.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:38:13 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.16 GiB is free. Including non-PyTorch memory, this process has 4.59 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 185.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.16 GiB is free. Including non-PyTorch memory, this process has 4.59 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 185.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:38:13 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:38:13 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:38:13 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:38:13 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:38:13 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:38:14 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:38:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:38:20 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:38:20 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:38:20 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:38:20 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:38:20 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:38:20 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:38:20 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:38:22 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:38:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:38:27 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:38:27 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:38:27 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:38:27 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:38:27 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:38:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:38:28 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:38:29 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:38:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:38:34 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:38:34 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:38:34 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:38:34 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:38:34 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:38:35 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:38:35 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:38:36 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:38:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:38:41 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:38:41 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 13.11 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 163.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:38:41 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:38:41 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 18/32
2025-12-12 14:38:41 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 14:38:41 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:38:41 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:38:41 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:38:41 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:38:41 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:38:41 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:38:43 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:38:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:38:50 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:38:50 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:38:51 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:38:51 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:38:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:38:51 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:38:51 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:38:52 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:38:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:39:01 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:39:01 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:39:01 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:39:01 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:39:01 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:39:02 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:39:02 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:39:03 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:39:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:39:19 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:39:20 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:39:20 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:39:20 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:39:20 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:39:20 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:39:20 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:39:22 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:39:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:39:39 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:39:39 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:39:39 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:39:39 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:39:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:39:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:39:39 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:39:41 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:39:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:39:50 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:39:50 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:39:51 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:39:51 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 19/32
2025-12-12 14:39:51 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 14:39:51 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:39:51 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:39:51 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:39:51 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:39:51 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:39:51 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:39:52 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:39:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:39:57 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.80 GiB is free. Including non-PyTorch memory, this process has 12.95 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 190.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:39:57 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.80 GiB is free. Including non-PyTorch memory, this process has 12.95 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 190.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.80 GiB is free. Including non-PyTorch memory, this process has 12.95 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 190.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:39:58 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:39:58 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:39:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:39:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:39:58 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:39:59 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:40:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:40:05 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:40:05 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:40:06 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:40:06 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:40:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:40:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:40:06 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:40:08 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:40:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:40:14 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:40:14 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:40:14 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:40:14 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:40:14 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:40:15 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:40:15 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:40:16 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:40:16 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:40:20 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 13.71 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 185.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:40:20 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 13.71 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 185.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 13.71 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 185.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:40:21 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:40:21 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:40:21 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:40:21 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:40:21 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:40:22 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:40:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:40:27 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:40:27 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:40:27 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:40:27 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 20/32
2025-12-12 14:40:27 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 14:40:27 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:40:27 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:40:27 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:40:27 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:40:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:40:28 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:40:29 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:40:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:40:41 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:40:41 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:40:42 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:40:42 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:40:42 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:40:42 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:40:42 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:40:43 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:40:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:40:52 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:40:52 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:40:52 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:40:53 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:40:53 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:40:53 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:40:53 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:40:54 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:40:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:41:04 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:41:04 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 14.61 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 109.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:41:05 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:41:05 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:41:05 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:41:05 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:41:05 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:41:07 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:41:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:41:13 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 14.28 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 167.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:41:13 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 14.28 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 167.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.47 GiB is free. Including non-PyTorch memory, this process has 14.28 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 167.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:41:14 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:41:14 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:41:14 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:41:14 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:41:14 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:41:16 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:41:16 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:41:31 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:41:31 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:41:31 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:41:31 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 21/32
2025-12-12 14:41:31 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 14:41:31 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:41:31 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:41:31 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:41:31 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:41:32 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:41:32 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:41:33 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:41:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:41:39 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:41:39 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:41:39 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:41:39 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:41:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:41:40 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:41:40 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:41:40 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:41:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:41:45 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:41:45 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:41:45 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:41:45 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:41:45 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:41:46 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:41:46 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:41:47 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:41:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:41:54 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:41:54 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 5.69 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 136.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:41:54 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:41:54 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:41:54 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:41:55 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:41:55 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:41:56 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:41:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:42:01 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:42:01 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:42:01 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:42:01 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:42:01 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:42:02 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:42:02 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:42:03 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:42:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:42:14 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:42:14 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:42:14 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:42:14 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 22/32
2025-12-12 14:42:14 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 14:42:14 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:42:14 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:42:14 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:42:14 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:42:15 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:42:15 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:42:16 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:42:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:42:25 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:42:25 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.23 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.51 GiB is free. Including non-PyTorch memory, this process has 14.24 GiB memory in use. Of the allocated memory 13.75 GiB is allocated by PyTorch, and 127.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:42:25 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:42:25 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:42:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:42:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:42:26 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:42:27 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:42:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:42:37 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:42:37 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:42:38 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:42:38 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:42:38 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:42:38 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:42:38 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:42:39 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:42:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:42:49 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 138.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:42:49 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 138.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 138.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:42:49 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:42:49 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:42:49 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:42:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:42:50 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:42:51 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:42:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:43:01 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:43:01 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.81 GiB is free. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 173.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:43:02 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:43:02 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:43:02 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:43:02 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:43:02 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:43:03 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:43:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:43:13 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:43:13 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:43:13 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:43:13 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 23/32
2025-12-12 14:43:13 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 14:43:13 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:43:13 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:43:13 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:43:13 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:43:14 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:43:14 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:43:15 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:43:16 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:43:21 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:43:21 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.18 GiB is free. Including non-PyTorch memory, this process has 4.57 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 165.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:43:21 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:43:21 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:43:21 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:43:22 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:43:22 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:43:22 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:43:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:43:27 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:43:27 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:43:27 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:43:27 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:43:27 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:43:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:43:28 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:43:29 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:43:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:43:34 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:43:34 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 143.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:43:34 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:43:34 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:43:34 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:43:35 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:43:35 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:43:36 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:43:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:43:41 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:43:41 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 13.66 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 125.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:43:41 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:43:41 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:43:41 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:43:42 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:43:42 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:43:43 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:43:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:43:49 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.06 GiB is free. Including non-PyTorch memory, this process has 13.70 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 165.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:43:49 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.06 GiB is free. Including non-PyTorch memory, this process has 13.70 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 165.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.06 GiB is free. Including non-PyTorch memory, this process has 13.70 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 165.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:43:49 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:43:49 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 24/32
2025-12-12 14:43:49 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 14:43:49 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:43:49 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:43:49 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:43:49 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:43:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:43:50 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:43:51 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:43:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:43:59 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:43:59 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:43:59 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:43:59 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:43:59 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:44:00 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:44:00 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:44:01 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:44:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:44:11 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.16 GiB is free. Including non-PyTorch memory, this process has 13.60 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:44:11 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.16 GiB is free. Including non-PyTorch memory, this process has 13.60 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.16 GiB is free. Including non-PyTorch memory, this process has 13.60 GiB memory in use. Of the allocated memory 13.08 GiB is allocated by PyTorch, and 151.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:44:12 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:44:12 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:44:12 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:44:12 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:44:12 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:44:13 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:44:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:44:24 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:44:24 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:44:25 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:44:25 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:44:25 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:44:25 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:44:25 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:44:27 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:44:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:44:35 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:44:35 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:44:35 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:44:35 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:44:35 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:44:36 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:44:36 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:44:37 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:44:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:44:53 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:44:53 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:44:53 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:44:53 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 25/32
2025-12-12 14:44:53 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 14:44:53 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:44:53 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:44:53 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:44:53 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:44:53 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:44:53 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:44:55 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:44:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:44:59 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:44:59 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.17 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.83 GiB is free. Including non-PyTorch memory, this process has 13.93 GiB memory in use. Of the allocated memory 13.42 GiB is allocated by PyTorch, and 143.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:45:00 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:45:00 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:45:00 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:45:00 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:45:00 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:45:01 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:45:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:45:06 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:45:06 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:45:06 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:45:06 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:45:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:45:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:45:07 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:45:08 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:45:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:45:13 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.75 GiB is free. Including non-PyTorch memory, this process has 5.00 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 159.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:45:13 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.75 GiB is free. Including non-PyTorch memory, this process has 5.00 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 159.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.75 GiB is free. Including non-PyTorch memory, this process has 5.00 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 159.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:45:13 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:45:13 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:45:13 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:45:14 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:45:14 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:45:15 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:45:16 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:45:23 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:45:23 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.22 GiB is free. Including non-PyTorch memory, this process has 4.54 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 125.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:45:23 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:45:23 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:45:23 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:45:24 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:45:24 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:45:25 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:45:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:45:30 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:45:30 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:45:30 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:45:30 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 26/32
2025-12-12 14:45:30 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 14:45:30 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:45:30 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:45:30 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:45:30 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:45:31 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:45:31 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:45:32 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:45:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:45:57 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:45:57 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:45:57 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:45:57 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:45:57 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:45:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:45:58 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:45:58 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:45:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:46:09 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:46:09 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:46:09 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:46:09 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:46:09 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:46:10 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:46:10 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:46:11 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:46:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:46:21 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:46:21 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:46:22 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:46:22 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:46:22 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:46:22 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:46:22 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:46:24 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:46:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:46:37 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:46:37 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:46:37 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:46:37 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:46:37 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:46:38 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:46:38 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:46:39 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:46:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:46:47 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:46:47 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 9.93 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 153.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:46:47 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:46:47 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 27/32
2025-12-12 14:46:47 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 14:46:47 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:46:47 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:46:47 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:46:47 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:46:48 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:46:48 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:46:49 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:46:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:46:57 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:46:57 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.82 GiB is free. Including non-PyTorch memory, this process has 12.93 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 170.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:46:58 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:46:58 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:46:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:46:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:46:58 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:46:59 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:46:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:47:03 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:47:03 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:47:03 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:47:03 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:47:03 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:47:04 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:47:04 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:47:05 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:47:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:47:12 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:47:12 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:47:13 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:47:13 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:47:13 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:47:13 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:47:13 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:47:14 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:47:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:47:19 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:47:19 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 13.13 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 183.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:47:20 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:47:20 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:47:20 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:47:20 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:47:20 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:47:21 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:47:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:47:30 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.08 GiB is free. Including non-PyTorch memory, this process has 13.68 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 145.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:47:30 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.08 GiB is free. Including non-PyTorch memory, this process has 13.68 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 145.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.08 GiB is free. Including non-PyTorch memory, this process has 13.68 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 145.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:47:30 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:47:30 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 28/32
2025-12-12 14:47:30 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 14:47:30 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:47:30 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:47:30 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:47:30 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:47:31 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:47:31 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:47:32 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:47:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:47:41 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:47:41 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:47:41 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:47:41 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:47:41 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:47:42 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:47:42 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:47:42 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:47:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:47:52 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:47:52 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 13.44 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 128.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:47:52 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:47:52 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:47:52 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:47:53 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:47:53 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:47:54 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:47:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:48:06 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:48:06 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:48:06 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:48:06 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:48:06 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:48:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:48:07 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:48:08 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:48:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:48:15 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:48:15 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:48:16 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:48:16 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:48:16 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:48:16 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:48:16 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:48:17 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:48:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:48:26 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:48:26 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:48:26 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:48:26 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 29/32
2025-12-12 14:48:26 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 14:48:26 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:48:26 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:48:26 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:48:26 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:48:27 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:48:27 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:48:28 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:48:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:48:41 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:48:41 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:48:41 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:48:41 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:48:41 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:48:41 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:48:41 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:48:42 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:48:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:48:47 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:48:47 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:48:48 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:48:48 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:48:48 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:48:48 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:48:48 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:48:49 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:48:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:48:55 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:48:55 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:48:56 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:48:56 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:48:56 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:48:56 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:48:56 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:48:57 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:48:58 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:49:03 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:49:03 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.24 GiB is free. Including non-PyTorch memory, this process has 4.52 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 105.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:49:03 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:49:03 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:49:03 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:49:04 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:49:04 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:49:05 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:49:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:49:11 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:49:11 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.71 GiB is free. Including non-PyTorch memory, this process has 13.05 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 103.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:49:11 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:49:11 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 30/32
2025-12-12 14:49:11 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 14:49:11 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:49:11 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:49:11 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:49:11 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:49:11 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:49:11 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:49:13 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:49:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:49:36 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:49:36 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:49:36 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:49:36 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:49:36 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:49:37 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:49:37 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:49:37 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:49:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:49:46 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:49:46 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.89 GiB is free. Including non-PyTorch memory, this process has 9.87 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 93.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:49:46 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:49:46 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:49:46 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:49:47 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:49:47 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:49:48 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:49:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:49:56 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:49:56 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.30 GiB is free. Including non-PyTorch memory, this process has 13.46 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 148.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:49:57 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:49:57 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:49:57 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:49:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:49:57 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:49:58 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:49:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:50:08 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:50:08 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.87 GiB is free. Including non-PyTorch memory, this process has 9.89 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 113.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:50:08 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:50:08 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:50:08 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:50:09 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:50:09 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:50:10 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:50:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:50:24 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 209.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:50:24 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 209.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 209.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:50:24 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:50:24 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 31/32
2025-12-12 14:50:24 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 14:50:24 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:50:24 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:50:24 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:50:24 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:50:25 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:50:25 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:50:26 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:50:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:50:31 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 2
2025-12-12 14:50:31 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 13.07 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 123.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:50:31 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:50:31 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:50:31 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:50:32 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:50:32 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:50:32 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:50:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:50:39 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 2
2025-12-12 14:50:39 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:50:39 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:50:39 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:50:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:50:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:50:39 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:50:41 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:50:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:50:45 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 2
2025-12-12 14:50:45 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 12.89 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 130.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:50:46 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:50:46 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:50:46 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:50:46 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:50:46 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:50:47 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:50:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:50:56 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 2
2025-12-12 14:50:56 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.20 GiB is free. Including non-PyTorch memory, this process has 4.55 GiB memory in use. Of the allocated memory 4.05 GiB is allocated by PyTorch, and 145.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:50:56 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:50:56 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 14:50:56 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:50:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:50:57 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:50:58 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:50:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:51:02 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 2
2025-12-12 14:51:02 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 114, in forward
    out = self.conv2(out)
          ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.93 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 12.91 GiB memory in use. Of the allocated memory 12.40 GiB is allocated by PyTorch, and 150.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:51:03 [INFO] [lib.training.pipeline:796] 
================================================================================
2025-12-12 14:51:03 [INFO] [lib.training.pipeline:797] Grid Search: Hyperparameter combination 32/32
2025-12-12 14:51:03 [INFO] [lib.training.pipeline:798] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 14:51:03 [INFO] [lib.training.pipeline:799] ================================================================================
2025-12-12 14:51:03 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 14:51:03 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:51:03 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:51:03 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:51:03 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 1...
2025-12-12 14:51:05 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:51:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:51:16 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Batch size: 4
2025-12-12 14:51:16 [ERROR] [lib.training.pipeline:1507] Error training fold 1: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 13.48 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 168.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:51:16 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 14:51:16 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:51:16 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:51:17 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:51:17 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 2...
2025-12-12 14:51:18 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:51:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:51:29 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Batch size: 4
2025-12-12 14:51:29 [ERROR] [lib.training.pipeline:1507] Error training fold 2: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 252, in forward
    x = self.stem(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 7.81 GiB. GPU 0 has a total capacity of 15.77 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.41 GiB is allocated by PyTorch, and 133.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:51:29 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 14:51:29 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:51:29 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:51:29 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:51:29 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 3...
2025-12-12 14:51:31 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:51:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:51:38 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Batch size: 4
2025-12-12 14:51:38 [ERROR] [lib.training.pipeline:1507] Error training fold 3: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 13.50 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 188.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:51:39 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 14:51:39 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:51:39 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:51:39 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:51:39 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 4...
2025-12-12 14:51:40 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:51:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:51:48 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.33 GiB is free. Including non-PyTorch memory, this process has 13.42 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 108.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Batch size: 4
2025-12-12 14:51:48 [ERROR] [lib.training.pipeline:1507] Error training fold 4: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.33 GiB is free. Including non-PyTorch memory, this process has 13.42 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 108.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.33 GiB is free. Including non-PyTorch memory, this process has 13.42 GiB memory in use. Of the allocated memory 12.95 GiB is allocated by PyTorch, and 108.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:51:48 [INFO] [lib.training.pipeline:811] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 14:51:48 [INFO] [lib.training.pipeline:879] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 14:51:48 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:51:48 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:51:48 [INFO] [lib.training.pipeline:997] Training PyTorch model x3d on fold 5...
2025-12-12 14:51:50 [INFO] [lib.training.pipeline:1039] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 14:51:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:51:58 [ERROR] [lib.training.pipeline:1112] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 178.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Batch size: 4
2025-12-12 14:51:58 [ERROR] [lib.training.pipeline:1507] Error training fold 5: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 178.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1089, in stage5_train_models
    logger.error(
        ^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.68 GiB. GPU 0 has a total capacity of 15.77 GiB of which 2.67 GiB is free. Including non-PyTorch memory, this process has 13.09 GiB memory in use. Of the allocated memory 12.55 GiB is allocated by PyTorch, and 178.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:51:58 [INFO] [lib.training.pipeline:1566] ================================================================================
2025-12-12 14:51:58 [INFO] [lib.training.pipeline:1567] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-12 14:51:58 [INFO] [lib.training.pipeline:1568] ================================================================================
2025-12-12 14:51:58 [INFO] [lib.training.pipeline:1581] Final training: Using 5-fold stratified cross-validation on full dataset (3278 rows)
2025-12-12 14:51:58 [INFO] [lib.training.pipeline:1591] Final training using default hyperparameters (no grid search)
2025-12-12 14:51:58 [INFO] [lib.training.pipeline:1595] 
Final Training - x3d - Fold 1/5 (full dataset)
2025-12-12 14:51:58 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:51:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:51:59 [INFO] [lib.training.pipeline:1719] Training PyTorch model x3d on fold 1 (full dataset)...
2025-12-12 14:51:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:52:02 [ERROR] [lib.training.pipeline:1906] Error training final fold 1: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.59 GiB is free. Including non-PyTorch memory, this process has 4.16 GiB memory in use. Of the allocated memory 3.73 GiB is allocated by PyTorch, and 63.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1721, in stage5_train_models
    logger.warning(f"Failed to create MLflow tracker: {e}")
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.59 GiB is free. Including non-PyTorch memory, this process has 4.16 GiB memory in use. Of the allocated memory 3.73 GiB is allocated by PyTorch, and 63.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:52:02 [INFO] [lib.training.pipeline:1595] 
Final Training - x3d - Fold 2/5 (full dataset)
2025-12-12 14:52:02 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:52:03 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:52:03 [INFO] [lib.training.pipeline:1719] Training PyTorch model x3d on fold 2 (full dataset)...
2025-12-12 14:52:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:52:05 [ERROR] [lib.training.pipeline:1906] Error training final fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.13 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 42.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1721, in stage5_train_models
    logger.warning(f"Failed to create MLflow tracker: {e}")
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.13 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 42.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:52:05 [INFO] [lib.training.pipeline:1595] 
Final Training - x3d - Fold 3/5 (full dataset)
2025-12-12 14:52:05 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:52:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:52:06 [INFO] [lib.training.pipeline:1719] Training PyTorch model x3d on fold 3 (full dataset)...
2025-12-12 14:52:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:52:08 [ERROR] [lib.training.pipeline:1906] Error training final fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.13 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 42.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1721, in stage5_train_models
    logger.warning(f"Failed to create MLflow tracker: {e}")
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.13 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 42.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:52:08 [INFO] [lib.training.pipeline:1595] 
Final Training - x3d - Fold 4/5 (full dataset)
2025-12-12 14:52:08 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:52:09 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:52:09 [INFO] [lib.training.pipeline:1719] Training PyTorch model x3d on fold 4 (full dataset)...
2025-12-12 14:52:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:52:12 [ERROR] [lib.training.pipeline:1906] Error training final fold 4: CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 39.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1721, in stage5_train_models
    logger.warning(f"Failed to create MLflow tracker: {e}")
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 39.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:52:12 [INFO] [lib.training.pipeline:1595] 
Final Training - x3d - Fold 5/5 (full dataset)
2025-12-12 14:52:12 [WARNING] [lib.training.x3d:57] torchvision X3D not available. Using r3d_18 as approximation.
2025-12-12 14:52:12 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 21ace6e581584db78a7fe9b09e14ed09 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 14:52:12 [INFO] [lib.training.pipeline:1719] Training PyTorch model x3d on fold 5 (full dataset)...
2025-12-12 14:52:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 14:52:14 [ERROR] [lib.training.pipeline:1906] Error training final fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.13 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 42.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1721, in stage5_train_models
    logger.warning(f"Failed to create MLflow tracker: {e}")
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 341, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 81, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.13 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 42.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 14:52:14 [WARNING] [lib.training.pipeline:118] No model files found in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/fold_1 to copy
2025-12-12 14:52:14 [INFO] [lib.training.pipeline:1979] 
x3d - Avg Val Loss: nan, Avg Val Acc: nan, Avg Val F1: nan
2025-12-12 14:52:17 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/plots/cv_fold_comparison.png
2025-12-12 14:52:17 [INFO] [lib.training.pipeline:2007] Generated plots for x3d in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/plots
2025-12-12 14:52:17 [INFO] [lib.training.pipeline:2044] ================================================================================
2025-12-12 14:52:17 [INFO] [lib.training.pipeline:2045] Stage 5: Model Training Pipeline Completed
2025-12-12 14:52:17 [INFO] [lib.training.pipeline:2046] ================================================================================
2025-12-12 14:52:17 [INFO] [__main__:401] ================================================================================
2025-12-12 14:52:17 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-12 14:52:17 [INFO] [__main__:403] ================================================================================
2025-12-12 14:52:17 [INFO] [__main__:404] Execution time: 1779.98 seconds (29.67 minutes)
2025-12-12 14:52:17 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 14:52:17 [INFO] [__main__:407] Models trained: ['x3d']
2025-12-12 14:52:17 [INFO] [__main__:408] K-fold splits: 5
2025-12-12 14:52:17 [INFO] [__main__:414] ================================================================================
2025-12-12 14:52:17 [INFO] [__main__:415] Final memory statistics:
2025-12-12 14:52:17 [INFO] [__main__:416] ================================================================================
2025-12-12 14:52:17 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: after training): {'cpu_memory_mb': 6786.78515625, 'cpu_memory_gb': 6.627719879150391, 'cpu_vms_mb': 254156.875, 'gpu_allocated_gb': 0.00851968, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 14:52:17 [INFO] [__main__:419] ================================================================================
2025-12-12 14:52:17 [INFO] [__main__:420] Training complete!
2025-12-12 14:52:17 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 14:52:17 [INFO] [__main__:422] ================================================================================
