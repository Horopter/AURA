2025-12-12 19:25:52 [INFO] [__main__:310] ================================================================================
2025-12-12 19:25:52 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-12 19:25:52 [INFO] [__main__:312] ================================================================================
2025-12-12 19:25:52 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-12 19:25:52 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 19:25:52 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 19:25:52 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 19:25:52 [INFO] [__main__:317] Model types: ['slowfast']
2025-12-12 19:25:52 [INFO] [__main__:318] K-fold splits: 5
2025-12-12 19:25:52 [INFO] [__main__:319] Number of frames: 500
2025-12-12 19:25:52 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 19:25:52 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-12 19:25:52 [INFO] [__main__:324] Delete existing: False
2025-12-12 19:25:52 [INFO] [__main__:325] Resume mode: True
2025-12-12 19:25:52 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765585552.log
2025-12-12 19:25:52 [INFO] [__main__:333] ================================================================================
2025-12-12 19:25:52 [INFO] [__main__:334] Checking prerequisites...
2025-12-12 19:25:52 [INFO] [__main__:335] ================================================================================
2025-12-12 19:25:52 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 19:25:52 [INFO] [__main__:352] ✓ All model types are valid
2025-12-12 19:25:52 [INFO] [__main__:358] ================================================================================
2025-12-12 19:25:52 [INFO] [__main__:359] Initial memory statistics:
2025-12-12 19:25:52 [INFO] [__main__:360] ================================================================================
2025-12-12 19:25:52 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.57421875, 'cpu_memory_gb': 0.7183341979980469, 'cpu_vms_mb': 10218.5625, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-12 19:25:52 [INFO] [__main__:364] ================================================================================
2025-12-12 19:25:52 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-12 19:25:52 [INFO] [__main__:366] ================================================================================
2025-12-12 19:25:52 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-12 19:25:52 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-12 19:25:52 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-12 19:25:52 [INFO] [__main__:370] ================================================================================
2025-12-12 19:25:52 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-12 19:25:52 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:490] ================================================================================
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:491] Stage 5: Model Training Pipeline Started
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:492] ================================================================================
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:493] Model types: ['slowfast']
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:494] K-fold splits: 5
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:495] Frames per video: 500
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:496] Output directory: data/stage5
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:497] Initializing pipeline...
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:265] ================================================================================
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:266] STAGE 5 PREREQUISITE VALIDATION
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:267] ================================================================================
2025-12-12 19:25:52 [INFO] [lib.training.pipeline:270] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:279] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:280]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:283] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:291] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:292]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:295] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:303] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:304]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:307] 
================================================================================
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:308] MODEL REQUIREMENTS CHECK
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:309] ================================================================================
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:333] ✓ slowfast: CAN RUN
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:336] 
================================================================================
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:337] VALIDATION SUMMARY
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:338] ================================================================================
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:339] Stage 3 (scaled videos): ✓ Available
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:340]   Count: 3278 videos
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:341] Stage 2 (features): ✓ Available
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:342]   Count: 3278 feature rows
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:343] Stage 4 (scaled features): ✓ Available
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:344]   Count: 3277 feature rows
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:345] 
Runnable models: 1/1
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:346]   ['slowfast']
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:353] ================================================================================
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:583] 
Stage 5: Loading metadata...
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:609] Loaded metadata: 3278 rows
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:619] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-12 19:25:53 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=833740.14GB, used=1666099.86GB (66.6%)
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:651] Stage 5: Found 3278 scaled videos
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:747] 
================================================================================
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:748] Stage 5: Training model: slowfast
2025-12-12 19:25:53 [INFO] [lib.training.pipeline:749] ================================================================================
2025-12-12 19:25:55 [INFO] [lib.training.pipeline:773] Grid search: 32 hyperparameter combinations to try
2025-12-12 19:25:55 [INFO] [lib.training.pipeline:781] ================================================================================
2025-12-12 19:25:55 [INFO] [lib.training.pipeline:782] HYPERPARAMETER SEARCH: Using 20% stratified sample for efficiency
2025-12-12 19:25:55 [INFO] [lib.training.pipeline:783] ================================================================================
2025-12-12 19:25:55 [INFO] [lib.training.pipeline:792] Hyperparameter search sample: 655 rows (20.0% of 3278 total)
2025-12-12 19:25:57 [INFO] [lib.training.pipeline:805] Using 5-fold stratified cross-validation on 20% sample for hyperparameter search
2025-12-12 19:25:57 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:25:57 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 1/32
2025-12-12 19:25:57 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 19:25:57 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:25:57 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:25:57 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:25:57 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:25:57 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:25:58 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:25:58 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:26:46 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:26:46 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:26:51 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:26:58 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 58ba5971af0b4012898211e067b2990a (experiment: slowfast)
2025-12-12 19:26:58 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:27:01 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:01 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:01 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 58ba5971af0b4012898211e067b2990a
2025-12-12 19:27:01 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:27:01 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:27:01 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:01 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:01 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:01 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:01 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:01 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:04 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:04 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 923c3a7695f74402b69476f2aed8639d (experiment: slowfast)
2025-12-12 19:27:04 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:27:05 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:05 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:05 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 923c3a7695f74402b69476f2aed8639d
2025-12-12 19:27:05 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:27:05 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:27:05 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:05 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:06 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:06 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:06 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:06 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:08 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:08 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7f7df0945ca2472985b06c0662f1b4ea (experiment: slowfast)
2025-12-12 19:27:08 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:27:10 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:10 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:10 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7f7df0945ca2472985b06c0662f1b4ea
2025-12-12 19:27:10 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:27:10 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:27:10 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:10 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:10 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:10 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:10 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:11 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:13 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:13 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e504807c126a4a73ba000dd9b7524e99 (experiment: slowfast)
2025-12-12 19:27:13 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:27:15 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:15 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:15 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e504807c126a4a73ba000dd9b7524e99
2025-12-12 19:27:15 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:27:15 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:27:15 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:15 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:15 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:15 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:15 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:15 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:18 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:18 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 741a6432ca0e471fbea56a5a596c400f (experiment: slowfast)
2025-12-12 19:27:18 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:27:20 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:20 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:20 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 741a6432ca0e471fbea56a5a596c400f
2025-12-12 19:27:20 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:27:20 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 2/32
2025-12-12 19:27:20 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 19:27:20 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:27:20 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:27:20 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:27:20 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:20 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:20 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:20 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:20 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:20 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:23 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:23 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2f1ac0735b6a4e3f94ab37f64c048a00 (experiment: slowfast)
2025-12-12 19:27:23 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:27:24 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:24 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:25 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2f1ac0735b6a4e3f94ab37f64c048a00
2025-12-12 19:27:25 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:27:25 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:27:25 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:25 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:25 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:25 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:25 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:25 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:28 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:28 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c66277ffd7464100b92f0c77126d675d (experiment: slowfast)
2025-12-12 19:27:28 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:27:29 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:29 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:29 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c66277ffd7464100b92f0c77126d675d
2025-12-12 19:27:29 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:27:29 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:27:29 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:29 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:29 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:29 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:29 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:29 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:32 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:32 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 93ce4190afc641e19fcf75596f7fd21e (experiment: slowfast)
2025-12-12 19:27:32 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:27:34 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:34 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:34 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 93ce4190afc641e19fcf75596f7fd21e
2025-12-12 19:27:34 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:27:34 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:27:34 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:34 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:34 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:34 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:34 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:34 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:37 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:37 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: fb6d08e7d5264390a6f56dcea238dc0b (experiment: slowfast)
2025-12-12 19:27:37 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:27:39 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:39 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:39 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: fb6d08e7d5264390a6f56dcea238dc0b
2025-12-12 19:27:39 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:27:39 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:27:39 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:39 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:39 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:39 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:39 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:39 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:42 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:42 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 273ace3056714cf7bfb9d798f532d2e8 (experiment: slowfast)
2025-12-12 19:27:42 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:27:44 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:44 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:44 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 273ace3056714cf7bfb9d798f532d2e8
2025-12-12 19:27:44 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:27:44 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 3/32
2025-12-12 19:27:44 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 19:27:44 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:27:44 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:27:44 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:27:44 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:44 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:44 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:44 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:44 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:44 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:47 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:47 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7acbf360943e4189b693f37c69b337c1 (experiment: slowfast)
2025-12-12 19:27:47 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:27:48 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:48 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:48 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7acbf360943e4189b693f37c69b337c1
2025-12-12 19:27:49 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:27:49 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:27:49 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:49 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:49 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:49 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:49 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:49 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:51 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:52 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e1af460cf3784003b1eb8c55fbcc9c68 (experiment: slowfast)
2025-12-12 19:27:52 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:27:53 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:53 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:53 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e1af460cf3784003b1eb8c55fbcc9c68
2025-12-12 19:27:53 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:27:53 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:27:53 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:53 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:53 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:53 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:53 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:53 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:56 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:27:56 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 6993b3e41e494379ae4c41a0e59cd8d3 (experiment: slowfast)
2025-12-12 19:27:56 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:27:57 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:57 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:27:57 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 6993b3e41e494379ae4c41a0e59cd8d3
2025-12-12 19:27:58 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:27:58 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:27:58 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:27:58 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:27:58 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:27:58 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:27:58 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:27:58 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:00 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 49ea59adb2aa41eeabda09e08c5ae1c1 (experiment: slowfast)
2025-12-12 19:28:01 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:28:02 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:02 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:02 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 49ea59adb2aa41eeabda09e08c5ae1c1
2025-12-12 19:28:03 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:28:03 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:28:03 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:03 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:03 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:03 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:03 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:03 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:05 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:05 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5f06115ab8bc4fad9dcd1c436b0b6986 (experiment: slowfast)
2025-12-12 19:28:05 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:28:07 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:07 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:07 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5f06115ab8bc4fad9dcd1c436b0b6986
2025-12-12 19:28:07 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:28:07 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 4/32
2025-12-12 19:28:07 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 19:28:07 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:28:07 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:28:07 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:28:07 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:07 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:07 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:07 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:07 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:08 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:10 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:10 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: cf3d460b6d5f4bae9ab4512fefd05ae6 (experiment: slowfast)
2025-12-12 19:28:10 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:28:12 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:12 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:12 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: cf3d460b6d5f4bae9ab4512fefd05ae6
2025-12-12 19:28:12 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:28:12 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:28:12 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:12 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:12 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:12 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:12 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:12 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:15 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:15 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: cde5918935b445baba5bb06f743c4f25 (experiment: slowfast)
2025-12-12 19:28:15 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:28:16 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:16 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:16 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: cde5918935b445baba5bb06f743c4f25
2025-12-12 19:28:16 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:28:16 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:28:16 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:16 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:17 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:17 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:17 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:17 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:19 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8182fec9c1a84a5f8b837e8e9db9c522 (experiment: slowfast)
2025-12-12 19:28:19 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:28:21 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:21 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:21 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8182fec9c1a84a5f8b837e8e9db9c522
2025-12-12 19:28:21 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:28:21 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:28:21 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:21 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:21 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:21 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:21 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:22 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:24 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:24 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 71136e63cf1d4645aad60fdac316a1bd (experiment: slowfast)
2025-12-12 19:28:24 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:28:26 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:26 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:26 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 71136e63cf1d4645aad60fdac316a1bd
2025-12-12 19:28:26 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:28:26 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:28:26 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:26 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:26 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:26 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:26 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:27 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:29 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:29 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 24609221bbe24659917ac736acc83f40 (experiment: slowfast)
2025-12-12 19:28:29 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:28:31 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:31 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:31 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 24609221bbe24659917ac736acc83f40
2025-12-12 19:28:31 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:28:31 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 5/32
2025-12-12 19:28:31 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 19:28:31 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:28:31 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:28:31 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:28:31 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:31 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:31 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:31 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:31 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:31 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:34 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:34 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e8cace10132548adbc07c1fff984d8d0 (experiment: slowfast)
2025-12-12 19:28:34 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:28:36 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:36 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:36 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e8cace10132548adbc07c1fff984d8d0
2025-12-12 19:28:36 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:28:36 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:28:36 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:36 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:36 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:36 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:36 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:36 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:38 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:39 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 42fd88822ead4a06bfd1c9f81fa049fd (experiment: slowfast)
2025-12-12 19:28:39 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:28:40 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:40 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:40 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 42fd88822ead4a06bfd1c9f81fa049fd
2025-12-12 19:28:40 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:28:40 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:28:40 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:40 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:40 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:40 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:40 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:40 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:43 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:43 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: b23f6465e1af441d83d47f0103c76a8f (experiment: slowfast)
2025-12-12 19:28:43 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:28:45 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:45 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:45 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: b23f6465e1af441d83d47f0103c76a8f
2025-12-12 19:28:45 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:28:45 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:28:45 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:45 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:45 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:45 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:48 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:48 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 69e5603467fc4710ab8cdaacec78d45b (experiment: slowfast)
2025-12-12 19:28:48 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:28:49 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:49 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:49 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 69e5603467fc4710ab8cdaacec78d45b
2025-12-12 19:28:50 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:28:50 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:28:50 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:50 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:50 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:50 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:50 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:50 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:52 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:53 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 499d0a9cb9504a37a553875de850f5fb (experiment: slowfast)
2025-12-12 19:28:53 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:28:54 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:54 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:54 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 499d0a9cb9504a37a553875de850f5fb
2025-12-12 19:28:55 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:28:55 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 6/32
2025-12-12 19:28:55 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 19:28:55 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:28:55 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:28:55 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:28:55 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:55 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:28:55 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:28:55 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:28:55 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:28:55 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:57 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:28:57 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e756006580ce4632ab3b0fa93421622c (experiment: slowfast)
2025-12-12 19:28:57 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:28:59 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:59 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:28:59 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e756006580ce4632ab3b0fa93421622c
2025-12-12 19:28:59 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:28:59 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:28:59 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:28:59 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:00 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:00 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:00 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:00 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:02 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:03 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1d51999d345246699343188631a37e93 (experiment: slowfast)
2025-12-12 19:29:03 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:29:04 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:04 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:04 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1d51999d345246699343188631a37e93
2025-12-12 19:29:04 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:29:04 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:29:04 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:04 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:04 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:04 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:04 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:04 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:07 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 81cd9d994e3e4e15838d191add387290 (experiment: slowfast)
2025-12-12 19:29:07 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:29:08 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:08 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:08 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 81cd9d994e3e4e15838d191add387290
2025-12-12 19:29:09 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:29:09 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:29:09 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:09 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:09 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:09 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:09 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:09 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:11 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:12 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9330c6b45aa441b8b35be333814e84ea (experiment: slowfast)
2025-12-12 19:29:12 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:29:13 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:13 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:13 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9330c6b45aa441b8b35be333814e84ea
2025-12-12 19:29:14 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:29:14 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:29:14 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:14 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:14 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:14 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:14 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:14 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:16 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:17 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5ead59c3b63d45c498a199479fa1f562 (experiment: slowfast)
2025-12-12 19:29:17 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:29:18 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:18 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:18 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5ead59c3b63d45c498a199479fa1f562
2025-12-12 19:29:19 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:29:19 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 7/32
2025-12-12 19:29:19 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 19:29:19 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:29:19 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:29:19 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:29:19 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:19 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:19 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:19 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:19 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:19 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:21 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:21 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 567d8274cc6145dc857ef3f5e15e407a (experiment: slowfast)
2025-12-12 19:29:21 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:29:23 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:23 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:23 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 567d8274cc6145dc857ef3f5e15e407a
2025-12-12 19:29:23 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:29:23 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:29:23 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:23 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:23 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:24 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:26 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:26 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 78772c77d0b5479b943b20ee96366125 (experiment: slowfast)
2025-12-12 19:29:26 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:29:27 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:27 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:27 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 78772c77d0b5479b943b20ee96366125
2025-12-12 19:29:28 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:29:28 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:29:28 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:28 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:28 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:28 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:28 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:28 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:30 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:30 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e67fc141ced74ebc8bbadc5bf5323fc1 (experiment: slowfast)
2025-12-12 19:29:30 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:29:32 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:32 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:32 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e67fc141ced74ebc8bbadc5bf5323fc1
2025-12-12 19:29:32 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:29:32 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:29:32 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:32 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:33 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:33 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:33 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:33 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:35 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:35 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ae379486591b44688083577350426add (experiment: slowfast)
2025-12-12 19:29:35 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:29:37 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:37 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: ae379486591b44688083577350426add
2025-12-12 19:29:37 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:29:37 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:29:37 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:37 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:37 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:37 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:37 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:37 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:40 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:40 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a3ed097cd3d7432ca7025336b8a459c7 (experiment: slowfast)
2025-12-12 19:29:40 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:29:42 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:42 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:42 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a3ed097cd3d7432ca7025336b8a459c7
2025-12-12 19:29:42 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:29:42 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 8/32
2025-12-12 19:29:42 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 19:29:42 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:29:42 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:29:42 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:29:42 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:42 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:42 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:42 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:42 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:42 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:45 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:45 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: cfbc244752be4dedb6e37924d565467d (experiment: slowfast)
2025-12-12 19:29:45 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:29:46 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:46 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:46 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: cfbc244752be4dedb6e37924d565467d
2025-12-12 19:29:47 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:29:47 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:29:47 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:47 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:47 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:47 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:47 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:47 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:49 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: cce696e671074839a1e4125ca2366119 (experiment: slowfast)
2025-12-12 19:29:50 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:29:51 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:51 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:51 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: cce696e671074839a1e4125ca2366119
2025-12-12 19:29:51 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:29:51 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:29:51 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:51 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:51 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:51 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:51 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:51 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:54 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8843e67648f7456ea6e169654cec50d7 (experiment: slowfast)
2025-12-12 19:29:54 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:29:55 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:55 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:29:55 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8843e67648f7456ea6e169654cec50d7
2025-12-12 19:29:56 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:29:56 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:29:56 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:29:56 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:29:56 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:29:56 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:29:56 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:29:56 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:58 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:29:59 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: aa9c3a5dd0e5488598abd673f34105c6 (experiment: slowfast)
2025-12-12 19:29:59 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:30:00 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:00 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:00 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: aa9c3a5dd0e5488598abd673f34105c6
2025-12-12 19:30:01 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:30:01 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:30:01 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:01 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:01 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:01 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:01 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:01 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:03 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:04 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: df71416085c8460f8805179260b9cbdc (experiment: slowfast)
2025-12-12 19:30:04 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:30:05 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:05 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:05 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: df71416085c8460f8805179260b9cbdc
2025-12-12 19:30:06 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:30:06 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 9/32
2025-12-12 19:30:06 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 19:30:06 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:30:06 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:30:06 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:30:06 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:06 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:06 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:06 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:06 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:06 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:08 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:08 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 288aab5b7b3f455bb0c89e26309e1a0b (experiment: slowfast)
2025-12-12 19:30:08 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:30:10 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:10 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:10 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 288aab5b7b3f455bb0c89e26309e1a0b
2025-12-12 19:30:10 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:30:10 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:30:10 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:10 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:11 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:11 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:11 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:11 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:13 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:13 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 3d5b8f9ef1f7485984855d72a9f4ae69 (experiment: slowfast)
2025-12-12 19:30:13 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:30:14 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:14 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:14 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 3d5b8f9ef1f7485984855d72a9f4ae69
2025-12-12 19:30:15 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:30:15 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:30:15 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:15 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:15 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:15 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:15 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:15 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:17 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:17 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 55df296b55aa432a8b7aa009766eb277 (experiment: slowfast)
2025-12-12 19:30:17 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:30:19 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:19 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:19 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 55df296b55aa432a8b7aa009766eb277
2025-12-12 19:30:19 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:30:19 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:30:19 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:19 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:20 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:20 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:20 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:20 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:22 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:22 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 70ee5f3295604eb3b05446f903d298ed (experiment: slowfast)
2025-12-12 19:30:22 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:30:24 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:24 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:24 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 70ee5f3295604eb3b05446f903d298ed
2025-12-12 19:30:24 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:30:24 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:30:24 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:24 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:24 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:24 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:27 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:27 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f0c3957d44824f6b99e788717200ae21 (experiment: slowfast)
2025-12-12 19:30:27 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:30:29 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:29 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:29 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f0c3957d44824f6b99e788717200ae21
2025-12-12 19:30:29 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:30:29 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 10/32
2025-12-12 19:30:29 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 19:30:29 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:30:29 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:30:29 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:30:29 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:29 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:29 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:29 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:29 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:29 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:32 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:32 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 66435adce7d344a0b9e1656d48cb92cb (experiment: slowfast)
2025-12-12 19:30:32 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:30:33 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:33 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:33 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 66435adce7d344a0b9e1656d48cb92cb
2025-12-12 19:30:34 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:30:34 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:30:34 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:34 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:34 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:34 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:34 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:34 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:36 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:37 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4f16c9d31ebb4eb7a743e25b7e61831d (experiment: slowfast)
2025-12-12 19:30:37 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:30:38 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:38 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:38 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4f16c9d31ebb4eb7a743e25b7e61831d
2025-12-12 19:30:38 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:30:38 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:30:38 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:38 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:38 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:38 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:38 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:38 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:41 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:41 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5827d5c8d7054c7aadfedd244211b818 (experiment: slowfast)
2025-12-12 19:30:41 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:30:42 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:42 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:42 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5827d5c8d7054c7aadfedd244211b818
2025-12-12 19:30:43 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:30:43 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:30:43 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:43 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:43 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:43 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:43 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:43 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:45 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:46 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4104e81c4dc54c75affa0b05a09a843a (experiment: slowfast)
2025-12-12 19:30:46 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:30:47 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:47 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:47 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4104e81c4dc54c75affa0b05a09a843a
2025-12-12 19:30:48 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:30:48 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:30:48 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:48 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:48 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:48 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:48 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:48 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:50 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:51 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: fbe3ef187bed46d9bfc07f2bc819af3c (experiment: slowfast)
2025-12-12 19:30:51 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:30:52 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:52 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:52 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: fbe3ef187bed46d9bfc07f2bc819af3c
2025-12-12 19:30:53 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:30:53 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 11/32
2025-12-12 19:30:53 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 19:30:53 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:30:53 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:30:53 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:30:53 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:53 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:53 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:53 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:53 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:53 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:55 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:30:55 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7b8257f039db4672b89b33a17147950d (experiment: slowfast)
2025-12-12 19:30:55 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:30:57 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:57 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:30:57 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7b8257f039db4672b89b33a17147950d
2025-12-12 19:30:57 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:30:57 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:30:57 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:30:57 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:30:58 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:30:58 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:30:58 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:30:58 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:00 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4271e42551c8419fbc5b3f40071d9b71 (experiment: slowfast)
2025-12-12 19:31:00 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:31:01 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:01 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:01 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4271e42551c8419fbc5b3f40071d9b71
2025-12-12 19:31:02 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:31:02 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:31:02 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:02 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:02 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:02 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:02 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:02 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:05 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:05 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5f398e418a2d48d6be8d0b6ebc078c43 (experiment: slowfast)
2025-12-12 19:31:05 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:31:06 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:06 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:06 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5f398e418a2d48d6be8d0b6ebc078c43
2025-12-12 19:31:07 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:31:07 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:31:07 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:07 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:07 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:07 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:07 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:07 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:09 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:09 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f5a3cb42d6974b28be0c74f95710bafc (experiment: slowfast)
2025-12-12 19:31:09 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:31:11 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:11 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:11 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f5a3cb42d6974b28be0c74f95710bafc
2025-12-12 19:31:12 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:31:12 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:31:12 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:12 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:12 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:12 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:12 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:12 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:14 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:14 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c12aed9ede6e4ff89cfb92b3475db0f7 (experiment: slowfast)
2025-12-12 19:31:14 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:31:16 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:16 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:16 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c12aed9ede6e4ff89cfb92b3475db0f7
2025-12-12 19:31:16 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:31:16 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 12/32
2025-12-12 19:31:16 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 19:31:16 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:31:16 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:31:16 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:31:16 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:16 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:16 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:16 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:16 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:16 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:19 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a8ab8c37fa534c3ea6254237d1496ea0 (experiment: slowfast)
2025-12-12 19:31:19 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:31:21 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:21 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:21 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a8ab8c37fa534c3ea6254237d1496ea0
2025-12-12 19:31:21 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:31:21 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:31:21 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:21 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:21 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:21 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:21 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:21 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:24 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:24 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8e8d01a5d16240d6b5f1384041ab311b (experiment: slowfast)
2025-12-12 19:31:24 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:31:25 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:25 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:25 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8e8d01a5d16240d6b5f1384041ab311b
2025-12-12 19:31:25 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:31:25 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:31:25 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:25 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:25 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:25 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:25 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:25 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:28 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:28 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c598da8d3b0341cfa47e9e2bdb9bfc47 (experiment: slowfast)
2025-12-12 19:31:28 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:31:30 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:30 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:30 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c598da8d3b0341cfa47e9e2bdb9bfc47
2025-12-12 19:31:30 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:31:30 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:31:30 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:30 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:30 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:30 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:30 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:30 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:33 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:33 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c21ba741779a41d48871290f93476274 (experiment: slowfast)
2025-12-12 19:31:33 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:31:35 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:35 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:35 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c21ba741779a41d48871290f93476274
2025-12-12 19:31:35 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:31:35 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:31:35 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:35 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:35 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:35 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:35 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:35 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:38 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a268166bcf7c4e9fa587bca226d7b1ba (experiment: slowfast)
2025-12-12 19:31:38 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:31:39 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:39 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:39 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a268166bcf7c4e9fa587bca226d7b1ba
2025-12-12 19:31:40 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:31:40 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 13/32
2025-12-12 19:31:40 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 19:31:40 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:31:40 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:31:40 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:31:40 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:40 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:40 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:40 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:40 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:40 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:42 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:43 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9a9264ca00394a72a439cabb6778844e (experiment: slowfast)
2025-12-12 19:31:43 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:31:44 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:44 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:44 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9a9264ca00394a72a439cabb6778844e
2025-12-12 19:31:45 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:31:45 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:31:45 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:45 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:45 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:45 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:47 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:47 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d3ba6663dea34de8b835877c8cc8cd5f (experiment: slowfast)
2025-12-12 19:31:47 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:31:48 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:48 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:48 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: d3ba6663dea34de8b835877c8cc8cd5f
2025-12-12 19:31:49 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:31:49 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:31:49 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:49 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:49 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:49 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:49 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:49 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:51 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:52 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5a3ba938d45b4f74b4b81c72b1c75907 (experiment: slowfast)
2025-12-12 19:31:52 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:31:53 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:53 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:53 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5a3ba938d45b4f74b4b81c72b1c75907
2025-12-12 19:31:54 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:31:54 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:31:54 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:54 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:54 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:54 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:54 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:54 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:56 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:31:56 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 02326bcb0a4b41ae827248fa887f7d1f (experiment: slowfast)
2025-12-12 19:31:56 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:31:58 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:58 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:31:58 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 02326bcb0a4b41ae827248fa887f7d1f
2025-12-12 19:31:58 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:31:58 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:31:58 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:31:58 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:31:58 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:31:58 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:31:58 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:31:58 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:01 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4c96a70b8df14dc3be77cfc395a17466 (experiment: slowfast)
2025-12-12 19:32:01 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:32:03 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:03 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:03 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4c96a70b8df14dc3be77cfc395a17466
2025-12-12 19:32:03 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:32:03 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 14/32
2025-12-12 19:32:03 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 19:32:03 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:32:03 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:32:03 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:32:03 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:03 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:04 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:04 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:04 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:04 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:06 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:06 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d85d7cb5b97e45278f0e663401b25d1e (experiment: slowfast)
2025-12-12 19:32:06 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:32:08 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:08 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:08 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: d85d7cb5b97e45278f0e663401b25d1e
2025-12-12 19:32:08 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:32:08 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:32:08 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:08 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:08 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:08 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:08 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:08 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:11 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:11 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 3772bd64223f4c5992ea5ad609013a34 (experiment: slowfast)
2025-12-12 19:32:11 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:32:12 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:12 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:12 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 3772bd64223f4c5992ea5ad609013a34
2025-12-12 19:32:13 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:32:13 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:32:13 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:13 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:13 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:13 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:13 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:13 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:15 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:15 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 90927cdb502f4b94bc55984cbce0c4ea (experiment: slowfast)
2025-12-12 19:32:15 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:32:17 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:17 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:17 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 90927cdb502f4b94bc55984cbce0c4ea
2025-12-12 19:32:17 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:32:17 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:32:17 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:17 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:17 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:17 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:17 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:18 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:20 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:20 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d664f8ad7e724aa4b16c60244dd5a4eb (experiment: slowfast)
2025-12-12 19:32:20 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:32:22 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:22 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:22 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: d664f8ad7e724aa4b16c60244dd5a4eb
2025-12-12 19:32:22 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:32:22 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:32:22 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:22 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:22 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:22 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:22 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:22 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:25 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:25 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4388dd9d0d2a4b29994e9474f71023ae (experiment: slowfast)
2025-12-12 19:32:25 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:32:27 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:27 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:27 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4388dd9d0d2a4b29994e9474f71023ae
2025-12-12 19:32:27 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:32:27 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 15/32
2025-12-12 19:32:27 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 19:32:27 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:32:27 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:32:27 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:32:27 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:27 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:27 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:27 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:27 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:27 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:30 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:30 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: efe81183f17542e9bc2b951154100c1a (experiment: slowfast)
2025-12-12 19:32:30 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:32:31 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:31 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:31 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: efe81183f17542e9bc2b951154100c1a
2025-12-12 19:32:32 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:32:32 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:32:32 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:32 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:32 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:32 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:32 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:32 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:34 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:35 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 13bc4e41f23c4fc6907408365797ea05 (experiment: slowfast)
2025-12-12 19:32:35 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:32:36 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:36 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:36 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 13bc4e41f23c4fc6907408365797ea05
2025-12-12 19:32:36 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:32:36 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:32:36 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:36 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:36 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:36 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:36 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:36 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:39 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:39 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e11c1f2694874cd2bce1460d0b87a360 (experiment: slowfast)
2025-12-12 19:32:39 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:32:40 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:40 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:40 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e11c1f2694874cd2bce1460d0b87a360
2025-12-12 19:32:41 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:32:41 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:32:41 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:41 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:41 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:41 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:41 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:41 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:43 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:44 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4f24916cb8b944e5b4e2bf0f6b241090 (experiment: slowfast)
2025-12-12 19:32:44 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:32:45 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:45 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:45 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4f24916cb8b944e5b4e2bf0f6b241090
2025-12-12 19:32:46 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:32:46 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:32:46 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:46 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:46 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:46 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:46 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:46 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:48 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:48 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: dc53cc1a6037460ab2bf271cde8aced2 (experiment: slowfast)
2025-12-12 19:32:48 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:32:50 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:50 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:50 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: dc53cc1a6037460ab2bf271cde8aced2
2025-12-12 19:32:50 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:32:50 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 16/32
2025-12-12 19:32:50 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 19:32:50 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:32:50 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:32:50 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:32:50 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:50 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:51 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:51 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:51 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:51 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:53 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:53 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d2af4e80ed4d43eb880c0d4c74a13c51 (experiment: slowfast)
2025-12-12 19:32:53 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:32:55 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:55 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:55 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: d2af4e80ed4d43eb880c0d4c74a13c51
2025-12-12 19:32:55 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:32:55 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:32:55 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:55 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:32:55 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:32:55 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:32:55 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:32:55 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:58 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:32:58 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a0bd3fd10e9c4da39a8ffa5d5a0bc021 (experiment: slowfast)
2025-12-12 19:32:58 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:32:59 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:59 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:32:59 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a0bd3fd10e9c4da39a8ffa5d5a0bc021
2025-12-12 19:32:59 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:32:59 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:32:59 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:32:59 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:00 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:00 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:00 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:00 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:02 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:02 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: db259c29bacc40e2a495ca5f7b95bc8e (experiment: slowfast)
2025-12-12 19:33:02 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:33:04 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:04 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:04 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: db259c29bacc40e2a495ca5f7b95bc8e
2025-12-12 19:33:04 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:33:04 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:33:04 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:04 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:05 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:05 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:05 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:05 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:07 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 72bf8c2805854e209176e84e618eda5b (experiment: slowfast)
2025-12-12 19:33:07 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:33:09 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:09 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:09 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 72bf8c2805854e209176e84e618eda5b
2025-12-12 19:33:10 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:33:10 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:33:10 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:10 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:10 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:10 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:10 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:10 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:12 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:12 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a6b201b8bf7e42fcaf774ddef9c83363 (experiment: slowfast)
2025-12-12 19:33:12 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:33:14 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:14 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:14 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a6b201b8bf7e42fcaf774ddef9c83363
2025-12-12 19:33:14 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:33:14 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 17/32
2025-12-12 19:33:14 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 19:33:14 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:33:14 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:33:14 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:33:14 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:14 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:15 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:15 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:15 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:15 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:17 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:17 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 088bc7bd483049d08407660d74db563b (experiment: slowfast)
2025-12-12 19:33:17 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:33:19 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:19 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:19 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 088bc7bd483049d08407660d74db563b
2025-12-12 19:33:19 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:33:19 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:33:19 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:19 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:19 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:19 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:19 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:20 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:22 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:22 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7b91047d6ed346a6bfaea2c5c0285ffe (experiment: slowfast)
2025-12-12 19:33:22 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:33:23 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:23 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:23 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7b91047d6ed346a6bfaea2c5c0285ffe
2025-12-12 19:33:23 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:33:23 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:33:23 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:23 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:24 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:24 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:26 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:26 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f06b6766f28f40e3ae80e79750d2a5e6 (experiment: slowfast)
2025-12-12 19:33:26 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:33:28 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:28 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:28 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f06b6766f28f40e3ae80e79750d2a5e6
2025-12-12 19:33:28 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:33:28 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:33:28 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:28 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:28 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:28 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:28 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:28 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:31 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:31 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 47bb3fe6f79d44288e205f0421c1400c (experiment: slowfast)
2025-12-12 19:33:31 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:33:33 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:33 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:33 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 47bb3fe6f79d44288e205f0421c1400c
2025-12-12 19:33:33 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:33:33 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:33:33 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:33 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:33 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:33 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:33 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:33 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:36 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:36 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ba9ee1c45ba64cf3a325c7f6f82b84fe (experiment: slowfast)
2025-12-12 19:33:36 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:33:37 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:37 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: ba9ee1c45ba64cf3a325c7f6f82b84fe
2025-12-12 19:33:38 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:33:38 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 18/32
2025-12-12 19:33:38 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 19:33:38 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:33:38 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:33:38 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:33:38 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:38 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:38 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:38 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:38 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:38 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:40 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:41 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5a01122fc5ff447f9d6e44dda5857ac5 (experiment: slowfast)
2025-12-12 19:33:41 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:33:42 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:42 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:42 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5a01122fc5ff447f9d6e44dda5857ac5
2025-12-12 19:33:43 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:33:43 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:33:43 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:43 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:43 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:43 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:43 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:43 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:45 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:46 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7950bd0c330744adbd908080024ceb93 (experiment: slowfast)
2025-12-12 19:33:46 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:33:47 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:47 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:47 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7950bd0c330744adbd908080024ceb93
2025-12-12 19:33:47 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:33:47 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:33:47 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:47 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:47 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:47 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:47 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:47 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:50 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a7559fed252f4805a36c0bb16ed2b9ef (experiment: slowfast)
2025-12-12 19:33:50 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:33:51 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:51 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:51 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a7559fed252f4805a36c0bb16ed2b9ef
2025-12-12 19:33:52 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:33:52 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:33:52 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:52 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:52 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:52 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:52 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:52 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:54 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:55 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0c9ea78740224adaa5ef6af015344d7a (experiment: slowfast)
2025-12-12 19:33:55 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:33:56 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:56 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:33:57 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0c9ea78740224adaa5ef6af015344d7a
2025-12-12 19:33:57 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:33:57 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:33:57 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:33:57 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:33:57 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:33:57 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:33:57 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:33:57 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:33:59 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2f6ad9f51bcb44599f88eb8694fc7fad (experiment: slowfast)
2025-12-12 19:34:00 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:34:01 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:01 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:01 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2f6ad9f51bcb44599f88eb8694fc7fad
2025-12-12 19:34:02 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:34:02 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 19/32
2025-12-12 19:34:02 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 19:34:02 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:34:02 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:34:02 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:34:02 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:02 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:02 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:02 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:02 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:02 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:04 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:04 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 59c28981e2464737990c6c7ade54c3c0 (experiment: slowfast)
2025-12-12 19:34:04 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:34:06 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:06 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:06 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 59c28981e2464737990c6c7ade54c3c0
2025-12-12 19:34:06 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:34:06 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:34:06 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:06 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:07 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:07 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:07 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:07 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:10 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:10 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f6a1ec9339624660b35467f17b67bba9 (experiment: slowfast)
2025-12-12 19:34:10 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:34:11 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:11 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:11 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f6a1ec9339624660b35467f17b67bba9
2025-12-12 19:34:11 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:34:11 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:34:11 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:11 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:11 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:11 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:11 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:11 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:14 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:14 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a8a8182bd1014f6cbba734963d1e1051 (experiment: slowfast)
2025-12-12 19:34:14 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:34:16 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:16 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:16 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a8a8182bd1014f6cbba734963d1e1051
2025-12-12 19:34:16 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:34:16 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:34:16 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:16 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:16 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:16 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:16 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:16 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:19 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8589270674074b82b3d4b71a05c8f14a (experiment: slowfast)
2025-12-12 19:34:19 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:34:20 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:20 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:20 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8589270674074b82b3d4b71a05c8f14a
2025-12-12 19:34:21 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:34:21 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:34:21 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:21 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:21 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:21 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:21 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:21 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:23 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:23 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 870a7c57c03b4c47807f19a8bab31358 (experiment: slowfast)
2025-12-12 19:34:23 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:34:25 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:25 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:25 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 870a7c57c03b4c47807f19a8bab31358
2025-12-12 19:34:26 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:34:26 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 20/32
2025-12-12 19:34:26 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 19:34:26 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:34:26 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:34:26 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:34:26 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:26 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:26 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:26 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:26 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:26 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:28 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:29 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1a436edcf4cc409086627647629faee6 (experiment: slowfast)
2025-12-12 19:34:29 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:34:30 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:30 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:30 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1a436edcf4cc409086627647629faee6
2025-12-12 19:34:31 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:34:31 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:34:31 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:31 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:31 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:31 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:31 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:31 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:33 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:33 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2e6c90d4e4a24435a941fae4eb54a171 (experiment: slowfast)
2025-12-12 19:34:33 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:34:34 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:34 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:34 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2e6c90d4e4a24435a941fae4eb54a171
2025-12-12 19:34:35 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:34:35 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:34:35 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:35 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:35 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:35 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:35 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:35 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:37 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: da4386cd2e7749fc9d47b36ee5df5424 (experiment: slowfast)
2025-12-12 19:34:38 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:34:39 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:39 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:39 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: da4386cd2e7749fc9d47b36ee5df5424
2025-12-12 19:34:40 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:34:40 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:34:40 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:40 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:40 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:40 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:40 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:40 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:42 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:42 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5ef02524413e478f8806c930891cd129 (experiment: slowfast)
2025-12-12 19:34:42 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:34:44 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:44 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:44 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5ef02524413e478f8806c930891cd129
2025-12-12 19:34:45 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:34:45 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:34:45 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:45 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:45 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:45 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:47 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:47 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0e04f1c3799a491a888a67a7aa51b587 (experiment: slowfast)
2025-12-12 19:34:47 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:34:49 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:49 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:49 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0e04f1c3799a491a888a67a7aa51b587
2025-12-12 19:34:49 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:34:49 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 21/32
2025-12-12 19:34:49 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 19:34:49 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:34:49 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:34:49 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:34:49 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:49 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:50 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:50 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:50 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:50 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:52 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:52 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8951b7ed49bf49029c423ff52e4e6af4 (experiment: slowfast)
2025-12-12 19:34:52 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:34:54 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:54 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:54 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8951b7ed49bf49029c423ff52e4e6af4
2025-12-12 19:34:54 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:34:54 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:34:54 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:54 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:54 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:54 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:54 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:54 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:57 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:34:57 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8e47002bb0ba460d8ef27d6303acd590 (experiment: slowfast)
2025-12-12 19:34:57 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:34:58 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:58 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:34:58 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8e47002bb0ba460d8ef27d6303acd590
2025-12-12 19:34:58 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:34:58 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:34:58 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:34:58 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:34:59 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:34:59 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:34:59 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:34:59 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:01 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 07965fc3375641b2ae59ae01a8e78ce9 (experiment: slowfast)
2025-12-12 19:35:01 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:35:03 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:03 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:03 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 07965fc3375641b2ae59ae01a8e78ce9
2025-12-12 19:35:03 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:35:03 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:35:03 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:03 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:03 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:03 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:03 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:03 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:06 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:06 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 297781d6a12d4c6ea137bb7041a11d9d (experiment: slowfast)
2025-12-12 19:35:06 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:35:08 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:08 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:08 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 297781d6a12d4c6ea137bb7041a11d9d
2025-12-12 19:35:08 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:35:08 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:35:08 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:08 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:08 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:08 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:08 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:08 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:11 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:11 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5a296f23e7194329aab1d03115d7c21e (experiment: slowfast)
2025-12-12 19:35:11 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:35:12 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:12 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:12 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5a296f23e7194329aab1d03115d7c21e
2025-12-12 19:35:13 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:35:13 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 22/32
2025-12-12 19:35:13 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 19:35:13 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:35:13 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:35:13 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:35:13 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:13 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:13 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:13 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:13 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:13 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:15 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:16 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 54532b52deda4172831d2c44ab64499c (experiment: slowfast)
2025-12-12 19:35:16 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:35:17 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:17 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:17 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 54532b52deda4172831d2c44ab64499c
2025-12-12 19:35:18 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:35:18 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:35:18 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:18 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:18 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:18 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:18 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:18 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:20 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:20 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 523711804bb24b4ba312a8657dacbddb (experiment: slowfast)
2025-12-12 19:35:20 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:35:21 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:21 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:21 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 523711804bb24b4ba312a8657dacbddb
2025-12-12 19:35:22 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:35:22 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:35:22 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:22 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:22 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:22 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:22 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:22 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:24 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:25 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 3636f03dadad4ae8bfc7efa941220037 (experiment: slowfast)
2025-12-12 19:35:25 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:35:26 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:26 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:26 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 3636f03dadad4ae8bfc7efa941220037
2025-12-12 19:35:27 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:35:27 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:35:27 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:27 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:27 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:27 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:27 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:27 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:29 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:29 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 83b4eba7debf4bd799de405bb68c5d57 (experiment: slowfast)
2025-12-12 19:35:29 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:35:31 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:31 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:31 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 83b4eba7debf4bd799de405bb68c5d57
2025-12-12 19:35:32 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:35:32 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:35:32 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:32 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:32 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:32 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:32 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:32 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:34 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:34 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1d119e0715c44698afd50e461b810bf1 (experiment: slowfast)
2025-12-12 19:35:34 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:35:36 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:36 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:36 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1d119e0715c44698afd50e461b810bf1
2025-12-12 19:35:36 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:35:36 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 23/32
2025-12-12 19:35:36 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 19:35:36 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:35:36 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:35:36 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:35:36 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:36 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:37 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:37 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:37 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:37 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:39 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:39 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7d6ed041321e414fb6fbbad82d051712 (experiment: slowfast)
2025-12-12 19:35:39 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:35:41 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:41 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:41 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7d6ed041321e414fb6fbbad82d051712
2025-12-12 19:35:41 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:35:41 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:35:41 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:41 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:41 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:41 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:41 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:41 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:44 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:44 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e77e72b8e1ae4575a13c9094224b8733 (experiment: slowfast)
2025-12-12 19:35:44 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:35:45 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:45 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:45 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e77e72b8e1ae4575a13c9094224b8733
2025-12-12 19:35:45 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:35:45 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:35:45 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:45 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:45 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:45 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:46 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:48 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:48 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4becb6168b044afcb2cbc4610a47ee3c (experiment: slowfast)
2025-12-12 19:35:48 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:35:50 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:50 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:50 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4becb6168b044afcb2cbc4610a47ee3c
2025-12-12 19:35:50 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:35:50 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:35:50 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:50 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:50 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:50 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:50 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:50 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:53 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:53 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 10adacb2b7364cbab209e3ac620f1e2c (experiment: slowfast)
2025-12-12 19:35:53 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:35:55 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:55 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:55 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 10adacb2b7364cbab209e3ac620f1e2c
2025-12-12 19:35:55 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:35:55 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:35:55 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:35:55 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:35:55 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:35:55 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:35:55 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:35:55 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:57 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:35:58 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 041d89832c6f4e48b3cfbfbbfa75f994 (experiment: slowfast)
2025-12-12 19:35:58 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:35:59 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:59 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:35:59 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 041d89832c6f4e48b3cfbfbbfa75f994
2025-12-12 19:36:00 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:36:00 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 24/32
2025-12-12 19:36:00 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 19:36:00 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:36:00 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:36:00 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:36:00 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:00 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:00 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:00 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:00 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:00 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:02 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:02 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5f25e16038c74842a22e9c58b521467c (experiment: slowfast)
2025-12-12 19:36:02 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:36:04 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:04 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:04 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5f25e16038c74842a22e9c58b521467c
2025-12-12 19:36:04 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:36:04 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:36:04 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:04 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:05 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:05 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:05 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:05 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:07 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1a7d464f85274f70b7e9a6f3b54b2cb1 (experiment: slowfast)
2025-12-12 19:36:07 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:36:08 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:08 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:08 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1a7d464f85274f70b7e9a6f3b54b2cb1
2025-12-12 19:36:09 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:36:09 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:36:09 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:09 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:09 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:09 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:09 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:09 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:12 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:12 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 55f4218942054bdbb035e5bbee0b8b31 (experiment: slowfast)
2025-12-12 19:36:12 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:36:13 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:13 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:13 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 55f4218942054bdbb035e5bbee0b8b31
2025-12-12 19:36:14 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:36:14 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:36:14 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:14 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:14 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:14 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:14 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:14 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:16 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:17 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 807aaa02cec042dc81f988ef82981924 (experiment: slowfast)
2025-12-12 19:36:17 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:36:18 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:18 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:19 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 807aaa02cec042dc81f988ef82981924
2025-12-12 19:36:19 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:36:19 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:36:19 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:19 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:19 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:19 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:19 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:19 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:21 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:22 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c3ba85dfbb464bbaaf6592a250708fe3 (experiment: slowfast)
2025-12-12 19:36:22 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:36:23 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:23 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:23 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c3ba85dfbb464bbaaf6592a250708fe3
2025-12-12 19:36:24 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:36:24 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 25/32
2025-12-12 19:36:24 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 19:36:24 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:36:24 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:36:24 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:36:24 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:24 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:24 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:24 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:26 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:26 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7fe42e4dc7704fabb8a6a408172fc085 (experiment: slowfast)
2025-12-12 19:36:26 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:36:28 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:28 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:28 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7fe42e4dc7704fabb8a6a408172fc085
2025-12-12 19:36:28 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:36:28 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:36:28 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:28 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:28 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:29 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:29 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:29 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:31 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:31 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c046342ba0b24be99e342ccb188bffa0 (experiment: slowfast)
2025-12-12 19:36:31 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:36:32 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:32 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:32 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c046342ba0b24be99e342ccb188bffa0
2025-12-12 19:36:33 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:36:33 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:36:33 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:33 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:33 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:33 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:33 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:33 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:35 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:35 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 48060f87a6e74f9b993346d6a2fd8a7b (experiment: slowfast)
2025-12-12 19:36:35 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:36:37 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:37 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 48060f87a6e74f9b993346d6a2fd8a7b
2025-12-12 19:36:37 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:36:37 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:36:37 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:37 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:37 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:37 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:37 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:38 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:40 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:40 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0617e5d2a9b24f5980ae3abdec07fd6e (experiment: slowfast)
2025-12-12 19:36:40 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:36:42 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:42 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:42 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0617e5d2a9b24f5980ae3abdec07fd6e
2025-12-12 19:36:42 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:36:42 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:36:42 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:42 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:42 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:42 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:42 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:42 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:45 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:45 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 670648227eb74744b73a5fb9dc8590ea (experiment: slowfast)
2025-12-12 19:36:45 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:36:47 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:47 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:47 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 670648227eb74744b73a5fb9dc8590ea
2025-12-12 19:36:47 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:36:47 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 26/32
2025-12-12 19:36:47 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 19:36:47 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:36:47 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:36:47 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:36:47 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:47 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:47 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:47 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:47 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:47 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:50 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: fb8f43f1104f431cb5bf2aa5f9977492 (experiment: slowfast)
2025-12-12 19:36:50 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:36:51 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:51 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:51 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: fb8f43f1104f431cb5bf2aa5f9977492
2025-12-12 19:36:52 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:36:52 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:36:52 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:52 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:52 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:52 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:52 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:52 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:54 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 3558dfe232ea4b028fb6028bc863a490 (experiment: slowfast)
2025-12-12 19:36:54 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:36:56 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:56 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:36:56 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 3558dfe232ea4b028fb6028bc863a490
2025-12-12 19:36:56 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:36:56 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:36:56 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:36:56 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:36:56 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:36:56 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:36:56 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:36:56 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:59 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:36:59 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a0caee40bbc948e1be9441ebff0e607e (experiment: slowfast)
2025-12-12 19:36:59 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:37:00 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:00 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:00 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a0caee40bbc948e1be9441ebff0e607e
2025-12-12 19:37:01 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:37:01 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:37:01 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:01 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:01 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:01 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:01 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:01 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:03 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:04 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: b6c1c048a1304385881db2f5e4fd9b10 (experiment: slowfast)
2025-12-12 19:37:04 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:37:05 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:05 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:05 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: b6c1c048a1304385881db2f5e4fd9b10
2025-12-12 19:37:06 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:37:06 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:37:06 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:06 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:06 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:06 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:06 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:06 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:08 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:08 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0824bd21d44f45d883c7ece331544898 (experiment: slowfast)
2025-12-12 19:37:08 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:37:10 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:10 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:10 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0824bd21d44f45d883c7ece331544898
2025-12-12 19:37:10 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:37:10 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 27/32
2025-12-12 19:37:10 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 19:37:10 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:37:10 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:37:10 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:37:10 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:10 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:11 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:11 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:11 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:11 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:13 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:13 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c43b048db11f4c6db1c0c9d7cfb31dc0 (experiment: slowfast)
2025-12-12 19:37:13 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:37:15 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:15 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:15 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c43b048db11f4c6db1c0c9d7cfb31dc0
2025-12-12 19:37:15 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:37:15 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:37:15 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:15 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:15 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:15 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:15 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:15 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:18 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:18 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 653f92ad3b4b456786f949bd52b2b1ea (experiment: slowfast)
2025-12-12 19:37:18 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:37:19 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:19 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:19 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 653f92ad3b4b456786f949bd52b2b1ea
2025-12-12 19:37:19 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:37:19 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:37:19 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:19 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:20 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:20 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:20 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:20 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:22 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:22 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: bf6223ab43da4d7ea545ec363df160d2 (experiment: slowfast)
2025-12-12 19:37:22 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:37:24 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:24 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:24 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: bf6223ab43da4d7ea545ec363df160d2
2025-12-12 19:37:24 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:37:24 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:37:24 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:24 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:24 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:24 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:24 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:27 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:27 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 42930509d15a42248ef8634e7e50abee (experiment: slowfast)
2025-12-12 19:37:27 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:37:29 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:29 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:29 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 42930509d15a42248ef8634e7e50abee
2025-12-12 19:37:29 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:37:29 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:37:29 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:29 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:29 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:29 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:29 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:29 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:32 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:32 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 24c0b420ca2e4dada1c74d93c9b1d348 (experiment: slowfast)
2025-12-12 19:37:32 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:37:33 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:33 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:33 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 24c0b420ca2e4dada1c74d93c9b1d348
2025-12-12 19:37:34 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:37:34 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 28/32
2025-12-12 19:37:34 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 19:37:34 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:37:34 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:37:34 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:37:34 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:34 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:34 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:34 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:34 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:34 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:36 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:36 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7add519c90d34bd589974ed0f2a01886 (experiment: slowfast)
2025-12-12 19:37:37 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:37:38 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:38 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:38 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7add519c90d34bd589974ed0f2a01886
2025-12-12 19:37:39 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:37:39 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:37:39 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:39 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:39 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:39 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:39 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:39 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:41 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:41 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a754954052834d2cb7c1b849d7180fbe (experiment: slowfast)
2025-12-12 19:37:41 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:37:43 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:43 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:43 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a754954052834d2cb7c1b849d7180fbe
2025-12-12 19:37:43 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:37:43 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:37:43 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:43 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:43 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:43 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:43 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:43 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:46 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:46 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 6c4e56c6bb2546cfa1df29ec3014c970 (experiment: slowfast)
2025-12-12 19:37:46 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:37:47 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:47 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:47 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 6c4e56c6bb2546cfa1df29ec3014c970
2025-12-12 19:37:48 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:37:48 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:37:48 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:48 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:48 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:48 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:48 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:48 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:50 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a48e58cdbc0b4c48aa76b6ee1174f2bf (experiment: slowfast)
2025-12-12 19:37:50 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:37:52 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:52 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:52 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a48e58cdbc0b4c48aa76b6ee1174f2bf
2025-12-12 19:37:53 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:37:53 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:37:53 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:53 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:53 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:53 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:53 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:53 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:55 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:37:55 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 67f4f38d6e644aea84c41099e239e80d (experiment: slowfast)
2025-12-12 19:37:55 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:37:57 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:57 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:37:57 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 67f4f38d6e644aea84c41099e239e80d
2025-12-12 19:37:57 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:37:57 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 29/32
2025-12-12 19:37:57 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-12 19:37:57 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:37:57 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:37:57 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:37:57 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:37:57 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:37:58 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:37:58 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:37:58 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:37:58 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:00 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0b37b2b3b23a4f58a00753007fdc008e (experiment: slowfast)
2025-12-12 19:38:00 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:38:02 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:02 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:02 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0b37b2b3b23a4f58a00753007fdc008e
2025-12-12 19:38:02 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:38:02 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:38:02 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:02 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:02 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:02 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:02 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:02 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:05 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:05 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 31a92410eeb04c3b9a30b9b22c2f09e0 (experiment: slowfast)
2025-12-12 19:38:05 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:38:06 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:06 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:06 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 31a92410eeb04c3b9a30b9b22c2f09e0
2025-12-12 19:38:06 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:38:06 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:38:06 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:06 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:06 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:06 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:06 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:07 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:09 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:09 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 87109fe5aeec4833b81b2e7925b9cf89 (experiment: slowfast)
2025-12-12 19:38:09 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:38:11 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:11 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:11 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 87109fe5aeec4833b81b2e7925b9cf89
2025-12-12 19:38:11 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:38:11 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:38:11 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:11 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:12 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:12 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:12 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:12 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:14 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:14 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 87f35b0deac547f091ce2a7e067c214c (experiment: slowfast)
2025-12-12 19:38:14 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:38:16 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:16 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:16 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 87f35b0deac547f091ce2a7e067c214c
2025-12-12 19:38:16 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:38:16 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:38:16 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:16 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:16 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:16 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:16 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:17 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:19 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9aec6ff4ec1d450cabfcdf15df75d656 (experiment: slowfast)
2025-12-12 19:38:19 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:38:21 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:21 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:21 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9aec6ff4ec1d450cabfcdf15df75d656
2025-12-12 19:38:21 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:38:21 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 30/32
2025-12-12 19:38:21 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 4}
2025-12-12 19:38:21 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:38:21 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:38:21 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:38:21 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:21 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:21 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:21 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:21 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:21 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:24 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:24 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 014225e19aca4dee8a814f531bea4ffd (experiment: slowfast)
2025-12-12 19:38:24 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:38:26 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:26 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:26 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 014225e19aca4dee8a814f531bea4ffd
2025-12-12 19:38:26 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:38:26 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:38:26 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:26 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:26 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:26 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:26 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:26 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:29 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:29 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 69dd120c2ea24aff9b382288230e3fbe (experiment: slowfast)
2025-12-12 19:38:29 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:38:30 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:30 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:30 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 69dd120c2ea24aff9b382288230e3fbe
2025-12-12 19:38:30 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:38:30 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:38:30 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:30 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:30 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:30 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:30 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:30 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:33 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:33 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 38ac7b11ec8d4c5aa5846f11b47551a9 (experiment: slowfast)
2025-12-12 19:38:33 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:38:35 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:35 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:35 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 38ac7b11ec8d4c5aa5846f11b47551a9
2025-12-12 19:38:35 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:38:35 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:38:35 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:35 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:35 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:35 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:35 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:35 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:38 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e248ec23310d4bc3a383b3d4f82fc3d7 (experiment: slowfast)
2025-12-12 19:38:38 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:38:40 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:40 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:40 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e248ec23310d4bc3a383b3d4f82fc3d7
2025-12-12 19:38:40 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:38:40 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:38:40 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:40 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:40 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:40 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:40 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:40 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:43 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:43 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 3a4a14ba36c24fd2a56c79481ce2a1d4 (experiment: slowfast)
2025-12-12 19:38:43 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:38:44 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:44 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:44 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 3a4a14ba36c24fd2a56c79481ce2a1d4
2025-12-12 19:38:45 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:38:45 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 31/32
2025-12-12 19:38:45 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 2}
2025-12-12 19:38:45 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:38:45 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:38:45 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:38:45 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:45 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:45 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:45 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:45 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:47 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:48 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c7355e8ea161420687133cfe92f5a735 (experiment: slowfast)
2025-12-12 19:38:48 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:38:49 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:49 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:49 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c7355e8ea161420687133cfe92f5a735
2025-12-12 19:38:50 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:38:50 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:38:50 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:50 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:50 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:50 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:50 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:50 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:52 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:52 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e1e790c1acc14f02af1ac2c92f2fa386 (experiment: slowfast)
2025-12-12 19:38:52 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:38:53 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:53 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:54 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e1e790c1acc14f02af1ac2c92f2fa386
2025-12-12 19:38:54 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:38:54 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:38:54 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:54 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:54 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:54 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:54 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:54 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:56 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:38:57 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 87cd9b7569354461860157041b2a09fc (experiment: slowfast)
2025-12-12 19:38:57 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:38:58 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:58 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:38:58 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 87cd9b7569354461860157041b2a09fc
2025-12-12 19:38:59 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:38:59 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:38:59 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:38:59 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:38:59 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:38:59 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:38:59 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:38:59 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:01 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 6379dcf636bd42918a9f4775f6cee697 (experiment: slowfast)
2025-12-12 19:39:01 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:39:03 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:03 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:03 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 6379dcf636bd42918a9f4775f6cee697
2025-12-12 19:39:03 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:39:03 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 2, Gradient accumulation steps: 32, Effective batch size: 64
2025-12-12 19:39:03 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:03 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:03 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:03 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:03 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:04 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:06 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:06 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f2fd26d23cfc4acf870dd20812b21d6c (experiment: slowfast)
2025-12-12 19:39:06 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:39:08 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:08 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:08 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f2fd26d23cfc4acf870dd20812b21d6c
2025-12-12 19:39:08 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:39:08 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 32/32
2025-12-12 19:39:08 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001, 'batch_size': 4}
2025-12-12 19:39:08 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:39:08 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 1/5 (20% sample)
2025-12-12 19:39:08 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:39:08 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:08 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:08 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:08 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:08 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:08 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:11 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:11 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 947e9b4f42dd476fa7bce390dd630c2f (experiment: slowfast)
2025-12-12 19:39:11 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 1...
2025-12-12 19:39:13 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:13 [ERROR] [lib.training.pipeline:1650] Error training fold 1: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:13 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 947e9b4f42dd476fa7bce390dd630c2f
2025-12-12 19:39:13 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 2/5 (20% sample)
2025-12-12 19:39:13 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:39:13 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:13 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:13 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:13 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:13 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:13 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:16 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:16 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e5f89673b3a7468cb90bb5901f9ac533 (experiment: slowfast)
2025-12-12 19:39:16 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 2...
2025-12-12 19:39:17 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:17 [ERROR] [lib.training.pipeline:1650] Error training fold 2: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:17 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e5f89673b3a7468cb90bb5901f9ac533
2025-12-12 19:39:17 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 3/5 (20% sample)
2025-12-12 19:39:17 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:39:17 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:17 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:17 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:17 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:17 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:17 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:20 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:20 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: efcea6c2759d462ab521a6e0a0a98d40 (experiment: slowfast)
2025-12-12 19:39:20 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 3...
2025-12-12 19:39:22 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:22 [ERROR] [lib.training.pipeline:1650] Error training fold 3: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:22 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: efcea6c2759d462ab521a6e0a0a98d40
2025-12-12 19:39:22 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 4/5 (20% sample)
2025-12-12 19:39:22 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:39:22 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:22 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:22 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:22 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:22 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:22 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:25 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:25 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c0c3347c50b04dbdaa894087c0dc0043 (experiment: slowfast)
2025-12-12 19:39:25 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 4...
2025-12-12 19:39:27 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:27 [ERROR] [lib.training.pipeline:1650] Error training fold 4: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:27 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c0c3347c50b04dbdaa894087c0dc0043
2025-12-12 19:39:27 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - slowfast - Fold 5/5 (20% sample)
2025-12-12 19:39:27 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 4, Gradient accumulation steps: 32, Effective batch size: 128
2025-12-12 19:39:27 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:27 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:27 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:27 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:27 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:27 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:30 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:30 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 262c4b94631b4b849750d26110c95b5b (experiment: slowfast)
2025-12-12 19:39:30 [INFO] [lib.training.pipeline:1073] Training PyTorch model slowfast on fold 5...
2025-12-12 19:39:31 [ERROR] [lib.training.pipeline:1160] Model forward pass test failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:31 [ERROR] [lib.training.pipeline:1650] Error training fold 5: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
                    ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1161, in stage5_train_models
    raise ValueError(f"Model initialization failed: {e}") from e
ValueError: Model initialization failed: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:32 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 262c4b94631b4b849750d26110c95b5b
2025-12-12 19:39:32 [INFO] [lib.training.pipeline:1709] ================================================================================
2025-12-12 19:39:32 [INFO] [lib.training.pipeline:1710] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-12 19:39:32 [INFO] [lib.training.pipeline:1711] ================================================================================
2025-12-12 19:39:32 [INFO] [lib.training.pipeline:1724] Final training: Using 5-fold stratified cross-validation on full dataset (3278 rows)
2025-12-12 19:39:32 [INFO] [lib.training.pipeline:1734] Final training using default hyperparameters (no grid search)
2025-12-12 19:39:32 [INFO] [lib.training.pipeline:1738] 
Final Training - slowfast - Fold 1/5 (full dataset)
2025-12-12 19:39:32 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:32 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:32 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:32 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:32 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:32 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:34 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:35 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 6cac937ca86f486981d6237ca76bc4f6 (experiment: slowfast)
2025-12-12 19:39:35 [INFO] [lib.training.pipeline:1895] Training PyTorch model slowfast on fold 1 (full dataset)...
2025-12-12 19:39:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:39:39 [ERROR] [lib.training.pipeline:2095] Error training final fold 1: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1901, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:39 [INFO] [lib.training.pipeline:1738] 
Final Training - slowfast - Fold 2/5 (full dataset)
2025-12-12 19:39:39 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:39 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:39 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:39 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:39 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:39 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:41 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:41 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 367dc7b6be644fd091aec741a5495bb9 (experiment: slowfast)
2025-12-12 19:39:41 [INFO] [lib.training.pipeline:1895] Training PyTorch model slowfast on fold 2 (full dataset)...
2025-12-12 19:39:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:39:43 [ERROR] [lib.training.pipeline:2095] Error training final fold 2: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1901, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:43 [INFO] [lib.training.pipeline:1738] 
Final Training - slowfast - Fold 3/5 (full dataset)
2025-12-12 19:39:43 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:43 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:43 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:43 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:43 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:43 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:45 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:46 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8dbb09f462b34fe0ba216cbabf4be726 (experiment: slowfast)
2025-12-12 19:39:46 [INFO] [lib.training.pipeline:1895] Training PyTorch model slowfast on fold 3 (full dataset)...
2025-12-12 19:39:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:39:47 [ERROR] [lib.training.pipeline:2095] Error training final fold 3: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1901, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:47 [INFO] [lib.training.pipeline:1738] 
Final Training - slowfast - Fold 4/5 (full dataset)
2025-12-12 19:39:47 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:47 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:47 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:47 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:47 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:47 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:49 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:49 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 408b01982d76451c8a300603e0153866 (experiment: slowfast)
2025-12-12 19:39:49 [INFO] [lib.training.pipeline:1895] Training PyTorch model slowfast on fold 4 (full dataset)...
2025-12-12 19:39:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:39:51 [ERROR] [lib.training.pipeline:2095] Error training final fold 4: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1901, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:51 [INFO] [lib.training.pipeline:1738] 
Final Training - slowfast - Fold 5/5 (full dataset)
2025-12-12 19:39:51 [INFO] [lib.training.slowfast:64] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-12 19:39:51 [INFO] [lib.training.slowfast:70] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-12 19:39:51 [INFO] [lib.training.slowfast:100] Trying pytorchvideo library directly...
2025-12-12 19:39:51 [INFO] [lib.training.slowfast:154] Trying HuggingFace for SlowFast...
2025-12-12 19:39:51 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: facebookresearch/slowfast
2025-12-12 19:39:51 [INFO] [lib.training.slowfast:166] Trying to load SlowFast from: MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:53 [INFO] [lib.training.slowfast:208] ✓ Loaded SlowFast from MCG-NJU/videomae-base-finetuned-kinetics
2025-12-12 19:39:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d180caa4ed99451a896a792321e669a8 (experiment: slowfast)
2025-12-12 19:39:54 [INFO] [lib.training.pipeline:1895] Training PyTorch model slowfast on fold 5 (full dataset)...
2025-12-12 19:39:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:39:58 [ERROR] [lib.training.pipeline:2095] Error training final fold 5: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1901, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 332, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 883, in forward
    outputs: BaseModelOutput = self.videomae(pixel_values, head_mask=head_mask, **kwargs)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 552, in forward
    embedding_output = self.embeddings(pixel_values, bool_masked_pos)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 112, in forward
    embeddings = self.patch_embeddings(pixel_values)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/transformers/models/videomae/modeling_videomae.py", line 168, in forward
    raise ValueError(
ValueError: Make sure that the channel dimension of the pixel values match with the one set in the configuration.
2025-12-12 19:39:58 [WARNING] [lib.training.pipeline:118] No model files found in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/slowfast/fold_1 to copy
2025-12-12 19:39:58 [INFO] [lib.training.pipeline:2168] 
slowfast - Avg Val Loss: nan, Avg Val Acc: nan, Avg Val F1: nan
2025-12-12 19:39:59 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/slowfast/plots/cv_fold_comparison.png
2025-12-12 19:39:59 [INFO] [lib.training.pipeline:2196] Generated plots for slowfast in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/slowfast/plots
2025-12-12 19:40:00 [INFO] [lib.training.pipeline:2233] ================================================================================
2025-12-12 19:40:00 [INFO] [lib.training.pipeline:2234] Stage 5: Model Training Pipeline Completed
2025-12-12 19:40:00 [INFO] [lib.training.pipeline:2235] ================================================================================
2025-12-12 19:40:00 [INFO] [__main__:401] ================================================================================
2025-12-12 19:40:00 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-12 19:40:00 [INFO] [__main__:403] ================================================================================
2025-12-12 19:40:00 [INFO] [__main__:404] Execution time: 847.63 seconds (14.13 minutes)
2025-12-12 19:40:00 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 19:40:00 [INFO] [__main__:407] Models trained: ['slowfast']
2025-12-12 19:40:00 [INFO] [__main__:408] K-fold splits: 5
2025-12-12 19:40:00 [INFO] [__main__:414] ================================================================================
2025-12-12 19:40:00 [INFO] [__main__:415] Final memory statistics:
2025-12-12 19:40:00 [INFO] [__main__:416] ================================================================================
2025-12-12 19:40:00 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: after training): {'cpu_memory_mb': 3447.1484375, 'cpu_memory_gb': 3.3663558959960938, 'cpu_vms_mb': 49770.77734375, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 1.176502272, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.751839744}
2025-12-12 19:40:00 [INFO] [__main__:419] ================================================================================
2025-12-12 19:40:00 [INFO] [__main__:420] Training complete!
2025-12-12 19:40:00 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 19:40:00 [INFO] [__main__:422] ================================================================================
