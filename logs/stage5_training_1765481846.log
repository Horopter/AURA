2025-12-11 14:37:27 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: before training): {'cpu_memory_mb': 772.921875, 'cpu_memory_gb': 0.7548065185546875, 'cpu_vms_mb': 10258.1640625, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-11 14:37:27 [DEBUG] [lib.utils.memory:95] CPU percent: 0.0%
2025-12-11 14:37:27 [DEBUG] [lib.utils.memory:96] Num threads: 4
2025-12-11 14:37:27 [INFO] [lib.training.stage5_feature_pipeline:63] Loading scaled metadata...
2025-12-11 14:37:28 [INFO] [lib.training.stage5_feature_pipeline:72] Loaded 3244 videos
2025-12-11 14:37:29 [INFO] [lib.training.stage5_feature_pipeline:86] Labels: [0, 1] -> {0: 0, 1: 1}
2025-12-11 14:37:29 [INFO] [lib.training.stage5_feature_pipeline:89] Loading features from Stage 2/4 (collinearity removal will be done once before splits)...
2025-12-11 14:37:29 [INFO] [lib.training.feature_preprocessing:316] Loading Stage 2 features...
2025-12-11 14:37:40 [INFO] [lib.training.feature_preprocessing:363] Loaded 15 Stage 2 features (3244/3244 videos matched)
2025-12-11 14:37:40 [INFO] [lib.training.feature_preprocessing:371] Loading Stage 4 features...
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:411] Sample unmatched Stage 4 videos (showing first 1): ['data/scaled_videos/FX5aeuJFQ64_aug1_scaled_aug1.mp4']
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:412] Sample Stage 4 feature paths (showing first 3): ['data/scaled_videos/51EwLmqOYNg_aug4_scaled_aug4.mp4', 'data/scaled_videos/735177418030252033_aug0_scaled_aug0.mp4', 'data/scaled_videos/-y0Vr7JmCek_aug5_scaled_aug5.mp4']
2025-12-11 14:37:57 [INFO] [lib.training.feature_preprocessing:416] Loaded 23 Stage 4 features (3243/3244 videos matched)
2025-12-11 14:37:57 [INFO] [lib.training.feature_preprocessing:427] Combined 38 features from 2 stages
2025-12-11 14:37:57 [INFO] [lib.training.feature_preprocessing:436] Stage 2: 3244 videos, Stage 4: 3243 videos
2025-12-11 14:37:57 [INFO] [lib.training.feature_preprocessing:437] Intersection (videos with BOTH Stage 2 AND Stage 4): 3243 videos
2025-12-11 14:37:57 [INFO] [lib.training.feature_preprocessing:458] ✓ Found 3243 videos with valid features (>= 3000 required)
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:152] Removing collinear features BEFORE data splits (to avoid data leakage)...
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:153]   Original feature count: 38
2025-12-11 14:37:57 [INFO] [lib.training.feature_preprocessing:76] Removed 2 features with zero variance
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage2_noise_mean (correlation=0.992)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage2_dct_dc_mean (correlation=0.999)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage2_dct_dc_std (correlation=0.992)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage2_dct_dc_std (correlation=0.968)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage2_dct_dc_std (correlation=0.988)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage2_dct_dc_std (correlation=0.959)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage2_gradient_std (correlation=0.964)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage2_boundary_inconsistency (correlation=0.994)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage4_noise_energy (correlation=0.958)
2025-12-11 14:37:57 [DEBUG] [lib.training.feature_preprocessing:128] Removing collinear feature: stage4_is_downscaled (correlation=-0.998)
2025-12-11 14:37:57 [INFO] [lib.training.feature_preprocessing:138] Removed 10 collinear features (correlation >= 0.95)
2025-12-11 14:37:57 [INFO] [lib.training.feature_preprocessing:159] Final feature count: 26/38 (68.4% retained)
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:162]   Final feature count after collinearity removal: 26/38 (68.4% retained)
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:104] ✓ Loaded 26 features for 3244 videos
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:105]   Features already cleaned (collinearity removed before splits)
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:120] After filtering to videos with valid features: 3243/3244 videos
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:136] ✓ Sufficient videos with valid features: 3243 >= 3000
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:146] Feature-based models: ['logistic_regression']
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:147] Video-based models: []
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:153] ================================================================================
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:154] TRAINING FEATURE-BASED MODELS
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:155] ================================================================================
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:158] ================================================================================
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:159] Training logistic_regression (feature-based)
2025-12-11 14:37:57 [INFO] [lib.training.stage5_feature_pipeline:160] ================================================================================
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:214] Using GPU for logistic_regression
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:220] Training logistic_regression (architecture: mlp, input_dim: 26)
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:224] Creating 60-20-20 stratified train-val-test split...
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:232] Train: 1945, Val: 649, Test: 649
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:233] ✓ Features cleaned BEFORE splits: 26 features (collinearity already removed)
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:243] Hyperparameter search: 81 combinations
2025-12-11 14:37:57 [INFO] [lib.training.feature_training_pipeline:246] Grid search 1/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:38:25 [INFO] [lib.training.feature_training_pipeline:246] Grid search 2/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:38:37 [INFO] [lib.training.feature_training_pipeline:246] Grid search 3/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:38:47 [INFO] [lib.training.feature_training_pipeline:246] Grid search 4/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:38:56 [INFO] [lib.training.feature_training_pipeline:246] Grid search 5/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:39:11 [INFO] [lib.training.feature_training_pipeline:246] Grid search 6/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:39:19 [INFO] [lib.training.feature_training_pipeline:246] Grid search 7/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:39:29 [INFO] [lib.training.feature_training_pipeline:246] Grid search 8/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:39:36 [INFO] [lib.training.feature_training_pipeline:246] Grid search 9/81: {'dropout': 0.3, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:39:42 [INFO] [lib.training.feature_training_pipeline:246] Grid search 10/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:39:57 [INFO] [lib.training.feature_training_pipeline:246] Grid search 11/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:40:12 [INFO] [lib.training.feature_training_pipeline:246] Grid search 12/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:40:28 [INFO] [lib.training.feature_training_pipeline:246] Grid search 13/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:40:37 [INFO] [lib.training.feature_training_pipeline:246] Grid search 14/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:40:44 [INFO] [lib.training.feature_training_pipeline:246] Grid search 15/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:40:51 [INFO] [lib.training.feature_training_pipeline:246] Grid search 16/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:40:59 [INFO] [lib.training.feature_training_pipeline:246] Grid search 17/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:41:10 [INFO] [lib.training.feature_training_pipeline:246] Grid search 18/81: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:41:18 [INFO] [lib.training.feature_training_pipeline:246] Grid search 19/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:41:31 [INFO] [lib.training.feature_training_pipeline:246] Grid search 20/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:41:44 [INFO] [lib.training.feature_training_pipeline:246] Grid search 21/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:41:56 [INFO] [lib.training.feature_training_pipeline:246] Grid search 22/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:42:09 [INFO] [lib.training.feature_training_pipeline:246] Grid search 23/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:42:22 [INFO] [lib.training.feature_training_pipeline:246] Grid search 24/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:42:28 [INFO] [lib.training.feature_training_pipeline:246] Grid search 25/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:42:34 [INFO] [lib.training.feature_training_pipeline:246] Grid search 26/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:42:40 [INFO] [lib.training.feature_training_pipeline:246] Grid search 27/81: {'dropout': 0.3, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:42:43 [INFO] [lib.training.feature_training_pipeline:246] Grid search 28/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:42:50 [INFO] [lib.training.feature_training_pipeline:246] Grid search 29/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:43:05 [INFO] [lib.training.feature_training_pipeline:246] Grid search 30/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:43:20 [INFO] [lib.training.feature_training_pipeline:246] Grid search 31/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:43:27 [INFO] [lib.training.feature_training_pipeline:246] Grid search 32/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:43:42 [INFO] [lib.training.feature_training_pipeline:246] Grid search 33/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:43:51 [INFO] [lib.training.feature_training_pipeline:246] Grid search 34/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:44:06 [INFO] [lib.training.feature_training_pipeline:246] Grid search 35/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:44:15 [INFO] [lib.training.feature_training_pipeline:246] Grid search 36/81: {'dropout': 0.5, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:44:18 [INFO] [lib.training.feature_training_pipeline:246] Grid search 37/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:44:33 [INFO] [lib.training.feature_training_pipeline:246] Grid search 38/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:44:49 [INFO] [lib.training.feature_training_pipeline:246] Grid search 39/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:45:04 [INFO] [lib.training.feature_training_pipeline:246] Grid search 40/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:45:19 [INFO] [lib.training.feature_training_pipeline:246] Grid search 41/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:45:30 [INFO] [lib.training.feature_training_pipeline:246] Grid search 42/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:45:41 [INFO] [lib.training.feature_training_pipeline:246] Grid search 43/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:45:48 [INFO] [lib.training.feature_training_pipeline:246] Grid search 44/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:45:56 [INFO] [lib.training.feature_training_pipeline:246] Grid search 45/81: {'dropout': 0.5, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:46:00 [INFO] [lib.training.feature_training_pipeline:246] Grid search 46/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:46:12 [INFO] [lib.training.feature_training_pipeline:246] Grid search 47/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:46:20 [INFO] [lib.training.feature_training_pipeline:246] Grid search 48/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:46:33 [INFO] [lib.training.feature_training_pipeline:246] Grid search 49/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:46:42 [INFO] [lib.training.feature_training_pipeline:246] Grid search 50/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:46:55 [INFO] [lib.training.feature_training_pipeline:246] Grid search 51/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:47:00 [INFO] [lib.training.feature_training_pipeline:246] Grid search 52/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:47:08 [INFO] [lib.training.feature_training_pipeline:246] Grid search 53/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:47:15 [INFO] [lib.training.feature_training_pipeline:246] Grid search 54/81: {'dropout': 0.5, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:47:21 [INFO] [lib.training.feature_training_pipeline:246] Grid search 55/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:47:23 [INFO] [lib.training.feature_training_pipeline:246] Grid search 56/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:47:26 [INFO] [lib.training.feature_training_pipeline:246] Grid search 57/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:47:28 [INFO] [lib.training.feature_training_pipeline:246] Grid search 58/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:47:42 [INFO] [lib.training.feature_training_pipeline:246] Grid search 59/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:47:56 [INFO] [lib.training.feature_training_pipeline:246] Grid search 60/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:48:10 [INFO] [lib.training.feature_training_pipeline:246] Grid search 61/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:48:20 [INFO] [lib.training.feature_training_pipeline:246] Grid search 62/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:48:23 [INFO] [lib.training.feature_training_pipeline:246] Grid search 63/81: {'dropout': 0.7, 'hidden_dims': [256, 128, 64], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:48:29 [INFO] [lib.training.feature_training_pipeline:246] Grid search 64/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:48:38 [INFO] [lib.training.feature_training_pipeline:246] Grid search 65/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:48:47 [INFO] [lib.training.feature_training_pipeline:246] Grid search 66/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:48:54 [INFO] [lib.training.feature_training_pipeline:246] Grid search 67/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:49:03 [INFO] [lib.training.feature_training_pipeline:246] Grid search 68/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:49:17 [INFO] [lib.training.feature_training_pipeline:246] Grid search 69/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:49:33 [INFO] [lib.training.feature_training_pipeline:246] Grid search 70/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:49:41 [INFO] [lib.training.feature_training_pipeline:246] Grid search 71/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:49:44 [INFO] [lib.training.feature_training_pipeline:246] Grid search 72/81: {'dropout': 0.7, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:49:46 [INFO] [lib.training.feature_training_pipeline:246] Grid search 73/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 1e-05}
2025-12-11 14:49:48 [INFO] [lib.training.feature_training_pipeline:246] Grid search 74/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.0001}
2025-12-11 14:49:57 [INFO] [lib.training.feature_training_pipeline:246] Grid search 75/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.0001, 'weight_decay': 0.001}
2025-12-11 14:49:59 [INFO] [lib.training.feature_training_pipeline:246] Grid search 76/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 1e-05}
2025-12-11 14:50:09 [INFO] [lib.training.feature_training_pipeline:246] Grid search 77/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 0.0001}
2025-12-11 14:50:22 [INFO] [lib.training.feature_training_pipeline:246] Grid search 78/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.001, 'weight_decay': 0.001}
2025-12-11 14:50:30 [INFO] [lib.training.feature_training_pipeline:246] Grid search 79/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 1e-05}
2025-12-11 14:50:32 [INFO] [lib.training.feature_training_pipeline:246] Grid search 80/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 0.0001}
2025-12-11 14:50:38 [INFO] [lib.training.feature_training_pipeline:246] Grid search 81/81: {'dropout': 0.7, 'hidden_dims': [128, 64], 'learning_rate': 0.01, 'weight_decay': 0.001}
2025-12-11 14:50:42 [INFO] [lib.training.feature_training_pipeline:365] Best hyperparameters: {'dropout': 0.3, 'hidden_dims': [512, 256, 128], 'learning_rate': 0.001, 'weight_decay': 1e-05} (val_f1: 0.9698)
2025-12-11 14:50:42 [INFO] [lib.training.feature_pipeline:240] Fold 1/5
2025-12-11 14:50:45 [INFO] [lib.training.feature_pipeline:345] Epoch 10/100: train_loss=0.3445, val_loss=0.3000
2025-12-11 14:50:47 [INFO] [lib.training.feature_pipeline:345] Epoch 20/100: train_loss=0.2481, val_loss=0.2103
2025-12-11 14:50:49 [INFO] [lib.training.feature_pipeline:345] Epoch 30/100: train_loss=0.2057, val_loss=0.1583
2025-12-11 14:50:50 [INFO] [lib.training.feature_pipeline:345] Epoch 40/100: train_loss=0.1749, val_loss=0.1810
2025-12-11 14:50:51 [INFO] [lib.training.feature_pipeline:341] Early stopping at epoch 47
2025-12-11 14:50:52 [INFO] [lib.training.feature_pipeline:240] Fold 2/5
2025-12-11 14:50:54 [INFO] [lib.training.feature_pipeline:345] Epoch 10/100: train_loss=0.3340, val_loss=0.2557
2025-12-11 14:50:55 [INFO] [lib.training.feature_pipeline:345] Epoch 20/100: train_loss=0.2726, val_loss=0.1474
2025-12-11 14:50:57 [INFO] [lib.training.feature_pipeline:345] Epoch 30/100: train_loss=0.1969, val_loss=0.0968
2025-12-11 14:50:59 [INFO] [lib.training.feature_pipeline:345] Epoch 40/100: train_loss=0.1673, val_loss=0.1040
2025-12-11 14:51:00 [INFO] [lib.training.feature_pipeline:345] Epoch 50/100: train_loss=0.1593, val_loss=0.0858
2025-12-11 14:51:02 [INFO] [lib.training.feature_pipeline:345] Epoch 60/100: train_loss=0.1165, val_loss=0.0842
2025-12-11 14:51:03 [INFO] [lib.training.feature_pipeline:345] Epoch 70/100: train_loss=0.1267, val_loss=0.0744
2025-12-11 14:51:04 [INFO] [lib.training.feature_pipeline:341] Early stopping at epoch 73
2025-12-11 14:51:04 [INFO] [lib.training.feature_pipeline:240] Fold 3/5
2025-12-11 14:51:06 [INFO] [lib.training.feature_pipeline:345] Epoch 10/100: train_loss=0.3486, val_loss=0.2929
2025-12-11 14:51:07 [INFO] [lib.training.feature_pipeline:345] Epoch 20/100: train_loss=0.2506, val_loss=0.2033
2025-12-11 14:51:09 [INFO] [lib.training.feature_pipeline:345] Epoch 30/100: train_loss=0.2019, val_loss=0.2104
2025-12-11 14:51:11 [INFO] [lib.training.feature_pipeline:345] Epoch 40/100: train_loss=0.1529, val_loss=0.1407
2025-12-11 14:51:12 [INFO] [lib.training.feature_pipeline:345] Epoch 50/100: train_loss=0.1479, val_loss=0.1256
2025-12-11 14:51:14 [INFO] [lib.training.feature_pipeline:345] Epoch 60/100: train_loss=0.1209, val_loss=0.1048
2025-12-11 14:51:15 [INFO] [lib.training.feature_pipeline:345] Epoch 70/100: train_loss=0.1159, val_loss=0.0993
2025-12-11 14:51:16 [INFO] [lib.training.feature_pipeline:341] Early stopping at epoch 75
2025-12-11 14:51:16 [INFO] [lib.training.feature_pipeline:240] Fold 4/5
2025-12-11 14:51:18 [INFO] [lib.training.feature_pipeline:345] Epoch 10/100: train_loss=0.3444, val_loss=0.2695
2025-12-11 14:51:20 [INFO] [lib.training.feature_pipeline:345] Epoch 20/100: train_loss=0.2387, val_loss=0.1819
2025-12-11 14:51:21 [INFO] [lib.training.feature_pipeline:345] Epoch 30/100: train_loss=0.1926, val_loss=0.1415
2025-12-11 14:51:23 [INFO] [lib.training.feature_pipeline:345] Epoch 40/100: train_loss=0.1714, val_loss=0.1157
2025-12-11 14:51:25 [INFO] [lib.training.feature_pipeline:345] Epoch 50/100: train_loss=0.1356, val_loss=0.1193
2025-12-11 14:51:26 [INFO] [lib.training.feature_pipeline:341] Early stopping at epoch 58
2025-12-11 14:51:26 [INFO] [lib.training.feature_pipeline:240] Fold 5/5
2025-12-11 14:51:28 [INFO] [lib.training.feature_pipeline:345] Epoch 10/100: train_loss=0.3622, val_loss=0.3086
2025-12-11 14:51:29 [INFO] [lib.training.feature_pipeline:345] Epoch 20/100: train_loss=0.2458, val_loss=0.2219
2025-12-11 14:51:31 [INFO] [lib.training.feature_pipeline:345] Epoch 30/100: train_loss=0.1690, val_loss=0.1831
2025-12-11 14:51:32 [INFO] [lib.training.feature_pipeline:345] Epoch 40/100: train_loss=0.1774, val_loss=0.1866
2025-12-11 14:51:34 [INFO] [lib.training.feature_pipeline:345] Epoch 50/100: train_loss=0.1460, val_loss=0.1523
2025-12-11 14:51:36 [INFO] [lib.training.feature_pipeline:345] Epoch 60/100: train_loss=0.1159, val_loss=0.1545
2025-12-11 14:51:37 [INFO] [lib.training.feature_pipeline:345] Epoch 70/100: train_loss=0.1372, val_loss=0.1589
2025-12-11 14:51:39 [INFO] [lib.training.feature_pipeline:345] Epoch 80/100: train_loss=0.1097, val_loss=0.1159
2025-12-11 14:51:41 [INFO] [lib.training.feature_pipeline:341] Early stopping at epoch 90
2025-12-11 14:51:43 [ERROR] [lib.training.stage5_feature_pipeline:182] ✗ Failed to train logistic_regression: Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/stage5_feature_pipeline.py", line 166, in stage5_train_all_models
    results = train_feature_model(
              ^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/feature_training_pipeline.py", line 402, in train_feature_model
    test_results = evaluate_model(
                   ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/feature_pipeline.py", line 419, in evaluate_model
    logits = model(batch_features)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/feature_models.py", line 55, in forward
    return self.network(x)
           ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)
2025-12-11 14:51:43 [INFO] [lib.training.stage5_feature_pipeline:282] ================================================================================
2025-12-11 14:51:43 [INFO] [lib.training.stage5_feature_pipeline:283] STAGE 5 TRAINING COMPLETE
2025-12-11 14:51:43 [INFO] [lib.training.stage5_feature_pipeline:284] ================================================================================
2025-12-11 14:51:43 [INFO] [lib.training.stage5_feature_pipeline:290] Successful: 0/1
2025-12-11 14:51:43 [INFO] [lib.training.stage5_feature_pipeline:291] Failed: 1/1
2025-12-11 14:51:43 [WARNING] [lib.training.stage5_feature_pipeline:303] Failed models:
2025-12-11 14:51:43 [WARNING] [lib.training.stage5_feature_pipeline:305]   logistic_regression: Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)
2025-12-11 14:51:43 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: after training): {'cpu_memory_mb': 1560.578125, 'cpu_memory_gb': 1.5240020751953125, 'cpu_vms_mb': 11921.83203125, 'gpu_allocated_gb': 0.018087936, 'gpu_reserved_gb': 0.027262976, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.90107904}
2025-12-11 14:51:43 [DEBUG] [lib.utils.memory:95] CPU percent: 0.0%
2025-12-11 14:51:43 [DEBUG] [lib.utils.memory:96] Num threads: 7
