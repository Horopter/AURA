2025-12-14 18:28:59 [INFO] [__main__:310] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:310] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-14 18:28:59 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-14 18:28:59 [INFO] [__main__:312] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:312] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-14 18:28:59 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-14 18:28:59 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 18:28:59 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 18:28:59 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-14 18:28:59 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-14 18:28:59 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-14 18:28:59 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-14 18:28:59 [INFO] [__main__:317] Model types: ['slowfast']
2025-12-14 18:28:59 [INFO] [__main__:317] Model types: ['x3d']
2025-12-14 18:28:59 [INFO] [__main__:318] K-fold splits: 5
2025-12-14 18:28:59 [INFO] [__main__:318] K-fold splits: 5
2025-12-14 18:28:59 [INFO] [__main__:319] Number of frames: 500
2025-12-14 18:28:59 [INFO] [__main__:319] Number of frames: 500
2025-12-14 18:28:59 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-14 18:28:59 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-14 18:28:59 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-14 18:28:59 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-14 18:28:59 [INFO] [__main__:324] Delete existing: False
2025-12-14 18:28:59 [INFO] [__main__:324] Delete existing: False
2025-12-14 18:28:59 [INFO] [__main__:325] Resume mode: True
2025-12-14 18:28:59 [INFO] [__main__:325] Resume mode: True
2025-12-14 18:28:59 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765754939.log
2025-12-14 18:28:59 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765754939.log
2025-12-14 18:28:59 [INFO] [__main__:333] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:333] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:334] Checking prerequisites...
2025-12-14 18:28:59 [INFO] [__main__:335] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:334] Checking prerequisites...
2025-12-14 18:28:59 [INFO] [__main__:335] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 18:28:59 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 18:28:59 [INFO] [__main__:352] ✓ All model types are valid
2025-12-14 18:28:59 [INFO] [__main__:352] ✓ All model types are valid
2025-12-14 18:28:59 [INFO] [__main__:358] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:358] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:359] Initial memory statistics:
2025-12-14 18:28:59 [INFO] [__main__:359] Initial memory statistics:
2025-12-14 18:28:59 [INFO] [__main__:360] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:360] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: before training): {'cpu_memory_mb': 743.6953125, 'cpu_memory_gb': 0.7262649536132812, 'cpu_vms_mb': 10224.0078125, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-14 18:28:59 [INFO] [__main__:364] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-14 18:28:59 [INFO] [__main__:366] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-14 18:28:59 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-14 18:28:59 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-14 18:28:59 [INFO] [__main__:370] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-14 18:28:59 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-14 18:28:59 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: before training): {'cpu_memory_mb': 743.6484375, 'cpu_memory_gb': 0.7262191772460938, 'cpu_vms_mb': 10223.1328125, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-14 18:28:59 [INFO] [__main__:364] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-14 18:28:59 [INFO] [__main__:366] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-14 18:28:59 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-14 18:28:59 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-14 18:28:59 [INFO] [__main__:370] ================================================================================
2025-12-14 18:28:59 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-14 18:28:59 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1398] Applied global PyTorch memory optimizations at pipeline start
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1401] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1402] Stage 5: Model Training Pipeline Started
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1403] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1404] Model types: ['slowfast']
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1405] K-fold splits: 5
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1406] Frames per video: 500
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1407] Output directory: data/stage5
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1398] Applied global PyTorch memory optimizations at pipeline start
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1408] Initializing pipeline...
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1401] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1402] Stage 5: Model Training Pipeline Started
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1403] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1404] Model types: ['x3d']
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1405] K-fold splits: 5
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1406] Frames per video: 500
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1407] Output directory: data/stage5
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:261] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:1408] Initializing pipeline...
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:262] STAGE 5 PREREQUISITE VALIDATION
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:263] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:266] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:261] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:262] STAGE 5 PREREQUISITE VALIDATION
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:263] ================================================================================
2025-12-14 18:28:59 [INFO] [lib.training.pipeline:266] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:275] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:275] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:276]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:276]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:279] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:279] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:287] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:287] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:288]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:288]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:291] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:291] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:299] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:299] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:300]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:300]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:303] 
================================================================================
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:303] 
================================================================================
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:304] MODEL REQUIREMENTS CHECK
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:304] MODEL REQUIREMENTS CHECK
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:305] ================================================================================
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:305] ================================================================================
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:329] ✓ slowfast: CAN RUN
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:329] ✓ x3d: CAN RUN
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:332] 
================================================================================
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:332] 
================================================================================
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:333] VALIDATION SUMMARY
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:333] VALIDATION SUMMARY
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:334] ================================================================================
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:334] ================================================================================
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:335] Stage 3 (scaled videos): ✓ Available
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:336]   Count: 3278 videos
2025-12-14 18:29:00 [INFO] [lib.training.pipeline:335] Stage 3 (scaled videos): ✓ Available
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:337] Stage 2 (features): ✓ Available
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:336]   Count: 3278 videos
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:338]   Count: 3278 feature rows
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:337] Stage 2 (features): ✓ Available
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:339] Stage 4 (scaled features): ✓ Available
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:338]   Count: 3278 feature rows
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:340]   Count: 3277 feature rows
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:339] Stage 4 (scaled features): ✓ Available
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:341] 
Runnable models: 1/1
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:340]   Count: 3277 feature rows
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:342]   ['slowfast']
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:341] 
Runnable models: 1/1
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:349] ================================================================================
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:342]   ['x3d']
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:349] ================================================================================
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1492] 
Stage 5: Loading metadata...
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1492] 
Stage 5: Loading metadata...
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1518] Loaded metadata: 3278 rows
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1518] Loaded metadata: 3278 rows
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1528] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1528] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-14 18:29:01 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=824769.81GB, used=1675070.19GB (67.0%)
2025-12-14 18:29:01 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=824769.81GB, used=1675070.19GB (67.0%)
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1560] Stage 5: Found 3278 scaled videos
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1565] ================================================================================
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1560] Stage 5: Found 3278 scaled videos
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1566] STAGE 5: VALIDATING VIDEOS (checking for corruption and empty videos)
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1565] ================================================================================
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1567] ================================================================================
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1566] STAGE 5: VALIDATING VIDEOS (checking for corruption and empty videos)
2025-12-14 18:29:01 [INFO] [lib.training.pipeline:1567] ================================================================================
2025-12-14 18:29:01 [INFO] [lib.data.loading:156] Checking file existence for 3278 videos...
2025-12-14 18:29:01 [INFO] [lib.data.loading:156] Checking file existence for 3278 videos...
2025-12-14 18:29:04 [INFO] [lib.data.loading:166] Found 3278 existing video files (filtered out 0 missing files)
2025-12-14 18:29:04 [INFO] [lib.data.loading:166] Found 3278 existing video files (filtered out 0 missing files)
2025-12-14 18:29:04 [INFO] [lib.data.loading:170] Checking for corrupted videos (moov atom errors, etc.)...
2025-12-14 18:29:04 [INFO] [lib.data.loading:170] Checking for corrupted videos (moov atom errors, etc.)...
2025-12-14 18:29:04 [INFO] [lib.data.loading:92] Loaded validation cache from /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/.video_validation_cache/validation_0192be168a40eb7e_corruptTrue_framesTrue.parquet (3278 entries)
2025-12-14 18:29:04 [INFO] [lib.data.loading:92] Loaded validation cache from /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/.video_validation_cache/validation_0192be168a40eb7e_corruptTrue_framesTrue.parquet (3278 entries)
2025-12-14 18:29:04 [INFO] [lib.data.loading:194] Cache hit: 3278 videos, Cache miss: 0 videos
2025-12-14 18:29:04 [INFO] [lib.data.loading:194] Cache hit: 3278 videos, Cache miss: 0 videos
2025-12-14 18:29:04 [WARNING] [lib.data.loading:306] Filtered out 1 corrupted videos and 0 empty videos. Keeping 3277 valid videos.
2025-12-14 18:29:04 [WARNING] [lib.data.loading:306] Filtered out 1 corrupted videos and 0 empty videos. Keeping 3277 valid videos.
2025-12-14 18:29:04 [WARNING] [lib.data.loading:311] Sample of invalid videos:
2025-12-14 18:29:04 [WARNING] [lib.data.loading:311] Sample of invalid videos:
2025-12-14 18:29:04 [WARNING] [lib.data.loading:313]   data/scaled_videos/FX5aeuJFQ64_aug1_scaled_aug1.mp4: Corrupted video: moov atom not found
2025-12-14 18:29:04 [WARNING] [lib.data.loading:313]   data/scaled_videos/FX5aeuJFQ64_aug1_scaled_aug1.mp4: Corrupted video: moov atom not found
2025-12-14 18:29:04 [INFO] [lib.data.loading:323] Found /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/skip_frame_check.txt - skipping frame check as requested.
2025-12-14 18:29:04 [INFO] [lib.data.loading:323] Found /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/skip_frame_check.txt - skipping frame check as requested.
2025-12-14 18:29:04 [WARNING] [lib.data.loading:387] Filtered out 1 invalid videos (corrupted). Keeping 3277 valid videos.
2025-12-14 18:29:04 [WARNING] [lib.data.loading:387] Filtered out 1 invalid videos (corrupted). Keeping 3277 valid videos.
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1579] ✓ Video validation complete: 3277 valid videos ready for training
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1579] ✓ Video validation complete: 3277 valid videos ready for training
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1580] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1580] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1661] Enabling adaptive chunked frame loading for slowfast: initial_chunk_size=5, num_frames=500. Chunk size will adapt automatically based on OOM events (AIMD algorithm).
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1661] Enabling adaptive chunked frame loading for x3d: initial_chunk_size=5, num_frames=500. Chunk size will adapt automatically based on OOM events (AIMD algorithm).
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1676] Frame caching enabled (default): cache_dir=data/.frame_cache. This will cache processed frames to disk to speed up training. First epoch will be slower (building cache), subsequent epochs will be faster. To disable, set FVC_USE_FRAME_CACHE=0
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1676] Frame caching enabled (default): cache_dir=data/.frame_cache. This will cache processed frames to disk to speed up training. First epoch will be slower (building cache), subsequent epochs will be faster. To disable, set FVC_USE_FRAME_CACHE=0
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1812] 
================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1813] Stage 5: Training model: slowfast
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1812] 
================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1814] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1813] Stage 5: Training model: x3d
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1814] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1854] Grid search: 1 hyperparameter combinations to try
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1867] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1868] HYPERPARAMETER SEARCH: Using 10.0% stratified sample for efficiency
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1869] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1854] Grid search: 1 hyperparameter combinations to try
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1867] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1868] HYPERPARAMETER SEARCH: Using 10.0% stratified sample for efficiency
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1869] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1879] Hyperparameter search sample: 327 rows (10.0% of 3277 total)
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1879] Hyperparameter search sample: 327 rows (10.0% of 3277 total)
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1880] To change sample size, set FVC_GRID_SEARCH_SAMPLE_SIZE environment variable (current: 0.1)
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1880] To change sample size, set FVC_GRID_SEARCH_SAMPLE_SIZE environment variable (current: 0.1)
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1893] Using 5-fold stratified cross-validation on 10.0% sample for hyperparameter search
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1906] 
================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1907] Grid Search: Hyperparameter combination 1/1
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1908] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1909] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1893] Using 5-fold stratified cross-validation on 10.0% sample for hyperparameter search
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - slowfast - Fold 1/5 (10.0% sample)
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1906] 
================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1907] Grid Search: Hyperparameter combination 1/1
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1908] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1909] ================================================================================
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - x3d - Fold 1/5 (10.0% sample)
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 1...
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 1...
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:29:04 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:29:04 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:29:05 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:29:05 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:29:05 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:29:05 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:29:05 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:29:07 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:29:07 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:29:08 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:29:08 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:29:14 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d84f39be7fd24a9da11b4fd7113653f3 (experiment: slowfast)
2025-12-14 18:29:14 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 571b2c04938f487e89bbfdc37fbf4a18 (experiment: x3d)
2025-12-14 18:29:14 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:29:14 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:29:17 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:29:17 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:29:23 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:29:23 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:29:23 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:29:23 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:29:25 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:29:25 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:29:26 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:29:26 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:29:26 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 1
2025-12-14 18:29:26 [ERROR] [lib.training.pipeline:2027] Error training fold 1: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:29:27 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - slowfast - Fold 2/5 (10.0% sample)
2025-12-14 18:29:27 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 2...
2025-12-14 18:29:27 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:29:27 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:29:27 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:29:27 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:29:28 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:29:28 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:29:28 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 01ad9e236b864997907301148cb64426 (experiment: slowfast)
2025-12-14 18:29:28 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:29:30 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:29:32 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 120.19 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 92.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-14 18:29:32 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:29:32 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:29:32 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:29:32 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:29:34 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:29:38 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 120.19 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 92.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-14 18:29:40 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:29:49 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:29:49 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:29:49 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 2
2025-12-14 18:29:49 [ERROR] [lib.training.pipeline:2027] Error training fold 2: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:29:50 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - slowfast - Fold 3/5 (10.0% sample)
2025-12-14 18:29:50 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 3...
2025-12-14 18:29:50 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:29:50 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:29:50 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:29:50 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:29:51 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:29:51 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:29:51 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a3003a2eafef45ff8fe5a94b938704f9 (experiment: slowfast)
2025-12-14 18:29:51 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:29:53 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:29:55 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:29:55 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:29:55 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:29:55 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:29:55 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 120.19 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 92.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-14 18:29:57 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:29:57 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:29:57 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:29:57 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 3
2025-12-14 18:29:57 [ERROR] [lib.training.pipeline:2027] Error training fold 3: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:29:58 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - slowfast - Fold 4/5 (10.0% sample)
2025-12-14 18:29:58 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 4...
2025-12-14 18:29:58 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:29:58 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:29:58 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:29:58 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:29:58 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:29:58 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:29:59 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 486d474e3a914662a2145f2cd81ccac5 (experiment: slowfast)
2025-12-14 18:29:59 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:30:01 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:30:01 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 120.19 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 92.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1
2025-12-14 18:30:01 [ERROR] [lib.training.pipeline:2027] Error training fold 1: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 120.19 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 92.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 120.19 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 92.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:30:01 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - x3d - Fold 2/5 (10.0% sample)
2025-12-14 18:30:01 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 2...
2025-12-14 18:30:01 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:30:01 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:30:01 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:30:01 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:30:02 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:30:02 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:30:02 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 83db4c046a9440769a74014a3e7d28d3 (experiment: x3d)
2025-12-14 18:30:02 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:30:02 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:30:02 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:30:02 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:30:02 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:30:04 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:30:06 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:30:06 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:30:16 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:30:16 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:30:17 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 4
2025-12-14 18:30:17 [ERROR] [lib.training.pipeline:2027] Error training fold 4: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:30:17 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - slowfast - Fold 5/5 (10.0% sample)
2025-12-14 18:30:17 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 5...
2025-12-14 18:30:17 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:30:17 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:30:17 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:30:17 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:30:18 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:30:18 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:30:18 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: b4d4b851bf8b4db6b80c54821487e092 (experiment: slowfast)
2025-12-14 18:30:18 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:30:20 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:30:21 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-14 18:30:22 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:30:22 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:30:22 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:30:22 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:30:23 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:30:33 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:30:34 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:30:37 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:30:37 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:30:37 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 5
2025-12-14 18:30:37 [ERROR] [lib.training.pipeline:2027] Error training fold 5: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:2083] Using single parameter combination: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:2086] ================================================================================
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:2087] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:2088] ================================================================================
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:2101] Final training: Using 5-fold stratified cross-validation on full dataset (3277 rows)
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:2109] Final training using best hyperparameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:2115] 
Final Training - slowfast - Fold 1/5 (full dataset)
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 1...
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:30:37 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:30:37 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:30:37 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:30:39 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:30:39 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:30:39 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4824ed52b59a47d6adbc73e1930aec82 (experiment: slowfast)
2025-12-14 18:30:39 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:30:40 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-14 18:30:41 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:30:42 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:30:53 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:30:53 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:30:53 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:30:53 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:30:57 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-14 18:30:59 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:31:10 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:31:10 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:31:10 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 1
2025-12-14 18:31:10 [ERROR] [lib.training.pipeline:2208] Error training final fold 1: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:31:10 [INFO] [lib.training.pipeline:2115] 
Final Training - slowfast - Fold 2/5 (full dataset)
2025-12-14 18:31:10 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 2...
2025-12-14 18:31:10 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:31:10 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:31:10 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:31:10 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:31:11 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:31:11 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:31:11 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 6e36261332764981bd8c2c4d00e1f2f2 (experiment: slowfast)
2025-12-14 18:31:11 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:31:13 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:31:14 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2
2025-12-14 18:31:14 [ERROR] [lib.training.pipeline:2027] Error training fold 2: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:31:15 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - x3d - Fold 3/5 (10.0% sample)
2025-12-14 18:31:15 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 3...
2025-12-14 18:31:15 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:31:15 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:31:15 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:31:15 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:31:15 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:31:15 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:31:15 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 14b35dd95a924555b6009643044b41e3 (experiment: x3d)
2025-12-14 18:31:15 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:31:17 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:31:19 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:31:19 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:31:23 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:31:25 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:31:26 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:31:26 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:31:26 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:31:29 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:31:34 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-14 18:31:36 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:31:39 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:31:39 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:31:39 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 2
2025-12-14 18:31:39 [ERROR] [lib.training.pipeline:2208] Error training final fold 2: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:31:39 [INFO] [lib.training.pipeline:2115] 
Final Training - slowfast - Fold 3/5 (full dataset)
2025-12-14 18:31:39 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 3...
2025-12-14 18:31:39 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:31:39 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:31:39 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:31:39 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:31:40 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-14 18:31:41 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:31:41 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:31:41 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d69a3225d13143b0a332a665b6806ea8 (experiment: slowfast)
2025-12-14 18:31:41 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:31:42 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:31:43 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:31:44 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:31:44 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:31:44 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:31:44 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:31:56 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:31:56 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:31:56 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 3
2025-12-14 18:31:56 [ERROR] [lib.training.pipeline:2208] Error training final fold 3: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:31:56 [INFO] [lib.training.pipeline:2115] 
Final Training - slowfast - Fold 4/5 (full dataset)
2025-12-14 18:31:56 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 4...
2025-12-14 18:31:56 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:31:57 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:31:57 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:31:57 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:31:57 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:31:57 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:31:57 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-14 18:31:57 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7eeea5a29ff14e9cbed5de3b6c05340f (experiment: slowfast)
2025-12-14 18:31:57 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:31:59 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:31:59 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:32:00 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:32:00 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:32:00 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:32:00 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:32:03 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3
2025-12-14 18:32:03 [ERROR] [lib.training.pipeline:2027] Error training fold 3: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:32:03 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - x3d - Fold 4/5 (10.0% sample)
2025-12-14 18:32:03 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 4...
2025-12-14 18:32:03 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:32:03 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:32:03 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:32:03 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:32:04 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:32:04 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:32:04 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e08c5876114a499d87a7951545ba065f (experiment: x3d)
2025-12-14 18:32:04 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:32:06 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:32:08 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:32:08 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:32:12 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:32:15 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:32:15 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:32:15 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 4
2025-12-14 18:32:15 [ERROR] [lib.training.pipeline:2208] Error training final fold 4: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:32:15 [INFO] [lib.training.pipeline:2115] 
Final Training - slowfast - Fold 5/5 (full dataset)
2025-12-14 18:32:15 [INFO] [lib.training.pipeline:631] Training PyTorch model slowfast on fold 5...
2025-12-14 18:32:15 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-14 18:32:15 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:32:15 [INFO] [lib.training.slowfast:394] torchvision SlowFast not available. Trying PyTorch Hub (pytorchvideo)...
2025-12-14 18:32:15 [INFO] [lib.training.slowfast:192] Loading SlowFast R50 from PyTorch Hub (facebookresearch/pytorchvideo)...
2025-12-14 18:32:16 [INFO] [lib.training.slowfast:203] ✓ Verified SlowFast model structure: Net
2025-12-14 18:32:16 [INFO] [lib.training.slowfast:211] ✓ Loaded SlowFast from PyTorch Hub (pytorchvideo)
2025-12-14 18:32:16 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7464cd3d4c924f5ebf4f62a0343cb2d5 (experiment: slowfast)
2025-12-14 18:32:16 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training slowfast...
2025-12-14 18:32:18 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:32:19 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:32:19 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:32:19 [WARNING] [lib.training.pipeline:876] SlowFast temporal dimension mismatch during forward pass test: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: torch.Size([1, 3, 500, 256, 256]). Training will handle this via error handling. Continuing...
2025-12-14 18:32:19 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:32:23 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-14 18:32:25 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:32:32 [WARNING] [lib.training.slowfast:572] SlowFast temporal dimension mismatch with T=500, alpha=8. Slow pathway T: 63, Fast pathway T: 500. Attempting to adjust input temporal dimension for compatibility...
2025-12-14 18:32:32 [ERROR] [lib.training.slowfast:599] SlowFast temporal dimension adjustment failed: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.. Original error: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Input shape: (N=1, C=3, T=500, H=256, W=256)
2025-12-14 18:32:32 [ERROR] [lib.training.pipeline:1018] Runtime error during training: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.. Model: slowfast, Fold: 5
2025-12-14 18:32:32 [ERROR] [lib.training.pipeline:2208] Error training final fold 5: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 596, in forward
    return self.backbone([slow_x_padded, fast_x_padded])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 128 for tensor number 1 in the list.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 522, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 604, in forward
    raise e
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/slowfast.py", line 558, in forward
    return self.backbone([slow_x, fast_x])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 121, in forward
    x_out = self.multipathway_fusion(x_out)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/suzanef/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/slowfast.py", line 728, in forward
    x_s_fuse = torch.cat([x_s, fuse], 1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 63 but got size 125 for tensor number 1 in the list.
2025-12-14 18:32:32 [WARNING] [lib.training.pipeline:114] No model files found in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/slowfast/fold_1 to copy
2025-12-14 18:32:32 [INFO] [lib.training.pipeline:2281] 
slowfast - Avg Val Loss: nan, Avg Val Acc: nan, Avg Val F1: nan
2025-12-14 18:32:35 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:32:35 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/slowfast/plots/cv_fold_comparison.png
2025-12-14 18:32:35 [INFO] [lib.training.pipeline:2309] Generated plots for slowfast in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/slowfast/plots
2025-12-14 18:32:36 [INFO] [lib.training.pipeline:2346] ================================================================================
2025-12-14 18:32:36 [INFO] [lib.training.pipeline:2347] Stage 5: Model Training Pipeline Completed
2025-12-14 18:32:36 [INFO] [lib.training.pipeline:2348] ================================================================================
2025-12-14 18:32:36 [INFO] [__main__:401] ================================================================================
2025-12-14 18:32:36 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-14 18:32:36 [INFO] [__main__:403] ================================================================================
2025-12-14 18:32:36 [INFO] [__main__:404] Execution time: 216.62 seconds (3.61 minutes)
2025-12-14 18:32:36 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-14 18:32:36 [INFO] [__main__:407] Models trained: ['slowfast']
2025-12-14 18:32:36 [INFO] [__main__:408] K-fold splits: 5
2025-12-14 18:32:36 [INFO] [__main__:414] ================================================================================
2025-12-14 18:32:36 [INFO] [__main__:415] Final memory statistics:
2025-12-14 18:32:36 [INFO] [__main__:416] ================================================================================
2025-12-14 18:32:36 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: after training): {'cpu_memory_mb': 3349.84765625, 'cpu_memory_gb': 3.2713356018066406, 'cpu_vms_mb': 50708.8046875, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 1.379926016, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.548416}
2025-12-14 18:32:36 [INFO] [__main__:419] ================================================================================
2025-12-14 18:32:36 [INFO] [__main__:420] Training complete!
2025-12-14 18:32:36 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-14 18:32:36 [INFO] [__main__:422] ================================================================================
2025-12-14 18:32:40 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-14 18:32:42 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:32:56 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-14 18:32:58 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:33:13 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4
2025-12-14 18:33:13 [ERROR] [lib.training.pipeline:2027] Error training fold 4: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:33:13 [INFO] [lib.training.pipeline:1931] 
Hyperparameter Search - x3d - Fold 5/5 (10.0% sample)
2025-12-14 18:33:13 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 5...
2025-12-14 18:33:13 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:33:13 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:33:13 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:33:13 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:33:14 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:33:14 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:33:14 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1f7b4f966ab544858783e6a3b504ef56 (experiment: x3d)
2025-12-14 18:33:14 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:33:16 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:33:18 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:33:18 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:33:22 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-14 18:33:24 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:33:28 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-14 18:33:30 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:33:40 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:33:45 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-14 18:33:47 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:34:02 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5
2025-12-14 18:34:02 [ERROR] [lib.training.pipeline:2027] Error training fold 5: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1974, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:2083] Using single parameter combination: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:2086] ================================================================================
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:2087] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:2088] ================================================================================
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:2101] Final training: Using 5-fold stratified cross-validation on full dataset (3277 rows)
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:2109] Final training using best hyperparameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001, 'batch_size': 2}
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:2115] 
Final Training - x3d - Fold 1/5 (full dataset)
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 1...
2025-12-14 18:34:02 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:34:02 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:34:03 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:34:03 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:34:03 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:34:03 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:34:03 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e68e1c1bff66410ba837304538c20fb3 (experiment: x3d)
2025-12-14 18:34:03 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:34:05 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:34:07 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:34:07 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:34:23 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-14 18:34:25 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:34:35 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:34:40 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-14 18:34:42 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:34:57 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-14 18:34:59 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:35:16 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1
2025-12-14 18:35:16 [ERROR] [lib.training.pipeline:2208] Error training final fold 1: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:35:16 [INFO] [lib.training.pipeline:2115] 
Final Training - x3d - Fold 2/5 (full dataset)
2025-12-14 18:35:16 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 2...
2025-12-14 18:35:16 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:35:16 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:35:16 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:35:16 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:35:17 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:35:17 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:35:17 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a86a90847fc74542ad5aed073464f903 (experiment: x3d)
2025-12-14 18:35:17 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:35:19 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:35:20 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:35:21 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:35:31 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:35:36 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-14 18:35:38 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:35:54 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-14 18:35:56 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:36:12 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-14 18:36:14 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:36:24 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:36:29 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2
2025-12-14 18:36:29 [ERROR] [lib.training.pipeline:2208] Error training final fold 2: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:36:29 [INFO] [lib.training.pipeline:2115] 
Final Training - x3d - Fold 3/5 (full dataset)
2025-12-14 18:36:29 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 3...
2025-12-14 18:36:29 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:36:29 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:36:29 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:36:29 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:36:30 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:36:30 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:36:30 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d018f69e20d64b6181f80e659f3c86a9 (experiment: x3d)
2025-12-14 18:36:30 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:36:32 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:36:33 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:36:34 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:36:53 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-14 18:36:54 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:37:09 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-14 18:37:11 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:37:21 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:37:27 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-14 18:37:29 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:37:44 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3
2025-12-14 18:37:44 [ERROR] [lib.training.pipeline:2208] Error training final fold 3: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:37:44 [INFO] [lib.training.pipeline:2115] 
Final Training - x3d - Fold 4/5 (full dataset)
2025-12-14 18:37:44 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 4...
2025-12-14 18:37:44 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:37:44 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:37:45 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:37:45 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:37:45 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:37:45 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:37:46 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 49d481826b58476d8596f5ac50367af6 (experiment: x3d)
2025-12-14 18:37:46 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:37:48 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:37:49 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:37:49 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:38:05 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-14 18:38:06 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:38:16 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:38:21 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-14 18:38:23 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:38:39 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-14 18:38:41 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:38:57 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4
2025-12-14 18:38:57 [ERROR] [lib.training.pipeline:2208] Error training final fold 4: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:38:57 [INFO] [lib.training.pipeline:2115] 
Final Training - x3d - Fold 5/5 (full dataset)
2025-12-14 18:38:57 [INFO] [lib.training.pipeline:631] Training PyTorch model x3d on fold 5...
2025-12-14 18:38:57 [WARNING] [lib.training.pipeline:656] x3d model requires batch_size<=1 to prevent OOM. Overriding batch_size from 2 to 1. Adjusting gradient_accumulation_steps to maintain effective batch size of 64.
2025-12-14 18:38:57 [INFO] [lib.training.pipeline:666] Training configuration - Batch size: 1, Gradient accumulation steps: 64, Effective batch size: 64
2025-12-14 18:38:57 [INFO] [lib.training.pipeline:714] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-14 18:38:57 [INFO] [lib.training.x3d:48] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-14 18:38:58 [INFO] [lib.training.x3d:141] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-14 18:38:58 [INFO] [lib.training.x3d:142] ✓ Verified X3D model structure: Net
2025-12-14 18:38:58 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f17df78e8eb04168845f5a20083ec3cc (experiment: x3d)
2025-12-14 18:38:58 [INFO] [lib.training.pipeline:788] Performing HYPER-AGGRESSIVE GC before training x3d...
2025-12-14 18:39:00 [INFO] [lib.training.pipeline:800] Hyper-aggressive GC complete. GPU memory cleared.
2025-12-14 18:39:02 [INFO] [lib.training.pipeline:860] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-14 18:39:02 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:39:20 [INFO] [lib.models.video:462] Chunk size increased from 10 to 20 (after 3 successes, increment: 10)
2025-12-14 18:39:26 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-14 18:39:28 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:39:31 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-14 18:39:33 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:39:48 [WARNING] [lib.training.pipeline:994] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-14 18:39:50 [INFO] [lib.training.trainer:380] Warmup will be handled in training loop (2 epochs)
2025-12-14 18:40:05 [ERROR] [lib.training.pipeline:1016] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5
2025-12-14 18:40:05 [ERROR] [lib.training.pipeline:2208] Error training final fold 5: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2157, in stage5_train_models
    result = _train_pytorch_model_fold(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 953, in _train_pytorch_model_fold
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 915, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 587, in train_one_epoch
    scaler.scale(loss).backward()
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1154, in unpack_hook
    _run_fn_with_dynamo_disabled(frame.recompute_fn, *args)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in _run_fn_with_dynamo_disabled
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1555, in recompute_fn
    fn(*args, **kwargs)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 312, in checkpointed_forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1399, in forward
    x = res_block(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1186, in forward
    x = self.branch_fusion(shortcut, self.branch2(x))
                                     ^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/resnet.py", line 1352, in forward
    x = self.act_a(x)
        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/activation.py", line 144, in forward
    return F.relu(input, inplace=self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/functional.py", line 1697, in relu
    result = torch.relu(input)
             ^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 100.19 MiB is free. Including non-PyTorch memory, this process has 15.66 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 112.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-14 18:40:05 [WARNING] [lib.training.pipeline:114] No model files found in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/fold_1 to copy
2025-12-14 18:40:05 [INFO] [lib.training.pipeline:2281] 
x3d - Avg Val Loss: nan, Avg Val Acc: nan, Avg Val F1: nan
2025-12-14 18:40:07 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/plots/cv_fold_comparison.png
2025-12-14 18:40:07 [INFO] [lib.training.pipeline:2309] Generated plots for x3d in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/plots
2025-12-14 18:40:07 [INFO] [lib.training.pipeline:2346] ================================================================================
2025-12-14 18:40:07 [INFO] [lib.training.pipeline:2347] Stage 5: Model Training Pipeline Completed
2025-12-14 18:40:07 [INFO] [lib.training.pipeline:2348] ================================================================================
2025-12-14 18:40:07 [INFO] [__main__:401] ================================================================================
2025-12-14 18:40:07 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-14 18:40:07 [INFO] [__main__:403] ================================================================================
2025-12-14 18:40:07 [INFO] [__main__:404] Execution time: 668.07 seconds (11.13 minutes)
2025-12-14 18:40:07 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-14 18:40:07 [INFO] [__main__:407] Models trained: ['x3d']
2025-12-14 18:40:07 [INFO] [__main__:408] K-fold splits: 5
2025-12-14 18:40:07 [INFO] [__main__:414] ================================================================================
2025-12-14 18:40:07 [INFO] [__main__:415] Final memory statistics:
2025-12-14 18:40:07 [INFO] [__main__:416] ================================================================================
2025-12-14 18:40:07 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: after training): {'cpu_memory_mb': 2284.12109375, 'cpu_memory_gb': 2.2305870056152344, 'cpu_vms_mb': 49652.94921875, 'gpu_allocated_gb': 0.01703936, 'gpu_reserved_gb': 16.412311552, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.516030464}
2025-12-14 18:40:07 [INFO] [__main__:419] ================================================================================
2025-12-14 18:40:07 [INFO] [__main__:420] Training complete!
2025-12-14 18:40:07 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-14 18:40:07 [INFO] [__main__:422] ================================================================================
