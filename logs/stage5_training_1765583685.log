2025-12-12 18:54:45 [INFO] [__main__:310] ================================================================================
2025-12-12 18:54:45 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-12 18:54:45 [INFO] [__main__:312] ================================================================================
2025-12-12 18:54:45 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-12 18:54:45 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 18:54:45 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 18:54:45 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 18:54:45 [INFO] [__main__:317] Model types: ['x3d']
2025-12-12 18:54:45 [INFO] [__main__:318] K-fold splits: 5
2025-12-12 18:54:45 [INFO] [__main__:319] Number of frames: 500
2025-12-12 18:54:45 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 18:54:45 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-12 18:54:45 [INFO] [__main__:324] Delete existing: False
2025-12-12 18:54:45 [INFO] [__main__:325] Resume mode: True
2025-12-12 18:54:45 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765583685.log
2025-12-12 18:54:45 [INFO] [__main__:333] ================================================================================
2025-12-12 18:54:45 [INFO] [__main__:334] Checking prerequisites...
2025-12-12 18:54:45 [INFO] [__main__:335] ================================================================================
2025-12-12 18:54:45 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 18:54:45 [INFO] [__main__:352] ✓ All model types are valid
2025-12-12 18:54:45 [INFO] [__main__:358] ================================================================================
2025-12-12 18:54:45 [INFO] [__main__:359] Initial memory statistics:
2025-12-12 18:54:45 [INFO] [__main__:360] ================================================================================
2025-12-12 18:54:45 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.58984375, 'cpu_memory_gb': 0.7183494567871094, 'cpu_vms_mb': 10217.68359375, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-12 18:54:45 [INFO] [__main__:364] ================================================================================
2025-12-12 18:54:45 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-12 18:54:45 [INFO] [__main__:366] ================================================================================
2025-12-12 18:54:45 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-12 18:54:45 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-12 18:54:45 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-12 18:54:45 [INFO] [__main__:370] ================================================================================
2025-12-12 18:54:45 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-12 18:54:45 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:490] ================================================================================
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:491] Stage 5: Model Training Pipeline Started
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:492] ================================================================================
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:493] Model types: ['x3d']
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:494] K-fold splits: 5
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:495] Frames per video: 500
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:496] Output directory: data/stage5
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:497] Initializing pipeline...
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:265] ================================================================================
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:266] STAGE 5 PREREQUISITE VALIDATION
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:267] ================================================================================
2025-12-12 18:54:45 [INFO] [lib.training.pipeline:270] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-12 18:54:48 [INFO] [lib.training.pipeline:279] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-12 18:54:48 [INFO] [lib.training.pipeline:280]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 18:54:48 [INFO] [lib.training.pipeline:283] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:291] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:292]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:295] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:303] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:304]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:307] 
================================================================================
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:308] MODEL REQUIREMENTS CHECK
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:309] ================================================================================
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:333] ✓ x3d: CAN RUN
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:336] 
================================================================================
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:337] VALIDATION SUMMARY
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:338] ================================================================================
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:339] Stage 3 (scaled videos): ✓ Available
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:340]   Count: 3278 videos
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:341] Stage 2 (features): ✓ Available
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:342]   Count: 3278 feature rows
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:343] Stage 4 (scaled features): ✓ Available
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:344]   Count: 3277 feature rows
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:345] 
Runnable models: 1/1
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:346]   ['x3d']
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:353] ================================================================================
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:583] 
Stage 5: Loading metadata...
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:609] Loaded metadata: 3278 rows
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:619] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-12 18:54:49 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=833809.25GB, used=1666030.75GB (66.6%)
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:651] Stage 5: Found 3278 scaled videos
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:675] Enabling adaptive chunked frame loading for x3d: initial_chunk_size=200, num_frames=500. Chunk size will adapt automatically based on OOM events (AIMD algorithm).
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:747] 
================================================================================
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:748] Stage 5: Training model: x3d
2025-12-12 18:54:49 [INFO] [lib.training.pipeline:749] ================================================================================
2025-12-12 18:54:51 [INFO] [lib.training.pipeline:773] Grid search: 16 hyperparameter combinations to try
2025-12-12 18:54:51 [INFO] [lib.training.pipeline:781] ================================================================================
2025-12-12 18:54:51 [INFO] [lib.training.pipeline:782] HYPERPARAMETER SEARCH: Using 20% stratified sample for efficiency
2025-12-12 18:54:51 [INFO] [lib.training.pipeline:783] ================================================================================
2025-12-12 18:54:52 [INFO] [lib.training.pipeline:792] Hyperparameter search sample: 655 rows (20.0% of 3278 total)
2025-12-12 18:54:54 [INFO] [lib.training.pipeline:805] Using 5-fold stratified cross-validation on 20% sample for hyperparameter search
2025-12-12 18:54:54 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:54:54 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 1/16
2025-12-12 18:54:54 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001}
2025-12-12 18:54:54 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:54:54 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 18:54:54 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:54:54 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:54:57 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:54:57 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:54:58 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:55:04 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 178525bee9684446a0dae403c2a5dc8b (experiment: x3d)
2025-12-12 18:55:04 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 18:55:17 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:55:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:55:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:55:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 2211.94921875, 'cpu_memory_gb': 2.160106658935547, 'cpu_vms_mb': 49328.9921875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.702887424, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.225454592}
2025-12-12 18:55:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:55:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:55:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:55:28 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:55:28 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 2212.0703125, 'cpu_memory_gb': 2.1602249145507812, 'cpu_vms_mb': 49328.9921875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.702887424, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.225454592}
2025-12-12 18:55:28 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:55:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:55:33 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:55:33 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 2582.421875, 'cpu_memory_gb': 2.5218963623046875, 'cpu_vms_mb': 49698.7578125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.702887424, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.225454592}
2025-12-12 18:55:33 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:55:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:55:36 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:55:37 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 2582.43359375, 'cpu_memory_gb': 2.5219078063964844, 'cpu_vms_mb': 49698.7578125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.702887424, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.225454592}
2025-12-12 18:55:37 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 18:55:37 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 45.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:55:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 178525bee9684446a0dae403c2a5dc8b
2025-12-12 18:55:37 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 18:55:37 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:55:37 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:55:38 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:55:38 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:55:38 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:55:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 61c28246ef9d4637a36d7082e2435733 (experiment: x3d)
2025-12-12 18:55:38 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 18:55:39 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:55:40 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:55:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:55:49 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.62 GiB is free. Including non-PyTorch memory, this process has 3.15 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 39.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:55:49 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.5546875, 'cpu_memory_gb': 3.6411666870117188, 'cpu_vms_mb': 87260.97265625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.208301056, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.72004096}
2025-12-12 18:55:49 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.62 GiB is free. Including non-PyTorch memory, this process has 3.15 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 39.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:55:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:55:53 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.28 GiB is free. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:55:53 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.96875, 'cpu_memory_gb': 3.641571044921875, 'cpu_vms_mb': 87260.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.684013056, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.24432896}
2025-12-12 18:55:53 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.28 GiB is free. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:55:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:55:57 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:55:59 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.28 GiB is free. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:55:59 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.25390625, 'cpu_memory_gb': 3.6418495178222656, 'cpu_vms_mb': 87261.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.684013056, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.24432896}
2025-12-12 18:55:59 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.28 GiB is free. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:55:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.28 GiB is free. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.265625, 'cpu_memory_gb': 3.6418609619140625, 'cpu_vms_mb': 87261.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.684013056, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.24432896}
2025-12-12 18:56:02 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.28 GiB is free. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 18:56:02 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.28 GiB is free. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.28 GiB is free. Including non-PyTorch memory, this process has 2.48 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 27.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:02 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 61c28246ef9d4637a36d7082e2435733
2025-12-12 18:56:02 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 18:56:02 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:56:02 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:56:03 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:56:03 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:56:03 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:56:03 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7cf5f76504cd47ffa2780c371fc06626 (experiment: x3d)
2025-12-12 18:56:03 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 18:56:05 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:56:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:08 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:56:09 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 67.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:09 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.28125, 'cpu_memory_gb': 3.640899658203125, 'cpu_vms_mb': 87260.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.725956096, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.20238592}
2025-12-12 18:56:09 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 67.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:56:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:12 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 67.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:12 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.28125, 'cpu_memory_gb': 3.640899658203125, 'cpu_vms_mb': 87260.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.725956096, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.20238592}
2025-12-12 18:56:12 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 67.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:56:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.21 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.30 GiB is free. Including non-PyTorch memory, this process has 2.46 GiB memory in use. Of the allocated memory 2.01 GiB is allocated by PyTorch, and 90.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.28125, 'cpu_memory_gb': 3.640899658203125, 'cpu_vms_mb': 87260.97265625, 'gpu_allocated_gb': 1.589748736, 'gpu_reserved_gb': 1.684013056, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.24432896}
2025-12-12 18:56:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.21 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.30 GiB is free. Including non-PyTorch memory, this process has 2.46 GiB memory in use. Of the allocated memory 2.01 GiB is allocated by PyTorch, and 90.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:56:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:15 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:56:17 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 67.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:17 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.28125, 'cpu_memory_gb': 3.640899658203125, 'cpu_vms_mb': 87260.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.725956096, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.20238592}
2025-12-12 18:56:17 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 67.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 18:56:17 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 67.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 67.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:17 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7cf5f76504cd47ffa2780c371fc06626
2025-12-12 18:56:17 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 18:56:17 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:56:17 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:56:17 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:56:17 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:56:18 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:56:18 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a9f6355c0e204ced84420e1a7d58dd10 (experiment: x3d)
2025-12-12 18:56:18 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 18:56:20 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:56:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:23 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:23 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.28125, 'cpu_memory_gb': 3.640899658203125, 'cpu_vms_mb': 87260.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.728053248, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.200288768}
2025-12-12 18:56:23 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:56:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:56:28 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 25.34 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.85 GiB is free. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.47 GiB is allocated by PyTorch, and 69.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:28 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.28125, 'cpu_memory_gb': 3.640899658203125, 'cpu_vms_mb': 123676.97265625, 'gpu_allocated_gb': 2.723316736, 'gpu_reserved_gb': 2.797600768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.130741248}
2025-12-12 18:56:28 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 25.34 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.85 GiB is free. Including non-PyTorch memory, this process has 3.91 GiB memory in use. Of the allocated memory 3.47 GiB is allocated by PyTorch, and 69.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:56:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:31 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.28125, 'cpu_memory_gb': 3.640899658203125, 'cpu_vms_mb': 123676.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.728053248, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.200288768}
2025-12-12 18:56:31 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:56:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:37 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.70 GiB is free. Including non-PyTorch memory, this process has 4.07 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 90.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:37 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.58203125, 'cpu_memory_gb': 3.641193389892578, 'cpu_vms_mb': 160092.97265625, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.923429888, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.004912128}
2025-12-12 18:56:37 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.70 GiB is free. Including non-PyTorch memory, this process has 4.07 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 90.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 18:56:37 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.70 GiB is free. Including non-PyTorch memory, this process has 4.07 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 90.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.70 GiB is free. Including non-PyTorch memory, this process has 4.07 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 90.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a9f6355c0e204ced84420e1a7d58dd10
2025-12-12 18:56:37 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 18:56:37 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:56:37 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:56:38 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:56:38 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:56:38 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:56:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0fac34a160e1408694abeb81a6895ac9 (experiment: x3d)
2025-12-12 18:56:38 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 18:56:39 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:56:40 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:56:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:43 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:43 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.58203125, 'cpu_memory_gb': 3.641193389892578, 'cpu_vms_mb': 160092.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 18:56:43 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:56:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:48 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:49 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.5859375, 'cpu_memory_gb': 3.6411972045898438, 'cpu_vms_mb': 196508.97265625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.273312768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.655029248}
2025-12-12 18:56:49 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:56:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:50 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:56:51 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 96.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:52 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.5859375, 'cpu_memory_gb': 3.6411972045898438, 'cpu_vms_mb': 196508.97265625, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 18:56:52 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 96.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:56:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:54 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 104.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:54 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.5859375, 'cpu_memory_gb': 3.6411972045898438, 'cpu_vms_mb': 196508.97265625, 'gpu_allocated_gb': 1.610740736, 'gpu_reserved_gb': 1.728053248, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.200288768}
2025-12-12 18:56:54 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 104.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 18:56:54 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 104.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 104.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:56:54 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0fac34a160e1408694abeb81a6895ac9
2025-12-12 18:56:55 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:56:55 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 2/16
2025-12-12 18:56:55 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001}
2025-12-12 18:56:55 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:56:55 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 18:56:55 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:56:55 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:56:55 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:56:55 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:56:55 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:56:55 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 50f6de0008ce46fa9953ed87c0181892 (experiment: x3d)
2025-12-12 18:56:55 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 18:56:57 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:56:58 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:56:59 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:57:00 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 76.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:01 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.5859375, 'cpu_memory_gb': 3.6411972045898438, 'cpu_vms_mb': 196508.97265625, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.728053248, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.200288768}
2025-12-12 18:57:01 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 76.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:57:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:04 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:04 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.6796875, 'cpu_memory_gb': 3.6412887573242188, 'cpu_vms_mb': 196508.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.728053248, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.200288768}
2025-12-12 18:57:04 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:57:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:08 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.57 GiB is free. Including non-PyTorch memory, this process has 3.19 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 81.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:08 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.1171875, 'cpu_memory_gb': 3.6407394409179688, 'cpu_vms_mb': 232923.97265625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.252341248, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.676000768}
2025-12-12 18:57:08 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.57 GiB is free. Including non-PyTorch memory, this process has 3.19 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 81.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:57:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:09 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:57:10 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:10 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.1171875, 'cpu_memory_gb': 3.6407394409179688, 'cpu_vms_mb': 232923.97265625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.728053248, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.200288768}
2025-12-12 18:57:10 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 18:57:10 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 69.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:10 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 50f6de0008ce46fa9953ed87c0181892
2025-12-12 18:57:11 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 18:57:11 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:57:11 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:57:11 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:57:11 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:57:11 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:57:11 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: bdedc2fffd764b7b9c09a1c31418da2e (experiment: x3d)
2025-12-12 18:57:11 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 18:57:13 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:57:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:22 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:22 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4637.71875, 'cpu_memory_gb': 4.529022216796875, 'cpu_vms_mb': 233834.3671875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 18:57:22 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:57:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:23 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:57:25 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:25 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.70703125, 'cpu_memory_gb': 3.642292022705078, 'cpu_vms_mb': 232926.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 18:57:25 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:57:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:29 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:29 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.734375, 'cpu_memory_gb': 3.6423187255859375, 'cpu_vms_mb': 232926.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 18:57:29 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:57:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:32 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:32 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.734375, 'cpu_memory_gb': 3.6423187255859375, 'cpu_vms_mb': 269342.3203125, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.441084928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.487257088}
2025-12-12 18:57:32 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 18:57:32 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:32 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: bdedc2fffd764b7b9c09a1c31418da2e
2025-12-12 18:57:33 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 18:57:33 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:57:33 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:57:33 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:57:33 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:57:34 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:57:34 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0fd1eb21a9b1452ab82bf69c9cffcd7b (experiment: x3d)
2025-12-12 18:57:34 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 18:57:35 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 18:57:36 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:57:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:40 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:40 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.734375, 'cpu_memory_gb': 3.6423187255859375, 'cpu_vms_mb': 269342.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 18:57:40 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:57:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:43 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:43 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.734375, 'cpu_memory_gb': 3.6423187255859375, 'cpu_vms_mb': 269342.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 18:57:43 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:57:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:44 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:57:46 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 2.80 GiB memory in use. Of the allocated memory 2.31 GiB is allocated by PyTorch, and 126.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:46 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.734375, 'cpu_memory_gb': 3.6423187255859375, 'cpu_vms_mb': 269342.3203125, 'gpu_allocated_gb': 1.820660736, 'gpu_reserved_gb': 1.937768448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.990573568}
2025-12-12 18:57:46 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 2.80 GiB memory in use. Of the allocated memory 2.31 GiB is allocated by PyTorch, and 126.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:57:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:50 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:50 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.734375, 'cpu_memory_gb': 3.6423187255859375, 'cpu_vms_mb': 269342.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 18:57:50 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 18:57:50 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:50 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0fd1eb21a9b1452ab82bf69c9cffcd7b
2025-12-12 18:57:50 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 18:57:50 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:57:50 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:57:50 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:57:50 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:57:51 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:57:51 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 63f97f93870d47c0abb7bf80019d81cd (experiment: x3d)
2025-12-12 18:57:51 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 18:57:53 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:57:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:57:55 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:57:57 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.38 GiB is free. Including non-PyTorch memory, this process has 3.38 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 114.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:57:57 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 305757.3203125, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.399141888, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.529200128}
2025-12-12 18:57:57 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.38 GiB is free. Including non-PyTorch memory, this process has 3.38 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 114.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:57:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:00 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:00 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 305757.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 18:58:00 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:58:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 305757.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 18:58:02 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:58:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:04 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:58:06 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.99 GiB is allocated by PyTorch, and 110.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 342173.3203125, 'gpu_allocated_gb': 2.345460736, 'gpu_reserved_gb': 2.462056448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.466285568}
2025-12-12 18:58:06 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 21.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.99 GiB is allocated by PyTorch, and 110.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 18:58:06 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 21.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.99 GiB is allocated by PyTorch, and 110.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.99 GiB is allocated by PyTorch, and 110.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:06 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 63f97f93870d47c0abb7bf80019d81cd
2025-12-12 18:58:07 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 18:58:07 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:58:07 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:58:07 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:58:07 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:58:07 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:58:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f4697bfd75d24b089f9c54bd767f1377 (experiment: x3d)
2025-12-12 18:58:07 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 18:58:09 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:58:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:12 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:13 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 342173.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 18:58:13 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:58:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:14 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:58:15 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:15 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 342173.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 18:58:15 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:58:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:18 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:18 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 342173.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 18:58:18 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:58:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:21 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 342173.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 18:58:21 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 18:58:21 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:21 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f4697bfd75d24b089f9c54bd767f1377
2025-12-12 18:58:21 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:58:21 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 3/16
2025-12-12 18:58:21 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-12 18:58:21 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:58:21 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 18:58:21 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:58:21 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:58:22 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:58:22 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:58:23 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:58:23 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ec383d50407b4bed8d4352032c588121 (experiment: x3d)
2025-12-12 18:58:23 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 18:58:24 [INFO] [lib.models.video:417] Chunk size increased from 220 to 230 (after 3 successes, increment: 10)
2025-12-12 18:58:24 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:58:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:29 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:29 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3728.734375, 'cpu_memory_gb': 3.6413421630859375, 'cpu_vms_mb': 342173.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 18:58:29 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:58:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:34 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:35 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.1875, 'cpu_memory_gb': 3.64178466796875, 'cpu_vms_mb': 342173.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 18:58:35 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:58:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:37 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:58:39 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:39 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.1875, 'cpu_memory_gb': 3.64178466796875, 'cpu_vms_mb': 378589.3203125, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 18:58:39 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 18:58:39 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:42 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:42 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.1875, 'cpu_memory_gb': 3.64178466796875, 'cpu_vms_mb': 378589.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 18:58:42 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 18:58:42 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:42 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: ec383d50407b4bed8d4352032c588121
2025-12-12 18:58:42 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 18:58:42 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:58:42 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:58:43 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:58:43 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:58:43 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:58:43 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ecbefefc82db4137b72d417641955dfe (experiment: x3d)
2025-12-12 18:58:43 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 18:58:45 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:58:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:46 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:58:48 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:48 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3729.1875, 'cpu_memory_gb': 3.64178466796875, 'cpu_vms_mb': 378589.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 18:58:48 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:58:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:54 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:54 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3731.140625, 'cpu_memory_gb': 3.6436920166015625, 'cpu_vms_mb': 378591.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 18:58:54 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:58:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:58:57 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:58:57 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3731.140625, 'cpu_memory_gb': 3.6436920166015625, 'cpu_vms_mb': 415007.3203125, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.441084928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.487257088}
2025-12-12 18:58:57 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 18:58:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:01 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:59:03 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:03 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3731.6171875, 'cpu_memory_gb': 3.6441574096679688, 'cpu_vms_mb': 415008.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 18:59:03 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 18:59:03 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:03 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: ecbefefc82db4137b72d417641955dfe
2025-12-12 18:59:03 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 18:59:03 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:59:03 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:59:04 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:59:04 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:59:04 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:59:04 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c6c6754db81a4eabb955b2c23fca19f3 (experiment: x3d)
2025-12-12 18:59:04 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 18:59:06 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:59:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:10 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 13.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.36 GiB is free. Including non-PyTorch memory, this process has 2.41 GiB memory in use. Of the allocated memory 1.90 GiB is allocated by PyTorch, and 143.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:10 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.6171875, 'cpu_memory_gb': 3.6431808471679688, 'cpu_vms_mb': 415007.3203125, 'gpu_allocated_gb': 1.505780736, 'gpu_reserved_gb': 1.644167168, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.284174848}
2025-12-12 18:59:10 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 13.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.36 GiB is free. Including non-PyTorch memory, this process has 2.41 GiB memory in use. Of the allocated memory 1.90 GiB is allocated by PyTorch, and 143.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:59:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:12 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:59:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.98 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 153.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.6171875, 'cpu_memory_gb': 3.6431808471679688, 'cpu_vms_mb': 451423.3203125, 'gpu_allocated_gb': 2.177524736, 'gpu_reserved_gb': 2.336227328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.592114688}
2025-12-12 18:59:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.98 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 153.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:59:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:17 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:17 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.6171875, 'cpu_memory_gb': 3.6431808471679688, 'cpu_vms_mb': 451423.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 18:59:17 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 18:59:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:22 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:23 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3731.921875, 'cpu_memory_gb': 3.6444549560546875, 'cpu_vms_mb': 451424.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 18:59:23 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 18:59:23 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:23 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c6c6754db81a4eabb955b2c23fca19f3
2025-12-12 18:59:23 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 18:59:23 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:59:23 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:59:24 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:59:24 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:59:24 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:59:24 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a20132dcbb594f779260b5826f34c5c4 (experiment: x3d)
2025-12-12 18:59:24 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 18:59:25 [INFO] [lib.models.video:417] Chunk size increased from 230 to 240 (after 3 successes, increment: 10)
2025-12-12 18:59:26 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:59:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:30 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 184.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:30 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 487839.3203125, 'gpu_allocated_gb': 2.093556736, 'gpu_reserved_gb': 2.273312768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.655029248}
2025-12-12 18:59:30 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 184.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:59:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:34 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:34 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 487839.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 18:59:34 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:59:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:36 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:59:38 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:38 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 487839.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 18:59:38 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 18:59:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:42 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 181.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:42 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 524255.3203125, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.357198848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.571143168}
2025-12-12 18:59:42 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 181.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 18:59:42 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 181.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 181.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:42 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a20132dcbb594f779260b5826f34c5c4
2025-12-12 18:59:42 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 18:59:42 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 18:59:42 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 18:59:42 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 18:59:42 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 18:59:43 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 18:59:43 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: dbef02983fd14d128ff18269f0fa6382 (experiment: x3d)
2025-12-12 18:59:43 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 18:59:45 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 18:59:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:47 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 18:59:48 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:48 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 524255.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 18:59:48 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:59:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:52 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.36 GiB is free. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 134.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:52 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 560671.3203125, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.420113408, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.508228608}
2025-12-12 18:59:52 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.36 GiB is free. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 134.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:59:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:57 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:59:57 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 597087.3203125, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.965372928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.962969088}
2025-12-12 18:59:57 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 18:59:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:59:58 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:00:00 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:00 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 597087.3203125, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:00:00 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:00:00 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:00 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: dbef02983fd14d128ff18269f0fa6382
2025-12-12 19:00:01 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:00:01 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 4/16
2025-12-12 19:00:01 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001}
2025-12-12 19:00:01 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:00:01 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:00:01 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:00:01 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:00:01 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:00:01 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:00:01 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:00:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 95af7bfbaddb4d9fb2138999a46b9f36 (experiment: x3d)
2025-12-12 19:00:01 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:00:03 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:00:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:07 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:07 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 597087.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:00:07 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:00:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:08 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:00:10 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:10 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 633503.3203125, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.336227328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.592114688}
2025-12-12 19:00:10 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:00:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:15 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process has 4.14 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 170.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:15 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 669919.3203125, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 3.007315968, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.921026048}
2025-12-12 19:00:15 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process has 4.14 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 170.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:00:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:18 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:18 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 669919.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:00:18 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:00:18 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:18 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 95af7bfbaddb4d9fb2138999a46b9f36
2025-12-12 19:00:18 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:00:18 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:00:18 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:00:18 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:00:18 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:00:19 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:00:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8c0e86ecf9c94a6681a94be35931ce17 (experiment: x3d)
2025-12-12 19:00:19 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:00:20 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:00:20 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:00:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 706335.3203125, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:00:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:00:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:28 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:28 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3730.9375, 'cpu_memory_gb': 3.64349365234375, 'cpu_vms_mb': 706335.3203125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:00:28 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:00:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:33 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:00:34 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:34 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 706351.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:00:34 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:00:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:38 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:38 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 742767.30859375, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:00:38 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:00:38 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:38 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8c0e86ecf9c94a6681a94be35931ce17
2025-12-12 19:00:38 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:00:38 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:00:38 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:00:39 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:00:39 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:00:39 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:00:39 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: bca4168e87004a9d8d6162dc2c5c1a36 (experiment: x3d)
2025-12-12 19:00:39 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:00:41 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:00:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:43 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:00:45 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:45 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 742767.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:00:45 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:00:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:49 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 194.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:49 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 779183.30859375, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.483027968, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.445314048}
2025-12-12 19:00:49 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 194.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:00:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:52 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:52 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 779183.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:00:52 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:00:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:00:53 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:00:55 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 184.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:55 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 815599.30859375, 'gpu_allocated_gb': 2.093556736, 'gpu_reserved_gb': 2.273312768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.655029248}
2025-12-12 19:00:55 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 184.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:00:55 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 184.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 184.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:00:55 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: bca4168e87004a9d8d6162dc2c5c1a36
2025-12-12 19:00:56 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:00:56 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:00:56 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:00:56 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:00:56 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:00:56 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:00:56 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f2e80f0b77a4476bb301fa5551bab57e (experiment: x3d)
2025-12-12 19:00:56 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:00:58 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:00:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 815599.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:01:02 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:01:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:04 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:01:05 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:05 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 815599.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:01:05 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:01:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:09 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:09 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 852015.30859375, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:01:09 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:01:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:12 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:12 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 888431.30859375, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:01:12 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:01:12 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:12 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f2e80f0b77a4476bb301fa5551bab57e
2025-12-12 19:01:13 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:01:13 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:01:13 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:01:13 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:01:13 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:01:13 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:01:13 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a18eb631bf0e4cdb994b68f4c372b4f3 (experiment: x3d)
2025-12-12 19:01:13 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:01:15 [INFO] [lib.models.video:417] Chunk size increased from 240 to 250 (after 3 successes, increment: 10)
2025-12-12 19:01:15 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:01:16 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 181.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:21 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 924847.30859375, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.357198848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.571143168}
2025-12-12 19:01:21 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 181.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:01:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 924847.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:01:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:01:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:01:28 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 194.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:29 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 961263.30859375, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.483027968, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.445314048}
2025-12-12 19:01:29 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 194.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:01:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:31 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 961263.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:01:31 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:01:31 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:31 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a18eb631bf0e4cdb994b68f4c372b4f3
2025-12-12 19:01:32 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:01:32 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 5/16
2025-12-12 19:01:32 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001}
2025-12-12 19:01:32 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:01:32 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:01:32 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:01:32 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:01:32 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:01:32 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:01:32 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:01:32 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1a8a3f1c721b47729003839427567c19 (experiment: x3d)
2025-12-12 19:01:32 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:01:34 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:01:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:36 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:01:38 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:38 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.62890625, 'cpu_memory_gb': 3.6588172912597656, 'cpu_vms_mb': 961263.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:01:38 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:01:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:40 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.21 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.01 GiB is allocated by PyTorch, and 172.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:41 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3746.640625, 'cpu_memory_gb': 3.6588287353515625, 'cpu_vms_mb': 961263.30859375, 'gpu_allocated_gb': 1.589748736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:01:41 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.21 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.01 GiB is allocated by PyTorch, and 172.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:01:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:45 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:45 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 961264.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:01:45 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:01:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:47 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:01:49 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:49 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 961264.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:01:49 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:01:49 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:49 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1a8a3f1c721b47729003839427567c19
2025-12-12 19:01:49 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:01:49 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:01:49 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:01:49 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:01:49 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:01:50 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:01:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 79239742bd4c4b7993c70110a87849a6 (experiment: x3d)
2025-12-12 19:01:50 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:01:51 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:01:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:55 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:01:55 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 961264.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:01:55 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:01:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:01:58 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:02:00 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:01 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 997680.30859375, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:02:01 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:02:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:04 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:05 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 997680.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:02:05 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:02:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:07 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:07 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 997680.30859375, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:02:07 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:02:07 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:07 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 79239742bd4c4b7993c70110a87849a6
2025-12-12 19:02:08 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:02:08 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:02:08 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:02:08 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:02:08 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:02:08 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:02:08 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 717e21310478460287261e2029135fa1 (experiment: x3d)
2025-12-12 19:02:08 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:02:09 [INFO] [lib.models.video:417] Chunk size increased from 250 to 260 (after 3 successes, increment: 10)
2025-12-12 19:02:10 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:02:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 997680.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:02:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:02:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:18 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:18 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 997680.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:02:18 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:02:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:19 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:02:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.98 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.46 GiB is free. Including non-PyTorch memory, this process has 3.30 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 173.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:21 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 1034096.30859375, 'gpu_allocated_gb': 2.177524736, 'gpu_reserved_gb': 2.357198848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.571143168}
2025-12-12 19:02:21 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.98 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.46 GiB is free. Including non-PyTorch memory, this process has 3.30 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 173.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:02:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:25 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 1034096.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:02:25 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:02:25 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:25 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 717e21310478460287261e2029135fa1
2025-12-12 19:02:25 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:02:25 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:02:25 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:02:25 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:02:25 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:02:25 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:02:25 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 61bc25c1b96940bc98e4b6f9e54b3787 (experiment: x3d)
2025-12-12 19:02:25 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:02:28 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:02:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:30 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:02:32 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:32 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 1034096.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:02:32 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:02:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:36 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.59 GiB is free. Including non-PyTorch memory, this process has 3.17 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 144.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:36 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 1070512.30859375, 'gpu_allocated_gb': 2.093556736, 'gpu_reserved_gb': 2.231369728, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.696972288}
2025-12-12 19:02:36 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.59 GiB is free. Including non-PyTorch memory, this process has 3.17 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 144.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:02:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:40 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:40 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 1106928.30859375, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.441084928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.487257088}
2025-12-12 19:02:40 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:02:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:42 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:02:44 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:44 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 1106928.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:02:44 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:02:44 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:44 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 61bc25c1b96940bc98e4b6f9e54b3787
2025-12-12 19:02:44 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:02:44 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:02:44 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:02:44 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:02:44 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:02:45 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:02:45 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: fdd4290f317441609e1b9a7f949ed6c9 (experiment: x3d)
2025-12-12 19:02:45 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:02:47 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:02:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:51 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:51 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4609375, 'cpu_memory_gb': 3.6596298217773438, 'cpu_vms_mb': 1106928.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:02:51 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:02:51 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:54 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:02:56 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:56 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1106928.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:02:56 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:02:56 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:02:59 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:02:59 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1106928.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:02:59 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:02:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1106928.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:03:02 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:03:02 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:02 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: fdd4290f317441609e1b9a7f949ed6c9
2025-12-12 19:03:02 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:03:02 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 6/16
2025-12-12 19:03:02 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001}
2025-12-12 19:03:02 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:03:02 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:03:02 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:03:02 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:03:03 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:03:03 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:03:03 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:03:03 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2799fea9de3740a98ec2452867d1d5f7 (experiment: x3d)
2025-12-12 19:03:03 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:03:05 [INFO] [lib.models.video:417] Chunk size increased from 260 to 270 (after 3 successes, increment: 10)
2025-12-12 19:03:06 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:03:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:11 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.68 GiB is free. Including non-PyTorch memory, this process has 4.09 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 110.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:11 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1143344.30859375, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.944401408, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.983940608}
2025-12-12 19:03:11 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.68 GiB is free. Including non-PyTorch memory, this process has 4.09 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 110.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:03:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1143344.30859375, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:03:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:03:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:16 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:03:18 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:18 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1143344.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:03:18 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:03:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.36 GiB is free. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 134.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:21 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1179760.30859375, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.420113408, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.508228608}
2025-12-12 19:03:21 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.36 GiB is free. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 134.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:03:21 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.36 GiB is free. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 134.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.36 GiB is free. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 134.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:21 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2799fea9de3740a98ec2452867d1d5f7
2025-12-12 19:03:22 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:03:22 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:03:22 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:03:22 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:03:22 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:03:22 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:03:22 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4915b7d5ad784e84bb27dfeca3057d2f (experiment: x3d)
2025-12-12 19:03:22 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:03:24 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:03:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:26 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:03:28 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:28 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1216176.30859375, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:03:28 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:03:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:32 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:33 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1216176.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:03:33 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:03:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:35 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:35 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1216176.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:03:35 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:03:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:37 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:03:39 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:39 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1216176.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:03:39 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:03:39 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:39 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4915b7d5ad784e84bb27dfeca3057d2f
2025-12-12 19:03:39 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:03:39 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:03:39 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:03:39 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:03:39 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:03:40 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:03:40 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0e37cbf6eb3d4692910f76fe8d40e6cb (experiment: x3d)
2025-12-12 19:03:40 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:03:42 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:03:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:45 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:46 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1216176.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:03:46 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:03:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:47 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:03:48 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:48 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1216176.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:03:48 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:03:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:52 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.98 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 153.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:52 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1252592.30859375, 'gpu_allocated_gb': 2.177524736, 'gpu_reserved_gb': 2.336227328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.592114688}
2025-12-12 19:03:52 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.98 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 153.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:03:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:03:56 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:56 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1252592.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:03:56 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:03:56 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:03:56 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0e37cbf6eb3d4692910f76fe8d40e6cb
2025-12-12 19:03:57 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:03:57 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:03:57 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:03:57 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:03:57 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:03:57 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:03:57 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 044fd4a6328c42b39abca8b5c1d5fb1f (experiment: x3d)
2025-12-12 19:03:57 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:03:59 [INFO] [lib.models.video:417] Chunk size increased from 270 to 280 (after 3 successes, increment: 10)
2025-12-12 19:03:59 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:04:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:03 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.63 GiB is free. Including non-PyTorch memory, this process has 3.13 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 104.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:03 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1289008.30859375, 'gpu_allocated_gb': 2.093556736, 'gpu_reserved_gb': 2.210398208, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.717943808}
2025-12-12 19:04:03 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.63 GiB is free. Including non-PyTorch memory, this process has 3.13 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 104.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:04:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:06 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1289008.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:04:06 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:04:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:07 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:04:09 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:09 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3747.4765625, 'cpu_memory_gb': 3.6596450805664062, 'cpu_vms_mb': 1289008.30859375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:04:09 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:04:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:16 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.68 GiB is free. Including non-PyTorch memory, this process has 4.09 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 110.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:16 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3768.87109375, 'cpu_memory_gb': 3.6805381774902344, 'cpu_vms_mb': 1325445.578125, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.944401408, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.983940608}
2025-12-12 19:04:16 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.68 GiB is free. Including non-PyTorch memory, this process has 4.09 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 110.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:04:16 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.68 GiB is free. Including non-PyTorch memory, this process has 4.09 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 110.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.68 GiB is free. Including non-PyTorch memory, this process has 4.09 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 110.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:16 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 044fd4a6328c42b39abca8b5c1d5fb1f
2025-12-12 19:04:17 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:04:17 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:04:17 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:04:17 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:04:17 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:04:18 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:04:18 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f060eb0bbba945b0a3c447063e265a1c (experiment: x3d)
2025-12-12 19:04:18 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:04:20 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:04:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:22 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:04:23 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:23 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3768.87109375, 'cpu_memory_gb': 3.6805381774902344, 'cpu_vms_mb': 1325445.578125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:04:23 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:04:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:27 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:27 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3768.87109375, 'cpu_memory_gb': 3.6805381774902344, 'cpu_vms_mb': 1361861.578125, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:04:27 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:04:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:36 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:36 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4377.4453125, 'cpu_memory_gb': 4.274848937988281, 'cpu_vms_mb': 1362469.56640625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:04:36 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:04:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:37 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:04:38 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:38 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4377.4453125, 'cpu_memory_gb': 4.274848937988281, 'cpu_vms_mb': 1362469.56640625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:04:38 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:04:38 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:38 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f060eb0bbba945b0a3c447063e265a1c
2025-12-12 19:04:39 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:04:39 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 7/16
2025-12-12 19:04:39 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-12 19:04:39 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:04:39 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:04:39 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:04:39 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:04:39 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:04:39 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:04:40 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:04:40 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f36178b909e2416b9fe554fc33964e34 (experiment: x3d)
2025-12-12 19:04:40 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:04:41 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:04:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:45 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:45 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4377.4453125, 'cpu_memory_gb': 4.274848937988281, 'cpu_vms_mb': 1362469.56640625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:04:45 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:04:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:48 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:04:50 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:50 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4377.4453125, 'cpu_memory_gb': 4.274848937988281, 'cpu_vms_mb': 1398885.56640625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:04:50 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:04:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:55 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:55 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4377.4453125, 'cpu_memory_gb': 4.274848937988281, 'cpu_vms_mb': 1398885.56640625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:04:55 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:04:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:04:57 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:58 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4377.4453125, 'cpu_memory_gb': 4.274848937988281, 'cpu_vms_mb': 1435301.56640625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:04:58 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:04:58 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:04:58 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f36178b909e2416b9fe554fc33964e34
2025-12-12 19:04:58 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:04:58 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:04:58 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:04:58 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:04:58 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:04:58 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:04:58 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5c726363d1ac41c593668368eadc2c75 (experiment: x3d)
2025-12-12 19:04:59 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:04:59 [INFO] [lib.models.video:417] Chunk size increased from 220 to 230 (after 3 successes, increment: 10)
2025-12-12 19:05:00 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:05:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:04 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:05 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4377.4453125, 'cpu_memory_gb': 4.274848937988281, 'cpu_vms_mb': 1471717.56640625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.273312768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.655029248}
2025-12-12 19:05:05 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:05:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:07 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:08 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3770.15625, 'cpu_memory_gb': 3.681793212890625, 'cpu_vms_mb': 1471110.23046875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:05:08 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:05:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:09 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:05:11 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.38 GiB is free. Including non-PyTorch memory, this process has 3.38 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 114.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:11 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3770.15625, 'cpu_memory_gb': 3.681793212890625, 'cpu_vms_mb': 1507526.23046875, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.399141888, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.529200128}
2025-12-12 19:05:11 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.38 GiB is free. Including non-PyTorch memory, this process has 3.38 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 114.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:05:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 96.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3770.15625, 'cpu_memory_gb': 3.681793212890625, 'cpu_vms_mb': 1507526.23046875, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:05:14 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 96.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:05:14 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 96.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 96.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:14 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5c726363d1ac41c593668368eadc2c75
2025-12-12 19:05:14 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:05:14 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:05:14 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:05:14 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:05:14 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:05:15 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:05:15 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5a910e06b73f4e84aa6cfb36a37efc5e (experiment: x3d)
2025-12-12 19:05:15 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:05:17 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:05:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:20 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:05:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:22 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3770.15625, 'cpu_memory_gb': 3.681793212890625, 'cpu_vms_mb': 1507526.23046875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:05:22 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:05:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:25 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:25 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3770.15625, 'cpu_memory_gb': 3.681793212890625, 'cpu_vms_mb': 1507526.23046875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:05:25 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:05:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:31 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4205.60546875, 'cpu_memory_gb': 4.107036590576172, 'cpu_vms_mb': 1507961.73046875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:05:31 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:05:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:34 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:05:36 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:36 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3771.17578125, 'cpu_memory_gb': 3.682788848876953, 'cpu_vms_mb': 1543943.23046875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:05:36 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:05:36 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:36 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5a910e06b73f4e84aa6cfb36a37efc5e
2025-12-12 19:05:36 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:05:36 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:05:36 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:05:38 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:05:38 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:05:38 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:05:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9b7e4a2f3e474d0ea8c2e7dba4e27d96 (experiment: x3d)
2025-12-12 19:05:38 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:05:40 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:05:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:56 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:56 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 7338.2734375, 'cpu_memory_gb': 7.166282653808594, 'cpu_vms_mb': 1547510.234375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:05:56 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:05:56 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:05:58 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:05:59 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:05:59 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 7338.2734375, 'cpu_memory_gb': 7.166282653808594, 'cpu_vms_mb': 1547510.234375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:05:59 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:05:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3772.1796875, 'cpu_memory_gb': 3.6837692260742188, 'cpu_vms_mb': 1543944.01171875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:06:02 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:06:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:05 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 104.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3772.1796875, 'cpu_memory_gb': 3.6837692260742188, 'cpu_vms_mb': 1543944.01171875, 'gpu_allocated_gb': 1.610740736, 'gpu_reserved_gb': 1.728053248, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.200288768}
2025-12-12 19:06:06 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 104.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:06:06 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 104.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.26 GiB is free. Including non-PyTorch memory, this process has 2.50 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 104.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:06 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9b7e4a2f3e474d0ea8c2e7dba4e27d96
2025-12-12 19:06:06 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:06:06 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:06:06 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:06:07 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:06:07 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:06:07 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:06:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: b2b57a0be123480780799b8b08e759f9 (experiment: x3d)
2025-12-12 19:06:07 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:06:08 [INFO] [lib.models.video:417] Chunk size increased from 280 to 290 (after 3 successes, increment: 10)
2025-12-12 19:06:09 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:06:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3772.1796875, 'cpu_memory_gb': 3.6837692260742188, 'cpu_vms_mb': 1543944.01171875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:06:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:06:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:27 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:27 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 7566.06640625, 'cpu_memory_gb': 7.388736724853516, 'cpu_vms_mb': 1547738.0625, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:06:27 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:06:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:29 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:06:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:31 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 7565.08203125, 'cpu_memory_gb': 7.387775421142578, 'cpu_vms_mb': 1584153.0625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:06:31 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:06:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:34 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:34 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3772.19921875, 'cpu_memory_gb': 3.683788299560547, 'cpu_vms_mb': 1580360.01171875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:06:34 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:06:34 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:34 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: b2b57a0be123480780799b8b08e759f9
2025-12-12 19:06:34 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:06:34 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 8/16
2025-12-12 19:06:34 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001}
2025-12-12 19:06:34 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:06:34 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:06:34 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:06:34 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:06:35 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:06:35 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:06:35 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:06:35 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 3d5ac67834ac4ad1a15b28ac906e3d08 (experiment: x3d)
2025-12-12 19:06:35 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:06:38 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:06:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:39 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:06:41 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:41 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3772.20703125, 'cpu_memory_gb': 3.683795928955078, 'cpu_vms_mb': 1616776.01171875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:06:41 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:06:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:44 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:44 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3771.22265625, 'cpu_memory_gb': 3.6828346252441406, 'cpu_vms_mb': 1616775.01171875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:06:44 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:06:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:47 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:48 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3771.22265625, 'cpu_memory_gb': 3.6828346252441406, 'cpu_vms_mb': 1653191.01171875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:06:48 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:06:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:50 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:06:52 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:53 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3771.22265625, 'cpu_memory_gb': 3.6828346252441406, 'cpu_vms_mb': 1689607.01171875, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.986344448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.941997568}
2025-12-12 19:06:53 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:06:53 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:53 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 3d5ac67834ac4ad1a15b28ac906e3d08
2025-12-12 19:06:53 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:06:53 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:06:53 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:06:53 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:06:53 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:06:54 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:06:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4d46b94bf1ba4a4a9c3703677590b31b (experiment: x3d)
2025-12-12 19:06:54 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:06:55 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:06:56 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:06:59 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:06:59 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3771.22265625, 'cpu_memory_gb': 3.6828346252441406, 'cpu_vms_mb': 1689607.01171875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:06:59 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:06:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:00 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:07:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3771.22265625, 'cpu_memory_gb': 3.6828346252441406, 'cpu_vms_mb': 1726023.01171875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:07:02 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:07:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:05 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3771.22265625, 'cpu_memory_gb': 3.6828346252441406, 'cpu_vms_mb': 1726023.01171875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:07:06 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:07:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:09 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 124.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:09 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3771.22265625, 'cpu_memory_gb': 3.6828346252441406, 'cpu_vms_mb': 1726023.01171875, 'gpu_allocated_gb': 1.610740736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:07:09 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 124.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:07:09 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 124.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.24 GiB is free. Including non-PyTorch memory, this process has 2.52 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 124.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:09 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4d46b94bf1ba4a4a9c3703677590b31b
2025-12-12 19:07:09 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:07:09 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:07:09 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:07:10 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:07:10 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:07:10 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:07:10 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 15a67681489d4671b1713ffcd2952c2d (experiment: x3d)
2025-12-12 19:07:10 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:07:11 [INFO] [lib.models.video:417] Chunk size increased from 290 to 300 (after 3 successes, increment: 10)
2025-12-12 19:07:12 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:07:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:17 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:17 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3770.22265625, 'cpu_memory_gb': 3.6818580627441406, 'cpu_vms_mb': 1726022.01171875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:07:17 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:07:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:21 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3770.22265625, 'cpu_memory_gb': 3.6818580627441406, 'cpu_vms_mb': 1762438.01171875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:07:21 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:07:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:29 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:07:30 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:30 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4653.328125, 'cpu_memory_gb': 4.5442657470703125, 'cpu_vms_mb': 1763321.8984375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:07:30 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:07:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:35 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:36 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4653.328125, 'cpu_memory_gb': 4.5442657470703125, 'cpu_vms_mb': 1799737.8984375, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.986344448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.941997568}
2025-12-12 19:07:36 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:07:36 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:36 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 15a67681489d4671b1713ffcd2952c2d
2025-12-12 19:07:36 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:07:36 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:07:36 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:07:36 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:07:36 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:07:36 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:07:37 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 6d189d9ae76e4027bc03f7294540a3dc (experiment: x3d)
2025-12-12 19:07:37 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:07:39 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:07:39 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:41 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:07:42 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:42 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7578125, 'cpu_memory_gb': 3.6716384887695312, 'cpu_vms_mb': 1798844.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:07:42 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:07:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:48 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:48 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7578125, 'cpu_memory_gb': 3.6716384887695312, 'cpu_vms_mb': 1835260.29296875, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.965372928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.962969088}
2025-12-12 19:07:48 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:07:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:51 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.61 GiB is free. Including non-PyTorch memory, this process has 3.15 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 124.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:52 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7578125, 'cpu_memory_gb': 3.6716384887695312, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 2.093556736, 'gpu_reserved_gb': 2.231369728, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.696972288}
2025-12-12 19:07:52 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.61 GiB is free. Including non-PyTorch memory, this process has 3.15 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 124.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:07:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:07:53 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:07:55 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:55 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7578125, 'cpu_memory_gb': 3.6716384887695312, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:07:55 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:07:55 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:07:55 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 6d189d9ae76e4027bc03f7294540a3dc
2025-12-12 19:07:55 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:07:55 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:07:55 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:07:55 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:07:55 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:07:56 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:07:56 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e7a96b07bb86414f892c42c6c1b7b3fe (experiment: x3d)
2025-12-12 19:07:56 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:07:58 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:07:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:01 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7578125, 'cpu_memory_gb': 3.6716384887695312, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:08:02 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:08:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:04 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:08:05 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7578125, 'cpu_memory_gb': 3.6716384887695312, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:08:06 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:08:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:11 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:11 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:08:11 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:08:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:16 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:16 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:08:16 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:08:16 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:16 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e7a96b07bb86414f892c42c6c1b7b3fe
2025-12-12 19:08:17 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:08:17 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 9/16
2025-12-12 19:08:17 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001}
2025-12-12 19:08:17 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:08:17 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:08:17 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:08:17 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:08:17 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:08:17 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:08:17 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:08:17 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 64a6984a43d742008f9780fe7b69d53b (experiment: x3d)
2025-12-12 19:08:17 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:08:19 [INFO] [lib.models.video:417] Chunk size increased from 300 to 310 (after 3 successes, increment: 10)
2025-12-12 19:08:20 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:08:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:08:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:08:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:28 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:28 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:08:28 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:08:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:29 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:08:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:31 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:08:31 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:08:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:34 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:34 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1871676.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:08:34 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:08:34 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:34 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 64a6984a43d742008f9780fe7b69d53b
2025-12-12 19:08:34 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:08:34 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:08:34 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:08:34 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:08:34 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:08:35 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:08:35 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: b00e56f7bb14416db7a5ca1008fb45b2 (experiment: x3d)
2025-12-12 19:08:35 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:08:37 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:08:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:39 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:08:41 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:41 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1908092.29296875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.273312768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.655029248}
2025-12-12 19:08:41 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:08:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:46 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:46 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1908092.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:08:46 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:08:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:49 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:49 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1908092.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:08:49 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:08:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:08:51 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:08:53 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:53 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1944508.29296875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.273312768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.655029248}
2025-12-12 19:08:53 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:08:53 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 101.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:08:53 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: b00e56f7bb14416db7a5ca1008fb45b2
2025-12-12 19:08:54 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:08:54 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:08:54 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:08:54 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:08:54 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:08:54 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:08:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8ba3a5e51f6e4bbebbfd8f7d8a3db8ad (experiment: x3d)
2025-12-12 19:08:54 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:08:56 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:08:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:00 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:00 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1944508.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:09:00 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:09:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:01 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:09:03 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:03 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1944508.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:09:03 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:09:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:06 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1944508.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:09:06 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:09:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:11 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:12 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1980924.29296875, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.965372928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.962969088}
2025-12-12 19:09:12 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:09:12 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:12 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8ba3a5e51f6e4bbebbfd8f7d8a3db8ad
2025-12-12 19:09:12 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:09:12 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:09:12 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:09:12 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:09:12 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:09:12 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:09:12 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 03d7f91dbbb0437bb2a0b9ccfc452f8d (experiment: x3d)
2025-12-12 19:09:12 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:09:14 [INFO] [lib.models.video:417] Chunk size increased from 310 to 320 (after 3 successes, increment: 10)
2025-12-12 19:09:15 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:09:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:19 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:19 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 1980924.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:09:19 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:09:19 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:23 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:23 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2017340.29296875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:09:23 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:09:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:24 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:09:26 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 136.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:26 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2017340.29296875, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:09:26 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 136.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:09:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:31 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2017340.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:09:31 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:09:31 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:31 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 03d7f91dbbb0437bb2a0b9ccfc452f8d
2025-12-12 19:09:31 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:09:31 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:09:31 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:09:31 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:09:31 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:09:32 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:09:32 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 715d497785224c90851f3f4dc8da9657 (experiment: x3d)
2025-12-12 19:09:32 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:09:34 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:09:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:39 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:09:41 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:41 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2017340.29296875, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:09:41 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:09:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:45 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 23.07 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.09 GiB is free. Including non-PyTorch memory, this process has 3.68 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 135.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:45 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2053756.29296875, 'gpu_allocated_gb': 2.492404736, 'gpu_reserved_gb': 2.629828608, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.298513408}
2025-12-12 19:09:45 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 23.07 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.09 GiB is free. Including non-PyTorch memory, this process has 3.68 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 135.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:09:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:50 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:50 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2090172.29296875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:09:50 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:09:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:09:51 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:09:53 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 2.80 GiB memory in use. Of the allocated memory 2.31 GiB is allocated by PyTorch, and 126.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:53 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2090172.29296875, 'gpu_allocated_gb': 1.820660736, 'gpu_reserved_gb': 1.937768448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.990573568}
2025-12-12 19:09:53 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 2.80 GiB memory in use. Of the allocated memory 2.31 GiB is allocated by PyTorch, and 126.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:09:53 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 2.80 GiB memory in use. Of the allocated memory 2.31 GiB is allocated by PyTorch, and 126.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.97 GiB is free. Including non-PyTorch memory, this process has 2.80 GiB memory in use. Of the allocated memory 2.31 GiB is allocated by PyTorch, and 126.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:09:53 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 715d497785224c90851f3f4dc8da9657
2025-12-12 19:09:54 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:09:54 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 10/16
2025-12-12 19:09:54 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001}
2025-12-12 19:09:54 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:09:54 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:09:54 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:09:54 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:09:54 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:09:54 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:09:54 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:09:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 21416f764d994c86aadd83c2e56c57dd (experiment: x3d)
2025-12-12 19:09:54 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:09:56 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:09:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.965372928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.962969088}
2025-12-12 19:10:02 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:10:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:04 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:10:06 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:10:06 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:10:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:10 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:11 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:10:11 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:10:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:15 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:15 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:10:15 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:10:15 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:15 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 21416f764d994c86aadd83c2e56c57dd
2025-12-12 19:10:15 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:10:15 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:10:15 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:10:15 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:10:15 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:10:16 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:10:16 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a6c9c30a91124f58bee26bf0c6fedf1d (experiment: x3d)
2025-12-12 19:10:16 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:10:17 [INFO] [lib.models.video:417] Chunk size increased from 230 to 240 (after 3 successes, increment: 10)
2025-12-12 19:10:18 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:10:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:21 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:10:21 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:10:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.77734375, 'cpu_memory_gb': 3.6716575622558594, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:10:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:10:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:32 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:10:33 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:33 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4656.53515625, 'cpu_memory_gb': 4.547397613525391, 'cpu_vms_mb': 2127485.11328125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:10:33 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:10:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:37 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:37 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4656.546875, 'cpu_memory_gb': 4.5474090576171875, 'cpu_vms_mb': 2127485.11328125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:10:37 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:10:37 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a6c9c30a91124f58bee26bf0c6fedf1d
2025-12-12 19:10:37 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:10:37 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:10:37 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:10:37 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:10:37 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:10:38 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:10:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5d62e71518c9488fa33ab3327ae0acba (experiment: x3d)
2025-12-12 19:10:38 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:10:40 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:10:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:42 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:10:43 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:44 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7734375, 'cpu_memory_gb': 3.6716537475585938, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:10:44 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:10:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:47 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:47 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7734375, 'cpu_memory_gb': 3.6716537475585938, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:10:47 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:10:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:50 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:50 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7734375, 'cpu_memory_gb': 3.6716537475585938, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:10:50 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:10:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:10:51 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:10:53 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:53 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7734375, 'cpu_memory_gb': 3.6716537475585938, 'cpu_vms_mb': 2126588.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:10:53 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:10:53 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:10:53 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5d62e71518c9488fa33ab3327ae0acba
2025-12-12 19:10:54 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:10:54 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:10:54 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:10:54 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:10:54 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:10:54 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:10:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8b65033673cb443094abf82ed9a82b2b (experiment: x3d)
2025-12-12 19:10:54 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:10:56 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:10:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:01 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:01 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7734375, 'cpu_memory_gb': 3.6716537475585938, 'cpu_vms_mb': 2163004.29296875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:11:01 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:11:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:05 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:11:07 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:07 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7734375, 'cpu_memory_gb': 3.6716537475585938, 'cpu_vms_mb': 2163004.29296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:11:07 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:11:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:10 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:10 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 3759.7734375, 'cpu_memory_gb': 3.6716537475585938, 'cpu_vms_mb': 2163004.29296875, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:11:10 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 116.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:11:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:18 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 18.33 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.73 GiB is free. Including non-PyTorch memory, this process has 3.03 GiB memory in use. Of the allocated memory 2.55 GiB is allocated by PyTorch, and 115.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:19 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.953125, 'cpu_memory_gb': 4.3466339111328125, 'cpu_vms_mb': 2200111.52734375, 'gpu_allocated_gb': 2.009588736, 'gpu_reserved_gb': 2.126512128, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.801829888}
2025-12-12 19:11:19 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 18.33 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.73 GiB is free. Including non-PyTorch memory, this process has 3.03 GiB memory in use. Of the allocated memory 2.55 GiB is allocated by PyTorch, and 115.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:11:19 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 18.33 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.73 GiB is free. Including non-PyTorch memory, this process has 3.03 GiB memory in use. Of the allocated memory 2.55 GiB is allocated by PyTorch, and 115.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.33 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.73 GiB is free. Including non-PyTorch memory, this process has 3.03 GiB memory in use. Of the allocated memory 2.55 GiB is allocated by PyTorch, and 115.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:19 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8b65033673cb443094abf82ed9a82b2b
2025-12-12 19:11:19 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:11:19 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:11:19 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:11:19 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:11:19 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:11:20 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:11:20 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d37a7454c0b64c929c82f4bbc91a6424 (experiment: x3d)
2025-12-12 19:11:20 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:11:21 [INFO] [lib.models.video:417] Chunk size increased from 320 to 330 (after 3 successes, increment: 10)
2025-12-12 19:11:22 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:11:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:25 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:25 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.953125, 'cpu_memory_gb': 4.3466339111328125, 'cpu_vms_mb': 2236527.52734375, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.336227328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.592114688}
2025-12-12 19:11:25 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:11:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 156.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:31 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.953125, 'cpu_memory_gb': 4.3466339111328125, 'cpu_vms_mb': 2236527.52734375, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:11:31 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 156.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:11:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:35 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:11:36 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:36 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.953125, 'cpu_memory_gb': 4.3466339111328125, 'cpu_vms_mb': 2236527.52734375, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:11:36 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:11:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:45 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:45 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 5411.44921875, 'cpu_memory_gb': 5.284618377685547, 'cpu_vms_mb': 2237487.2578125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:11:45 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:11:45 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:45 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: d37a7454c0b64c929c82f4bbc91a6424
2025-12-12 19:11:45 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:11:45 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 11/16
2025-12-12 19:11:45 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-12 19:11:45 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:11:45 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:11:45 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:11:45 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:11:45 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:11:45 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:11:46 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:11:46 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0ad1f7207ef740e2a75a0c86523f236b (experiment: x3d)
2025-12-12 19:11:46 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:11:48 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:11:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:50 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:11:52 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:52 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.9765625, 'cpu_memory_gb': 4.346656799316406, 'cpu_vms_mb': 2236526.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:11:52 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:11:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:55 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:55 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.9765625, 'cpu_memory_gb': 4.346656799316406, 'cpu_vms_mb': 2236526.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:11:55 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:11:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:57 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:11:57 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.9765625, 'cpu_memory_gb': 4.346656799316406, 'cpu_vms_mb': 2236526.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:11:57 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:11:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:11:59 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:12:00 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:00 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.9765625, 'cpu_memory_gb': 4.346656799316406, 'cpu_vms_mb': 2236526.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:12:00 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:12:00 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:00 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0ad1f7207ef740e2a75a0c86523f236b
2025-12-12 19:12:00 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:12:00 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:12:00 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:12:00 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:12:00 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:12:01 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:12:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 79f5ca25a66d471ebf6c3770447a521b (experiment: x3d)
2025-12-12 19:12:01 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:12:02 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:12:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:07 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 156.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:07 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.9765625, 'cpu_memory_gb': 4.346656799316406, 'cpu_vms_mb': 2236526.76953125, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:12:07 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 156.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:12:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:09 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:12:10 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:10 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4450.9765625, 'cpu_memory_gb': 4.346656799316406, 'cpu_vms_mb': 2236526.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:12:10 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:12:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.32 GiB is free. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 174.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4449.99609375, 'cpu_memory_gb': 4.345699310302734, 'cpu_vms_mb': 2272941.76953125, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.462056448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.466285568}
2025-12-12 19:12:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.32 GiB is free. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 174.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:12:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:17 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 23.07 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.05 GiB is free. Including non-PyTorch memory, this process has 3.71 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 175.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:18 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4449.99609375, 'cpu_memory_gb': 4.345699310302734, 'cpu_vms_mb': 2309357.76953125, 'gpu_allocated_gb': 2.492404736, 'gpu_reserved_gb': 2.671771648, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.256570368}
2025-12-12 19:12:18 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 23.07 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.05 GiB is free. Including non-PyTorch memory, this process has 3.71 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 175.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:12:18 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 23.07 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.05 GiB is free. Including non-PyTorch memory, this process has 3.71 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 175.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.07 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.05 GiB is free. Including non-PyTorch memory, this process has 3.71 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 175.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:18 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 79f5ca25a66d471ebf6c3770447a521b
2025-12-12 19:12:18 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:12:18 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:12:18 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:12:18 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:12:18 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:12:19 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:12:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c0f51a72220b4de9bbe286ed76adecda (experiment: x3d)
2025-12-12 19:12:19 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:12:20 [INFO] [lib.models.video:417] Chunk size increased from 330 to 340 (after 3 successes, increment: 10)
2025-12-12 19:12:21 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:12:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4449.99609375, 'cpu_memory_gb': 4.345699310302734, 'cpu_vms_mb': 2309357.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:12:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:12:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:29 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:29 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4449.99609375, 'cpu_memory_gb': 4.345699310302734, 'cpu_vms_mb': 2309357.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:12:29 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:12:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:33 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:12:35 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:35 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4449.99609375, 'cpu_memory_gb': 4.345699310302734, 'cpu_vms_mb': 2309357.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:12:35 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:12:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:39 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:39 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4449.99609375, 'cpu_memory_gb': 4.345699310302734, 'cpu_vms_mb': 2345773.76953125, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:12:39 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:12:39 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:39 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c0f51a72220b4de9bbe286ed76adecda
2025-12-12 19:12:40 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:12:40 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:12:40 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:12:40 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:12:40 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:12:40 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:12:40 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9c10e93b4b544ee9932e711a73f6a3a5 (experiment: x3d)
2025-12-12 19:12:40 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:12:42 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:12:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:45 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:12:46 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:46 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4449.99609375, 'cpu_memory_gb': 4.345699310302734, 'cpu_vms_mb': 2345773.76953125, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:12:46 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:12:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:49 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:49 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4449.99609375, 'cpu_memory_gb': 4.345699310302734, 'cpu_vms_mb': 2382189.76953125, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.336227328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.592114688}
2025-12-12 19:12:49 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:12:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:57 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:12:57 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2382218.296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:12:57 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:12:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:12:58 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:13:00 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.28 GiB is free. Including non-PyTorch memory, this process has 3.48 GiB memory in use. Of the allocated memory 2.96 GiB is allocated by PyTorch, and 158.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:00 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2418634.296875, 'gpu_allocated_gb': 2.324468736, 'gpu_reserved_gb': 2.483027968, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.445314048}
2025-12-12 19:13:00 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 21.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.28 GiB is free. Including non-PyTorch memory, this process has 3.48 GiB memory in use. Of the allocated memory 2.96 GiB is allocated by PyTorch, and 158.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:13:00 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 21.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.28 GiB is free. Including non-PyTorch memory, this process has 3.48 GiB memory in use. Of the allocated memory 2.96 GiB is allocated by PyTorch, and 158.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.28 GiB is free. Including non-PyTorch memory, this process has 3.48 GiB memory in use. Of the allocated memory 2.96 GiB is allocated by PyTorch, and 158.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:00 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9c10e93b4b544ee9932e711a73f6a3a5
2025-12-12 19:13:00 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:13:00 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:13:00 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:13:01 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:13:01 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:13:01 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:13:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2891e56f1a33415db293f98275436dea (experiment: x3d)
2025-12-12 19:13:01 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:13:03 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:13:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:09 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 156.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:09 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2418634.296875, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:13:09 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 156.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:13:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:10 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:13:12 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:12 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2418634.296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:13:12 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:13:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:15 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:15 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2418634.296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:13:15 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:13:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:18 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.32 GiB is free. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 174.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:18 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2455050.296875, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.462056448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.466285568}
2025-12-12 19:13:18 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.32 GiB is free. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 174.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:13:18 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.32 GiB is free. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 174.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.32 GiB is free. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 174.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:18 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2891e56f1a33415db293f98275436dea
2025-12-12 19:13:18 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:13:18 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 12/16
2025-12-12 19:13:18 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001}
2025-12-12 19:13:18 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:13:18 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:13:18 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:13:18 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:13:18 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:13:18 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:13:19 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:13:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 61dfdbd361954dbbaf19ae8f1d25b025 (experiment: x3d)
2025-12-12 19:13:19 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:13:20 [INFO] [lib.models.video:417] Chunk size increased from 340 to 350 (after 3 successes, increment: 10)
2025-12-12 19:13:21 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:13:22 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2455050.296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:13:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:13:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:27 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:27 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2455050.296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:13:27 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:13:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:28 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:13:30 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:30 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2455050.296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:13:30 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:13:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:33 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:33 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.703125, 'cpu_memory_gb': 4.3727569580078125, 'cpu_vms_mb': 2455050.296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:13:33 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:13:33 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:33 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 61dfdbd361954dbbaf19ae8f1d25b025
2025-12-12 19:13:33 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:13:33 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:13:33 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:13:33 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:13:33 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:13:34 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:13:34 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7a59bc65048743a3beb8fa6ddb5f9e26 (experiment: x3d)
2025-12-12 19:13:34 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:13:35 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:13:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:37 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:13:39 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 166.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:39 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.70703125, 'cpu_memory_gb': 4.372760772705078, 'cpu_vms_mb': 2491466.296875, 'gpu_allocated_gb': 2.303476736, 'gpu_reserved_gb': 2.462056448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.466285568}
2025-12-12 19:13:39 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.30 GiB is free. Including non-PyTorch memory, this process has 3.46 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 166.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:13:39 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:42 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:42 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.70703125, 'cpu_memory_gb': 4.372760772705078, 'cpu_vms_mb': 2491466.296875, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:13:42 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:13:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:46 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:46 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.70703125, 'cpu_memory_gb': 4.372760772705078, 'cpu_vms_mb': 2527882.296875, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.336227328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.592114688}
2025-12-12 19:13:46 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:13:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:47 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:13:49 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:49 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.70703125, 'cpu_memory_gb': 4.372760772705078, 'cpu_vms_mb': 2564298.296875, 'gpu_allocated_gb': 2.282484736, 'gpu_reserved_gb': 2.441084928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.487257088}
2025-12-12 19:13:49 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:13:49 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.01 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 154.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:49 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7a59bc65048743a3beb8fa6ddb5f9e26
2025-12-12 19:13:49 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:13:49 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:13:49 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:13:49 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:13:49 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:13:50 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:13:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 6dff2cf73e364d87a9c332cc3a1eb88e (experiment: x3d)
2025-12-12 19:13:50 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:13:52 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:13:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:13:56 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.38 GiB is free. Including non-PyTorch memory, this process has 3.38 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 86.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:13:56 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 4477.70703125, 'cpu_memory_gb': 4.372760772705078, 'cpu_vms_mb': 2600714.296875, 'gpu_allocated_gb': 2.303476736, 'gpu_reserved_gb': 2.399141888, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.529200128}
2025-12-12 19:13:56 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.38 GiB is free. Including non-PyTorch memory, this process has 3.38 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 86.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:13:56 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:09 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:14:11 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 16.89 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.93 GiB is free. Including non-PyTorch memory, this process has 2.84 GiB memory in use. Of the allocated memory 2.36 GiB is allocated by PyTorch, and 110.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:11 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.453125, 'cpu_memory_gb': 6.0014190673828125, 'cpu_vms_mb': 2602381.25390625, 'gpu_allocated_gb': 1.862644736, 'gpu_reserved_gb': 1.979711488, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.948630528}
2025-12-12 19:14:11 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 16.89 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.93 GiB is free. Including non-PyTorch memory, this process has 2.84 GiB memory in use. Of the allocated memory 2.36 GiB is allocated by PyTorch, and 110.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:14:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.453125, 'cpu_memory_gb': 6.0014190673828125, 'cpu_vms_mb': 2602381.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:14:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:14:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 18.33 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.75 GiB is free. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.55 GiB is allocated by PyTorch, and 95.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:22 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.4609375, 'cpu_memory_gb': 6.001426696777344, 'cpu_vms_mb': 2638797.25390625, 'gpu_allocated_gb': 2.009588736, 'gpu_reserved_gb': 2.105540608, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.822801408}
2025-12-12 19:14:22 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 18.33 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.75 GiB is free. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.55 GiB is allocated by PyTorch, and 95.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:14:22 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 18.33 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.75 GiB is free. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.55 GiB is allocated by PyTorch, and 95.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.33 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.75 GiB is free. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.55 GiB is allocated by PyTorch, and 95.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:22 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 6dff2cf73e364d87a9c332cc3a1eb88e
2025-12-12 19:14:22 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:14:22 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:14:22 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:14:22 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:14:22 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:14:23 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:14:23 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 69ae24722f01432e86e54701e5a92a4b (experiment: x3d)
2025-12-12 19:14:23 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:14:24 [INFO] [lib.models.video:417] Chunk size increased from 350 to 360 (after 3 successes, increment: 10)
2025-12-12 19:14:24 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:14:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:28 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 144.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:28 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.4609375, 'cpu_memory_gb': 6.001426696777344, 'cpu_vms_mb': 2638797.25390625, 'gpu_allocated_gb': 1.610740736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:14:28 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 144.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:14:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:32 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:33 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.4609375, 'cpu_memory_gb': 6.001426696777344, 'cpu_vms_mb': 2675213.25390625, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.986344448, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.941997568}
2025-12-12 19:14:33 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.64 GiB is free. Including non-PyTorch memory, this process has 4.12 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 150.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:14:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:34 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:14:35 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:35 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.4609375, 'cpu_memory_gb': 6.001426696777344, 'cpu_vms_mb': 2675213.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:14:35 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:14:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:38 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:38 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.4609375, 'cpu_memory_gb': 6.001426696777344, 'cpu_vms_mb': 2675213.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:14:38 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:14:38 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:38 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 69ae24722f01432e86e54701e5a92a4b
2025-12-12 19:14:38 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:14:38 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:14:38 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:14:38 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:14:38 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:14:39 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:14:39 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8570481e4c71433a9f8abb3b50e468b6 (experiment: x3d)
2025-12-12 19:14:39 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:14:41 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:14:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:43 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:14:44 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:44 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.4609375, 'cpu_memory_gb': 6.001426696777344, 'cpu_vms_mb': 2675213.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:14:44 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:14:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:47 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:47 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6145.4609375, 'cpu_memory_gb': 6.001426696777344, 'cpu_vms_mb': 2675213.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:14:47 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:14:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:55 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:14:55 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.76953125, 'cpu_memory_gb': 6.002704620361328, 'cpu_vms_mb': 2675215.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:14:55 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:14:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:14:59 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:15:00 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:00 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7734375, 'cpu_memory_gb': 6.002708435058594, 'cpu_vms_mb': 2675215.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:15:00 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:15:00 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:00 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8570481e4c71433a9f8abb3b50e468b6
2025-12-12 19:15:01 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:15:01 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 13/16
2025-12-12 19:15:01 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001}
2025-12-12 19:15:01 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:15:01 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:15:01 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:15:01 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:15:01 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:15:01 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:15:01 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:15:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 52b8dcfd472247d6b17d0feff142e968 (experiment: x3d)
2025-12-12 19:15:01 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:15:03 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:15:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:07 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:07 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7734375, 'cpu_memory_gb': 6.002708435058594, 'cpu_vms_mb': 2711631.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:15:07 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:15:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:09 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:15:10 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:10 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7734375, 'cpu_memory_gb': 6.002708435058594, 'cpu_vms_mb': 2711631.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:15:10 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:15:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:13 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:13 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7734375, 'cpu_memory_gb': 6.002708435058594, 'cpu_vms_mb': 2748047.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:15:13 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:15:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:20 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:20 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2748047.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:15:20 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:15:20 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:20 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 52b8dcfd472247d6b17d0feff142e968
2025-12-12 19:15:20 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:15:20 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:15:20 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:15:20 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:15:20 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:15:21 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:15:21 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ec2eabd7e28f458f9b5d61f1154fbbc3 (experiment: x3d)
2025-12-12 19:15:21 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:15:22 [INFO] [lib.models.video:417] Chunk size increased from 240 to 250 (after 3 successes, increment: 10)
2025-12-12 19:15:22 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:15:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:26 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.36 GiB is free. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 106.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:26 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2784463.25390625, 'gpu_allocated_gb': 2.303476736, 'gpu_reserved_gb': 2.420113408, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.508228608}
2025-12-12 19:15:26 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.36 GiB is free. Including non-PyTorch memory, this process has 3.40 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 106.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:15:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:29 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:29 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2784463.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:15:29 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:15:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:30 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:15:32 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:32 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2820879.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:15:32 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:15:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:36 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:36 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2857295.25390625, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 2.965372928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.962969088}
2025-12-12 19:15:36 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:15:36 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.66 GiB is free. Including non-PyTorch memory, this process has 4.11 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 130.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:36 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: ec2eabd7e28f458f9b5d61f1154fbbc3
2025-12-12 19:15:37 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:15:37 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:15:37 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:15:37 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:15:37 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:15:37 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:15:37 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a5776646601d4f159465d8b66e7635a1 (experiment: x3d)
2025-12-12 19:15:37 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:15:39 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:15:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:41 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:15:43 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 144.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:43 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2857295.25390625, 'gpu_allocated_gb': 1.610740736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:15:43 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.42 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 144.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:15:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:47 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:47 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2857295.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:15:47 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:15:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:51 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:51 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2857295.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:15:51 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:15:51 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:15:52 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:15:54 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 17.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.75 GiB is free. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.50 GiB is allocated by PyTorch, and 151.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:54 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2893711.25390625, 'gpu_allocated_gb': 1.967604736, 'gpu_reserved_gb': 2.126512128, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.801829888}
2025-12-12 19:15:54 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 17.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.75 GiB is free. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.50 GiB is allocated by PyTorch, and 151.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:15:54 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 17.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.75 GiB is free. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.50 GiB is allocated by PyTorch, and 151.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.92 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.75 GiB is free. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.50 GiB is allocated by PyTorch, and 151.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:15:54 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a5776646601d4f159465d8b66e7635a1
2025-12-12 19:15:54 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:15:54 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:15:54 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:15:54 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:15:54 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:15:55 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:15:55 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8fcd069da80a4012bb7583c0cbc8162f (experiment: x3d)
2025-12-12 19:15:55 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:15:57 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:15:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:03 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:03 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2893711.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:16:03 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:16:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:04 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:16:06 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.98 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 113.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2930127.25390625, 'gpu_allocated_gb': 2.177524736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:16:06 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.98 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 113.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:16:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:09 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:09 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2930127.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:16:09 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:16:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:12 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:12 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6146.7890625, 'cpu_memory_gb': 6.002723693847656, 'cpu_vms_mb': 2930127.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.749024768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.179317248}
2025-12-12 19:16:12 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:16:12 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.22 GiB is free. Including non-PyTorch memory, this process has 2.54 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 89.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:12 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8fcd069da80a4012bb7583c0cbc8162f
2025-12-12 19:16:12 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:16:12 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:16:12 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:16:12 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:16:12 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:16:13 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:16:13 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 91429ccc677d48bc93ae53be15444f61 (experiment: x3d)
2025-12-12 19:16:13 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:16:14 [INFO] [lib.models.video:417] Chunk size increased from 360 to 370 (after 3 successes, increment: 10)
2025-12-12 19:16:15 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:16:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:23 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:23 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.93359375, 'cpu_memory_gb': 6.005794525146484, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:16:23 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:16:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:27 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:27 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.93359375, 'cpu_memory_gb': 6.005794525146484, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:16:27 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:16:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:28 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:16:29 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 156.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:29 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.93359375, 'cpu_memory_gb': 6.005794525146484, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:16:29 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 156.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:16:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:32 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:32 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.93359375, 'cpu_memory_gb': 6.005794525146484, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:16:32 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:16:32 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:32 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 91429ccc677d48bc93ae53be15444f61
2025-12-12 19:16:32 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:16:32 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 14/16
2025-12-12 19:16:32 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001}
2025-12-12 19:16:32 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:16:32 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:16:32 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:16:32 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:16:32 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:16:32 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:16:33 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:16:33 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2784c81b045d45688ffadf3e902f68dc (experiment: x3d)
2025-12-12 19:16:33 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:16:35 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:16:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:37 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:16:38 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:39 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.93359375, 'cpu_memory_gb': 6.005794525146484, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:16:39 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:16:39 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:41 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:41 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.93359375, 'cpu_memory_gb': 6.005794525146484, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:16:41 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:16:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:45 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 13.18 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.42 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.85 GiB is allocated by PyTorch, and 131.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:45 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.99609375, 'cpu_memory_gb': 6.005855560302734, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 2.533586944, 'gpu_reserved_gb': 2.671771648, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.256570368}
2025-12-12 19:16:45 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 13.18 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.42 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.85 GiB is allocated by PyTorch, and 131.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:16:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:47 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:16:49 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:49 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.99609375, 'cpu_memory_gb': 6.005855560302734, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:16:49 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:16:49 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:49 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2784c81b045d45688ffadf3e902f68dc
2025-12-12 19:16:49 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:16:49 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:16:49 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:16:49 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:16:49 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:16:50 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:16:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 48b89dab0d5d4586975d82833bcb35e6 (experiment: x3d)
2025-12-12 19:16:50 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:16:51 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:16:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:54 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:54 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.99609375, 'cpu_memory_gb': 6.005855560302734, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:16:54 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:16:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:16:56 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:16:57 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:16:57 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6149.99609375, 'cpu_memory_gb': 6.005855560302734, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:16:57 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:16:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:17:02 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:17:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:06 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:06 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 2930130.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:17:06 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:17:06 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:06 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 48b89dab0d5d4586975d82833bcb35e6
2025-12-12 19:17:06 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:17:06 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:17:06 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:17:06 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:17:06 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:17:07 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:17:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 91b5197211cc4f2f89e821c4e7a5180b (experiment: x3d)
2025-12-12 19:17:07 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:17:08 [INFO] [lib.models.video:417] Chunk size increased from 370 to 380 (after 3 successes, increment: 10)
2025-12-12 19:17:09 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:17:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:13 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 126.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:13 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 2966546.25390625, 'gpu_allocated_gb': 2.303476736, 'gpu_reserved_gb': 2.441084928, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.487257088}
2025-12-12 19:17:13 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 21.22 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.34 GiB is free. Including non-PyTorch memory, this process has 3.42 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 126.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:17:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:15 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:15 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 2966546.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:17:15 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:17:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:17 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:17:18 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:18 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 2966546.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:17:18 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:17:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:21 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:21 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:17:21 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:17:21 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:21 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 91b5197211cc4f2f89e821c4e7a5180b
2025-12-12 19:17:22 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:17:22 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:17:22 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:17:22 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:17:22 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:17:22 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:17:22 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a1853b3f94f146ed894d8934140abb8c (experiment: x3d)
2025-12-12 19:17:22 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:17:24 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:17:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:27 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:17:28 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:28 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:17:28 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:17:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:31 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:17:31 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:17:31 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:37 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:37 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:17:37 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:17:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:38 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:17:40 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:40 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:17:40 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:17:40 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:40 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a1853b3f94f146ed894d8934140abb8c
2025-12-12 19:17:40 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:17:40 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:17:40 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:17:40 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:17:40 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:17:41 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:17:41 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 41081c3d635b44ffac4b7765382b579c (experiment: x3d)
2025-12-12 19:17:41 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:17:43 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:17:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:46 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:46 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:17:46 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:17:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:49 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:17:50 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:51 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:17:51 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:17:51 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:53 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:53 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:17:53 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:17:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:17:59 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 176.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:59 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:17:59 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 176.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:17:59 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 176.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 176.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:17:59 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 41081c3d635b44ffac4b7765382b579c
2025-12-12 19:17:59 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:17:59 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 15/16
2025-12-12 19:17:59 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-12 19:17:59 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:17:59 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:17:59 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:17:59 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:17:59 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:17:59 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:18:00 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:18:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 88198d9fbc4746888851358e4d073d3d (experiment: x3d)
2025-12-12 19:18:00 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:18:01 [INFO] [lib.models.video:417] Chunk size increased from 380 to 390 (after 3 successes, increment: 10)
2025-12-12 19:18:02 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:18:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:05 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.93 GiB is free. Including non-PyTorch memory, this process has 2.84 GiB memory in use. Of the allocated memory 2.31 GiB is allocated by PyTorch, and 166.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:05 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.820660736, 'gpu_reserved_gb': 1.979711488, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.948630528}
2025-12-12 19:18:05 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.93 GiB is free. Including non-PyTorch memory, this process has 2.84 GiB memory in use. Of the allocated memory 2.31 GiB is allocated by PyTorch, and 166.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:18:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:08 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:09 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:18:09 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:18:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:12 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:18:13 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:18:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:18:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:18 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.79 GiB is free. Including non-PyTorch memory, this process has 2.97 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 167.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:18 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.925620736, 'gpu_reserved_gb': 2.105540608, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.822801408}
2025-12-12 19:18:18 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.79 GiB is free. Including non-PyTorch memory, this process has 2.97 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 167.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:18:18 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.79 GiB is free. Including non-PyTorch memory, this process has 2.97 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 167.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.79 GiB is free. Including non-PyTorch memory, this process has 2.97 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 167.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:18 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 88198d9fbc4746888851358e4d073d3d
2025-12-12 19:18:18 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:18:18 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:18:18 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:18:18 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:18:18 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:18:19 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:18:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d904246b0d8a457c9901e5eb62690a98 (experiment: x3d)
2025-12-12 19:18:19 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:18:20 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:18:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:22 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:18:23 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:18:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:18:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:26 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:26 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:18:26 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:18:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:29 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:29 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:18:29 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:18:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:30 [INFO] [lib.models.video:417] Chunk size increased from 220 to 230 (after 3 successes, increment: 10)
2025-12-12 19:18:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:32 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:18:32 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:18:32 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:32 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: d904246b0d8a457c9901e5eb62690a98
2025-12-12 19:18:32 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:18:32 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:18:32 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:18:32 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:18:32 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:18:33 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:18:33 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8df22f1b83774e6784b1bf4a72f11a27 (experiment: x3d)
2025-12-12 19:18:33 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:18:34 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:18:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:38 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:38 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:18:38 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:18:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:39 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:18:41 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:41 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:18:41 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:18:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:43 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:43 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:18:43 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:18:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:46 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:46 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:18:46 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:18:46 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:46 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8df22f1b83774e6784b1bf4a72f11a27
2025-12-12 19:18:46 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:18:46 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:18:46 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:18:46 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:18:46 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:18:47 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:18:47 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8c9c7fa9feae40c1b2d9d561a05ffee2 (experiment: x3d)
2025-12-12 19:18:47 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:18:48 [INFO] [lib.models.video:417] Chunk size increased from 390 to 400 (after 3 successes, increment: 10)
2025-12-12 19:18:49 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:18:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:52 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:52 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3002962.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:18:52 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:18:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:55 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:55 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.01953125, 'cpu_memory_gb': 6.005878448486328, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.294284288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.634057728}
2025-12-12 19:18:55 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.54 GiB is free. Including non-PyTorch memory, this process has 3.23 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 121.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:18:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:18:56 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:18:58 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:18:58 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:18:58 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:18:58 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:02 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.769996288, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.158345728}
2025-12-12 19:19:02 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:19:02 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 109.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:02 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8c9c7fa9feae40c1b2d9d561a05ffee2
2025-12-12 19:19:02 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:19:02 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:19:02 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:19:02 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:19:02 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:19:03 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:19:03 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4979c9e7c88344da83d848a76c078bd9 (experiment: x3d)
2025-12-12 19:19:03 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:19:05 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:19:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:06 [INFO] [lib.models.video:417] Chunk size increased from 220 to 230 (after 3 successes, increment: 10)
2025-12-12 19:19:08 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:08 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:19:08 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:19:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:11 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:11 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:19:11 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:19:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:13 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:19:14 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:19:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:16 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:19:17 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:17 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:19:17 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:19:17 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:17 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4979c9e7c88344da83d848a76c078bd9
2025-12-12 19:19:18 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 19:19:18 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 16/16
2025-12-12 19:19:18 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001}
2025-12-12 19:19:18 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 19:19:18 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 19:19:18 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:19:18 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:19:18 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:19:18 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:19:18 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:19:18 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4384bb4d53ee447f95459e7cdab6ac63 (experiment: x3d)
2025-12-12 19:19:18 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 1...
2025-12-12 19:19:20 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:19:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:25 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:26 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:19:26 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:19:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:27 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:19:29 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:29 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3039378.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:19:29 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:19:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:34 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process has 4.14 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 170.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:34 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3075794.25390625, 'gpu_allocated_gb': 2.828276736, 'gpu_reserved_gb': 3.007315968, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 13.921026048}
2025-12-12 19:19:34 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 26.37 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.62 GiB is free. Including non-PyTorch memory, this process has 4.14 GiB memory in use. Of the allocated memory 3.61 GiB is allocated by PyTorch, and 170.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 19:19:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:37 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:37 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3075794.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:19:37 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Final batch size: 1
2025-12-12 19:19:37 [ERROR] [lib.training.pipeline:1640] Error training fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4384bb4d53ee447f95459e7cdab6ac63
2025-12-12 19:19:37 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 19:19:37 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:19:37 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:19:37 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:19:37 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:19:38 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:19:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8cb09e6b90064bd5911599cf1e28d243 (experiment: x3d)
2025-12-12 19:19:38 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 2...
2025-12-12 19:19:39 [INFO] [lib.models.video:417] Chunk size increased from 250 to 260 (after 3 successes, increment: 10)
2025-12-12 19:19:39 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:19:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:44 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:44 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3075794.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:19:44 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:19:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:48 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 181.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:48 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3112210.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.357198848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.571143168}
2025-12-12 19:19:48 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.48 GiB is free. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 181.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:19:48 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:50 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:19:52 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 184.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:52 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3148626.25390625, 'gpu_allocated_gb': 2.093556736, 'gpu_reserved_gb': 2.273312768, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.655029248}
2025-12-12 19:19:52 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.55 GiB is free. Including non-PyTorch memory, this process has 3.21 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 184.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 19:19:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:19:56 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:56 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3148626.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.832910848, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.095431168}
2025-12-12 19:19:56 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Final batch size: 1
2025-12-12 19:19:56 [ERROR] [lib.training.pipeline:1640] Error training fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.62 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 169.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:19:56 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8cb09e6b90064bd5911599cf1e28d243
2025-12-12 19:19:57 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 19:19:57 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:19:57 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:19:57 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:19:57 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:19:58 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:19:58 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1a0cbc8fe5574d5aa14a6e7c5f8135e3 (experiment: x3d)
2025-12-12 19:19:58 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 3...
2025-12-12 19:20:00 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:20:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:02 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:20:04 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.59 GiB is free. Including non-PyTorch memory, this process has 3.17 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 144.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:04 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3185042.25390625, 'gpu_allocated_gb': 2.093556736, 'gpu_reserved_gb': 2.231369728, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.696972288}
2025-12-12 19:20:04 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 19.16 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.59 GiB is free. Including non-PyTorch memory, this process has 3.17 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 144.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:20:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:08 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:08 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.315255808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.613086208}
2025-12-12 19:20:08 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.52 GiB is free. Including non-PyTorch memory, this process has 3.25 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 141.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:20:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:11 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 136.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:11 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 1.631732736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:20:11 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.63 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.20 GiB is free. Including non-PyTorch memory, this process has 2.56 GiB memory in use. Of the allocated memory 2.06 GiB is allocated by PyTorch, and 136.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 19:20:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:12 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:20:14 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:14 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:20:14 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Final batch size: 1
2025-12-12 19:20:14 [ERROR] [lib.training.pipeline:1640] Error training fold 3: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:14 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1a0cbc8fe5574d5aa14a6e7c5f8135e3
2025-12-12 19:20:14 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 19:20:14 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:20:14 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:20:14 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:20:14 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:20:15 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:20:15 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 613cb92b3574409c828dccb83673560e (experiment: x3d)
2025-12-12 19:20:15 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 4...
2025-12-12 19:20:17 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:20:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:20 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:20 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:20:20 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:20:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:22 [INFO] [lib.models.video:417] Chunk size increased from 210 to 220 (after 3 successes, increment: 10)
2025-12-12 19:20:24 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:24 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:20:24 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:20:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:27 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:27 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.790967808, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.137374208}
2025-12-12 19:20:27 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.18 GiB is free. Including non-PyTorch memory, this process has 2.58 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 129.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 19:20:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:31 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.81 GiB is free. Including non-PyTorch memory, this process has 2.95 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 147.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:32 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 1.925620736, 'gpu_reserved_gb': 2.084569088, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.843772928}
2025-12-12 19:20:32 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.81 GiB is free. Including non-PyTorch memory, this process has 2.95 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 147.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Final batch size: 1
2025-12-12 19:20:32 [ERROR] [lib.training.pipeline:1640] Error training fold 4: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.81 GiB is free. Including non-PyTorch memory, this process has 2.95 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 147.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.81 GiB is free. Including non-PyTorch memory, this process has 2.95 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 147.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:32 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 613cb92b3574409c828dccb83673560e
2025-12-12 19:20:32 [INFO] [lib.training.pipeline:850] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 19:20:32 [INFO] [lib.training.pipeline:954] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 19:20:32 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:20:32 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:20:32 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:20:33 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:20:33 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1b0cf7591f5a41f899ba9776295f4082 (experiment: x3d)
2025-12-12 19:20:33 [INFO] [lib.training.pipeline:1073] Training PyTorch model x3d on fold 5...
2025-12-12 19:20:34 [INFO] [lib.models.video:417] Chunk size increased from 400 to 410 (after 3 successes, increment: 10)
2025-12-12 19:20:34 [INFO] [lib.training.pipeline:1115] Model forward pass test successful. Output shape: torch.Size([1, 1])
2025-12-12 19:20:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:38 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:38 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:20:38 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:20:38 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:42 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:42 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3221458.25390625, 'gpu_allocated_gb': 1.652724736, 'gpu_reserved_gb': 1.811939328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.116402688}
2025-12-12 19:20:42 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.09 GiB is allocated by PyTorch, and 149.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:20:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:44 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:20:46 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:46 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3257874.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.336227328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.592114688}
2025-12-12 19:20:46 [WARNING] [lib.training.pipeline:1246] CUDA OOM during training (attempt 3/4): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 19:20:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:49 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:50 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6150.0234375, 'cpu_memory_gb': 6.005882263183594, 'cpu_vms_mb': 3294290.25390625, 'gpu_allocated_gb': 2.156532736, 'gpu_reserved_gb': 2.336227328, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.592114688}
2025-12-12 19:20:50 [ERROR] [lib.training.pipeline:1261] CUDA OOM or runtime error during training (max retries reached): CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Final batch size: 1
2025-12-12 19:20:50 [ERROR] [lib.training.pipeline:1640] Error training fold 5: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1220, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.78 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.50 GiB is free. Including non-PyTorch memory, this process has 3.27 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 161.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:50 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1b0cf7591f5a41f899ba9776295f4082
2025-12-12 19:20:50 [INFO] [lib.training.pipeline:1699] ================================================================================
2025-12-12 19:20:50 [INFO] [lib.training.pipeline:1700] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-12 19:20:50 [INFO] [lib.training.pipeline:1701] ================================================================================
2025-12-12 19:20:50 [INFO] [lib.training.pipeline:1714] Final training: Using 5-fold stratified cross-validation on full dataset (3278 rows)
2025-12-12 19:20:50 [INFO] [lib.training.pipeline:1724] Final training using default hyperparameters (no grid search)
2025-12-12 19:20:50 [INFO] [lib.training.pipeline:1728] 
Final Training - x3d - Fold 1/5 (full dataset)
2025-12-12 19:20:50 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:20:50 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:20:50 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:20:51 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:20:51 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: aa3161fca4c34003b925bb2f011ed679 (experiment: x3d)
2025-12-12 19:20:51 [INFO] [lib.training.pipeline:1885] Training PyTorch model x3d on fold 1 (full dataset)...
2025-12-12 19:20:51 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:53 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:53 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6152.6171875, 'cpu_memory_gb': 6.008415222167969, 'cpu_vms_mb': 3294293.25390625, 'gpu_allocated_gb': 1.785445888, 'gpu_reserved_gb': 1.874853888, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.053488128}
2025-12-12 19:20:53 [ERROR] [lib.training.pipeline:2072] Error training final fold 1: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1887, in stage5_train_models
    if mlflow_tracker:
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:53 [INFO] [lib.training.pipeline:1728] 
Final Training - x3d - Fold 2/5 (full dataset)
2025-12-12 19:20:53 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:20:53 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:20:53 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:20:54 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:20:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 76d4968cc9ee425b8c45c7a3f3a35cec (experiment: x3d)
2025-12-12 19:20:54 [INFO] [lib.training.pipeline:1885] Training PyTorch model x3d on fold 2 (full dataset)...
2025-12-12 19:20:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:20:55 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:20:57 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:57 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6152.625, 'cpu_memory_gb': 6.0084228515625, 'cpu_vms_mb': 3294293.25390625, 'gpu_allocated_gb': 1.785445888, 'gpu_reserved_gb': 1.874853888, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.053488128}
2025-12-12 19:20:57 [ERROR] [lib.training.pipeline:2072] Error training final fold 2: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1887, in stage5_train_models
    if mlflow_tracker:
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:20:57 [INFO] [lib.training.pipeline:1728] 
Final Training - x3d - Fold 3/5 (full dataset)
2025-12-12 19:20:57 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:20:57 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:20:57 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:20:58 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:20:58 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ca9f312efb5744df86642492f39dd0de (experiment: x3d)
2025-12-12 19:20:58 [INFO] [lib.training.pipeline:1885] Training PyTorch model x3d on fold 3 (full dataset)...
2025-12-12 19:20:58 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:21:02 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.73 GiB is free. Including non-PyTorch memory, this process has 3.03 GiB memory in use. Of the allocated memory 2.57 GiB is allocated by PyTorch, and 100.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:21:03 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6152.625, 'cpu_memory_gb': 6.0084228515625, 'cpu_vms_mb': 3294293.25390625, 'gpu_allocated_gb': 2.058341888, 'gpu_reserved_gb': 2.168455168, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.759886848}
2025-12-12 19:21:03 [ERROR] [lib.training.pipeline:2072] Error training final fold 3: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.73 GiB is free. Including non-PyTorch memory, this process has 3.03 GiB memory in use. Of the allocated memory 2.57 GiB is allocated by PyTorch, and 100.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1887, in stage5_train_models
    if mlflow_tracker:
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.73 GiB is free. Including non-PyTorch memory, this process has 3.03 GiB memory in use. Of the allocated memory 2.57 GiB is allocated by PyTorch, and 100.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:21:03 [INFO] [lib.training.pipeline:1728] 
Final Training - x3d - Fold 4/5 (full dataset)
2025-12-12 19:21:03 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:21:03 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:21:03 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:21:03 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:21:03 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a182c3e0620e4721b148793bf360e029 (experiment: x3d)
2025-12-12 19:21:03 [INFO] [lib.training.pipeline:1885] Training PyTorch model x3d on fold 4 (full dataset)...
2025-12-12 19:21:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:21:06 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.87 GiB is free. Including non-PyTorch memory, this process has 2.89 GiB memory in use. Of the allocated memory 2.43 GiB is allocated by PyTorch, and 99.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:21:07 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6152.625, 'cpu_memory_gb': 6.0084228515625, 'cpu_vms_mb': 3294293.25390625, 'gpu_allocated_gb': 1.953381888, 'gpu_reserved_gb': 2.042626048, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 14.885715968}
2025-12-12 19:21:07 [ERROR] [lib.training.pipeline:2072] Error training final fold 4: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.87 GiB is free. Including non-PyTorch memory, this process has 2.89 GiB memory in use. Of the allocated memory 2.43 GiB is allocated by PyTorch, and 99.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1887, in stage5_train_models
    if mlflow_tracker:
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.48 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.87 GiB is free. Including non-PyTorch memory, this process has 2.89 GiB memory in use. Of the allocated memory 2.43 GiB is allocated by PyTorch, and 99.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:21:07 [INFO] [lib.training.pipeline:1728] 
Final Training - x3d - Fold 5/5 (full dataset)
2025-12-12 19:21:07 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 19:21:07 [WARNING] [lib.training.x3d:109] Failed to load X3D from PyTorchVideo: No module named 'fvcore'. Trying torchvision...
2025-12-12 19:21:07 [WARNING] [lib.training.x3d:139] torchvision X3D not available: cannot import name 'x3d_m' from 'torchvision.models.video' (/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/__init__.py). Using r3d_18 as approximation.
2025-12-12 19:21:07 [WARNING] [lib.training.x3d:156] ⚠ Using r3d_18 as X3D approximation (X3D not available)
2025-12-12 19:21:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 63215a4d794b4752854bd1ea023cdd3b (experiment: x3d)
2025-12-12 19:21:07 [INFO] [lib.training.pipeline:1885] Training PyTorch model x3d on fold 5 (full dataset)...
2025-12-12 19:21:07 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 19:21:14 [INFO] [lib.models.video:417] Chunk size increased from 200 to 210 (after 3 successes, increment: 10)
2025-12-12 19:21:16 [ERROR] [lib.utils.memory:128] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:21:16 [INFO] [lib.utils.memory:89] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6152.625, 'cpu_memory_gb': 6.0084228515625, 'cpu_vms_mb': 3294293.25390625, 'gpu_allocated_gb': 1.785445888, 'gpu_reserved_gb': 1.874853888, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.053488128}
2025-12-12 19:21:16 [ERROR] [lib.training.pipeline:2072] Error training final fold 5: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1887, in stage5_train_models
    if mlflow_tracker:
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 624, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 342, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 176, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 254, in forward
    x = self.layer1(x)
        ^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torchvision/models/video/resnet.py", line 113, in forward
    out = self.conv1(x)
          ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 717, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 712, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.10 GiB is free. Including non-PyTorch memory, this process has 2.66 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 82.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 19:21:16 [WARNING] [lib.training.pipeline:118] No model files found in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/fold_1 to copy
2025-12-12 19:21:16 [INFO] [lib.training.pipeline:2145] 
x3d - Avg Val Loss: nan, Avg Val Acc: nan, Avg Val F1: nan
2025-12-12 19:21:18 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/plots/cv_fold_comparison.png
2025-12-12 19:21:18 [INFO] [lib.training.pipeline:2173] Generated plots for x3d in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/plots
2025-12-12 19:21:18 [INFO] [lib.training.pipeline:2210] ================================================================================
2025-12-12 19:21:18 [INFO] [lib.training.pipeline:2211] Stage 5: Model Training Pipeline Completed
2025-12-12 19:21:18 [INFO] [lib.training.pipeline:2212] ================================================================================
2025-12-12 19:21:18 [INFO] [__main__:401] ================================================================================
2025-12-12 19:21:18 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-12 19:21:18 [INFO] [__main__:403] ================================================================================
2025-12-12 19:21:18 [INFO] [__main__:404] Execution time: 1593.11 seconds (26.55 minutes)
2025-12-12 19:21:18 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 19:21:18 [INFO] [__main__:407] Models trained: ['x3d']
2025-12-12 19:21:18 [INFO] [__main__:408] K-fold splits: 5
2025-12-12 19:21:18 [INFO] [__main__:414] ================================================================================
2025-12-12 19:21:18 [INFO] [__main__:415] Final memory statistics:
2025-12-12 19:21:18 [INFO] [__main__:416] ================================================================================
2025-12-12 19:21:18 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: after training): {'cpu_memory_mb': 6151.03515625, 'cpu_memory_gb': 6.006870269775391, 'cpu_vms_mb': 3294322.81640625, 'gpu_allocated_gb': 0.00851968, 'gpu_reserved_gb': 1.874853888, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 15.053488128}
2025-12-12 19:21:18 [INFO] [__main__:419] ================================================================================
2025-12-12 19:21:18 [INFO] [__main__:420] Training complete!
2025-12-12 19:21:18 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 19:21:18 [INFO] [__main__:422] ================================================================================
