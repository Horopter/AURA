2025-12-14 13:28:48 [INFO] [__main__:310] ================================================================================
2025-12-14 13:28:48 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-14 13:28:48 [INFO] [__main__:312] ================================================================================
2025-12-14 13:28:48 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-14 13:28:48 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 13:28:48 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-14 13:28:48 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-14 13:28:48 [INFO] [__main__:317] Model types: ['xgboost_vit_gru']
2025-12-14 13:28:48 [INFO] [__main__:318] K-fold splits: 5
2025-12-14 13:28:48 [INFO] [__main__:319] Number of frames: 1000
2025-12-14 13:28:48 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-14 13:28:48 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-14 13:28:48 [INFO] [__main__:324] Delete existing: False
2025-12-14 13:28:48 [INFO] [__main__:325] Resume mode: True
2025-12-14 13:28:48 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765736928.log
2025-12-14 13:28:48 [INFO] [__main__:333] ================================================================================
2025-12-14 13:28:48 [INFO] [__main__:334] Checking prerequisites...
2025-12-14 13:28:48 [INFO] [__main__:335] ================================================================================
2025-12-14 13:28:48 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 13:28:48 [INFO] [__main__:352] ✓ All model types are valid
2025-12-14 13:28:48 [INFO] [__main__:358] ================================================================================
2025-12-14 13:28:48 [INFO] [__main__:359] Initial memory statistics:
2025-12-14 13:28:48 [INFO] [__main__:360] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.3828125, 'cpu_memory_gb': 0.7181472778320312, 'cpu_vms_mb': 10218.640625, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-14 13:28:48 [INFO] [__main__:364] ================================================================================
2025-12-14 13:28:48 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-14 13:28:48 [INFO] [__main__:366] ================================================================================
2025-12-14 13:28:48 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-14 13:28:48 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-14 13:28:48 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-14 13:28:48 [INFO] [__main__:370] ================================================================================
2025-12-14 13:28:48 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-14 13:28:48 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:851] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:852] Stage 5: Model Training Pipeline Started
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:853] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:854] Model types: ['xgboost_vit_gru']
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:855] K-fold splits: 5
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:856] Frames per video: 1000
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:857] Output directory: data/stage5
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:858] Initializing pipeline...
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:261] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:262] STAGE 5 PREREQUISITE VALIDATION
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:263] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:266] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:275] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:276]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:279] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:287] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:288]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:291] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:299] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:300]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:303] 
================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:304] MODEL REQUIREMENTS CHECK
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:305] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:329] ✓ xgboost_vit_gru: CAN RUN
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:332] 
================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:333] VALIDATION SUMMARY
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:334] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:335] Stage 3 (scaled videos): ✓ Available
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:336]   Count: 3278 videos
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:337] Stage 2 (features): ✓ Available
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:338]   Count: 3278 feature rows
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:339] Stage 4 (scaled features): ✓ Available
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:340]   Count: 3277 feature rows
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:341] 
Runnable models: 1/1
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:342]   ['xgboost_vit_gru']
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:349] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:942] 
Stage 5: Loading metadata...
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:968] Loaded metadata: 3278 rows
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:978] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-14 13:28:48 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=825696.45GB, used=1674143.55GB (67.0%)
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:1000] Loading Stage 2 and Stage 4 features (required for feature-based models)...
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:1010] Stage 5: Found 3278 scaled videos
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:1015] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:1016] STAGE 5: VALIDATING VIDEOS (checking for corruption and empty videos)
2025-12-14 13:28:48 [INFO] [lib.training.pipeline:1017] ================================================================================
2025-12-14 13:28:48 [INFO] [lib.data.loading:156] Checking file existence for 3278 videos...
2025-12-14 13:28:50 [INFO] [lib.data.loading:166] Found 3278 existing video files (filtered out 0 missing files)
2025-12-14 13:28:50 [INFO] [lib.data.loading:170] Checking for corrupted videos (moov atom errors, etc.)...
2025-12-14 13:28:50 [INFO] [lib.data.loading:92] Loaded validation cache from /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/.video_validation_cache/validation_0192be168a40eb7e_corruptTrue_framesTrue.parquet (3278 entries)
2025-12-14 13:28:50 [INFO] [lib.data.loading:194] Cache hit: 3278 videos, Cache miss: 0 videos
2025-12-14 13:28:50 [WARNING] [lib.data.loading:306] Filtered out 1 corrupted videos and 0 empty videos. Keeping 3277 valid videos.
2025-12-14 13:28:50 [WARNING] [lib.data.loading:311] Sample of invalid videos:
2025-12-14 13:28:50 [WARNING] [lib.data.loading:313]   data/scaled_videos/FX5aeuJFQ64_aug1_scaled_aug1.mp4: Corrupted video: moov atom not found
2025-12-14 13:28:50 [INFO] [lib.data.loading:323] Found /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/skip_frame_check.txt - skipping frame check as requested.
2025-12-14 13:28:50 [WARNING] [lib.data.loading:387] Filtered out 1 invalid videos (corrupted). Keeping 3277 valid videos.
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1029] ✓ Video validation complete: 3277 valid videos ready for training
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1030] ================================================================================
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1116] Frame caching enabled (default): cache_dir=data/.frame_cache. This will cache processed frames to disk to speed up training. First epoch will be slower (building cache), subsequent epochs will be faster. To disable, set FVC_USE_FRAME_CACHE=0
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1202] Overriding num_frames to 400 for xgboost_vit_gru (XGBoost pretrained model with enhanced features) to balance performance and memory. Original num_frames was 1000.
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1252] 
================================================================================
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1253] Stage 5: Training model: xgboost_vit_gru
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1254] ================================================================================
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1275] Overriding model_config num_frames to 400 for xgboost_vit_gru (XGBoost pretrained model with enhanced feature extraction) to improve feature quality.
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1294] Grid search: 1 hyperparameter combinations to try
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1308] ================================================================================
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1309] HYPERPARAMETER SEARCH: Using 10.0% stratified sample for efficiency
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1310] ================================================================================
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1320] Hyperparameter search sample: 327 rows (10.0% of 3277 total)
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1321] To change sample size, set FVC_GRID_SEARCH_SAMPLE_SIZE environment variable (current: 0.1)
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1334] Using 5-fold stratified cross-validation on 10.0% sample for hyperparameter search
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1347] 
================================================================================
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1348] Grid Search: Hyperparameter combination 1/1
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1349] Parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1350] ================================================================================
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:1372] 
Hyperparameter Search - xgboost_vit_gru - Fold 1/5 (10.0% sample)
2025-12-14 13:28:50 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 1...
2025-12-14 13:28:50 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-14 13:28:50 [INFO] [lib.training._xgboost_pretrained:637] Processing 261 videos...
2025-12-14 13:28:50 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 13:28:58 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 13:28:58 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 13:28:58 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 13:28:59 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 13:28:59 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 13:28:59 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 13:29:00 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 13:46:02 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (261, 3072)
2025-12-14 13:46:03 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 13:46:03 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-14 13:46:03 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-14 13:46:04 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-14 13:46:04 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-14 13:46:04 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-14 13:46:04 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=133, scale_pos_weight=0.962
2025-12-14 13:46:04 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 208 train samples, 53 validation samples for early stopping
2025-12-14 13:46:04 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-14 13:46:13 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-14 13:46:13 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-14 13:46:13 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 13:46:14 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 13:46:14 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 13:46:14 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 13:46:15 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 13:46:15 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 13:46:15 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 13:46:15 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 13:50:38 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (66, 3072)
2025-12-14 13:50:38 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 13:50:38 [INFO] [lib.training.pipeline:536] Fold 1 - Val Loss: 0.4664, Val Acc: 0.7727, Val F1: 0.7692, Val Precision: 0.8065, Val Recall: 0.7353
2025-12-14 13:50:38 [INFO] [lib.training.pipeline:541]   Class 0 - Precision: 0.7429, Recall: 0.8125, F1: 0.7761
2025-12-14 13:50:38 [INFO] [lib.training.pipeline:545]   Class 1 - Precision: 0.8065, Recall: 0.7353, F1: 0.7692
2025-12-14 13:50:38 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_1
2025-12-14 13:50:38 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_1
2025-12-14 13:50:39 [INFO] [lib.training.pipeline:1372] 
Hyperparameter Search - xgboost_vit_gru - Fold 2/5 (10.0% sample)
2025-12-14 13:50:39 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 2...
2025-12-14 13:50:39 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-14 13:50:39 [INFO] [lib.training._xgboost_pretrained:637] Processing 261 videos...
2025-12-14 13:50:39 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 13:50:40 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 13:50:40 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 13:50:40 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 13:50:41 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 13:50:41 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 13:50:41 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 13:50:41 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 14:08:05 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (261, 3072)
2025-12-14 14:08:06 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 14:08:06 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-14 14:08:06 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-14 14:08:07 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-14 14:08:07 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-14 14:08:07 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-14 14:08:07 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=133, scale_pos_weight=0.962
2025-12-14 14:08:07 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 208 train samples, 53 validation samples for early stopping
2025-12-14 14:08:07 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-14 14:08:15 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 172 (out of 200)
2025-12-14 14:08:15 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-14 14:08:16 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 14:08:17 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 14:08:17 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 14:08:17 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 14:08:18 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 14:08:18 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 14:08:18 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 14:08:18 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 14:12:44 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (66, 3072)
2025-12-14 14:12:44 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 14:12:44 [INFO] [lib.training.pipeline:536] Fold 2 - Val Loss: 0.3902, Val Acc: 0.7879, Val F1: 0.7879, Val Precision: 0.8125, Val Recall: 0.7647
2025-12-14 14:12:44 [INFO] [lib.training.pipeline:541]   Class 0 - Precision: 0.7647, Recall: 0.8125, F1: 0.7879
2025-12-14 14:12:44 [INFO] [lib.training.pipeline:545]   Class 1 - Precision: 0.8125, Recall: 0.7647, F1: 0.7879
2025-12-14 14:12:44 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_2
2025-12-14 14:12:44 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_2
2025-12-14 14:12:45 [INFO] [lib.training.pipeline:1372] 
Hyperparameter Search - xgboost_vit_gru - Fold 3/5 (10.0% sample)
2025-12-14 14:12:45 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 3...
2025-12-14 14:12:45 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-14 14:12:45 [INFO] [lib.training._xgboost_pretrained:637] Processing 262 videos...
2025-12-14 14:12:45 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 14:12:46 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 14:12:46 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 14:12:46 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 14:12:47 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 14:12:47 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 14:12:47 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 14:12:47 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 14:29:53 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (262, 3072)
2025-12-14 14:29:53 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 14:29:53 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-14 14:29:53 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-14 14:29:54 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-14 14:29:54 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-14 14:29:54 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-14 14:29:54 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-14 14:29:54 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-14 14:29:54 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-14 14:29:58 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 32 (out of 200)
2025-12-14 14:29:58 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-14 14:29:58 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 14:29:59 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 14:29:59 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 14:30:00 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 14:30:00 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 14:30:00 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 14:30:01 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 14:30:01 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 14:34:31 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (65, 3072)
2025-12-14 14:34:32 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 14:34:32 [INFO] [lib.training.pipeline:536] Fold 3 - Val Loss: 0.5288, Val Acc: 0.7385, Val F1: 0.7213, Val Precision: 0.7857, Val Recall: 0.6667
2025-12-14 14:34:32 [INFO] [lib.training.pipeline:541]   Class 0 - Precision: 0.7027, Recall: 0.8125, F1: 0.7536
2025-12-14 14:34:32 [INFO] [lib.training.pipeline:545]   Class 1 - Precision: 0.7857, Recall: 0.6667, F1: 0.7213
2025-12-14 14:34:32 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_3
2025-12-14 14:34:32 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_3
2025-12-14 14:34:32 [INFO] [lib.training.pipeline:1372] 
Hyperparameter Search - xgboost_vit_gru - Fold 4/5 (10.0% sample)
2025-12-14 14:34:32 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 4...
2025-12-14 14:34:32 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-14 14:34:32 [INFO] [lib.training._xgboost_pretrained:637] Processing 262 videos...
2025-12-14 14:34:32 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 14:34:33 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 14:34:33 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 14:34:33 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 14:34:34 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 14:34:34 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 14:34:34 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 14:34:34 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 14:51:50 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (262, 3072)
2025-12-14 14:51:50 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 14:51:50 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-14 14:51:50 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-14 14:51:51 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-14 14:51:51 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-14 14:51:51 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-14 14:51:51 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-14 14:51:51 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-14 14:51:51 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-14 14:51:56 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 51 (out of 200)
2025-12-14 14:51:56 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-14 14:51:56 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 14:51:57 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 14:51:57 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 14:51:57 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 14:51:58 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 14:51:58 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 14:51:58 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 14:51:58 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 14:56:19 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (65, 3072)
2025-12-14 14:56:19 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 14:56:19 [INFO] [lib.training.pipeline:536] Fold 4 - Val Loss: 0.4936, Val Acc: 0.7846, Val F1: 0.7941, Val Precision: 0.7714, Val Recall: 0.8182
2025-12-14 14:56:19 [INFO] [lib.training.pipeline:541]   Class 0 - Precision: 0.8000, Recall: 0.7500, F1: 0.7742
2025-12-14 14:56:19 [INFO] [lib.training.pipeline:545]   Class 1 - Precision: 0.7714, Recall: 0.8182, F1: 0.7941
2025-12-14 14:56:19 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_4
2025-12-14 14:56:19 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_4
2025-12-14 14:56:20 [INFO] [lib.training.pipeline:1372] 
Hyperparameter Search - xgboost_vit_gru - Fold 5/5 (10.0% sample)
2025-12-14 14:56:20 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 5...
2025-12-14 14:56:20 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-14 14:56:20 [INFO] [lib.training._xgboost_pretrained:637] Processing 262 videos...
2025-12-14 14:56:20 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 14:56:21 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 14:56:21 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 14:56:21 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 14:56:22 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 14:56:22 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 14:56:22 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 14:56:22 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 15:13:46 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (262, 3072)
2025-12-14 15:13:47 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 15:13:47 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-14 15:13:47 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-14 15:13:48 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-14 15:13:48 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-14 15:13:48 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-14 15:13:48 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=128, Class 1=134, scale_pos_weight=0.955
2025-12-14 15:13:48 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 209 train samples, 53 validation samples for early stopping
2025-12-14 15:13:48 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-14 15:13:55 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 111 (out of 200)
2025-12-14 15:13:55 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-14 15:13:55 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 15:13:56 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 15:13:56 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 15:13:56 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 15:13:57 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 15:13:57 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 15:13:57 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 15:13:57 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 15:17:52 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (65, 3072)
2025-12-14 15:17:53 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:536] Fold 5 - Val Loss: 0.4740, Val Acc: 0.7692, Val F1: 0.7692, Val Precision: 0.7812, Val Recall: 0.7576
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:541]   Class 0 - Precision: 0.7576, Recall: 0.7812, F1: 0.7692
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:545]   Class 1 - Precision: 0.7812, Recall: 0.7576, F1: 0.7692
2025-12-14 15:17:53 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_5
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_5
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:2026] Parameter combination 1 - Mean F1: 0.7684, Mean Acc: 0.7706
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:2038] Using single parameter combination: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:2041] ================================================================================
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:2042] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:2043] ================================================================================
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:2056] Final training: Using 5-fold stratified cross-validation on full dataset (3277 rows)
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:2064] Final training using best hyperparameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8}
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:2070] 
Final Training - xgboost_vit_gru - Fold 1/5 (full dataset)
2025-12-14 15:17:53 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 1...
2025-12-14 15:17:53 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-14 15:17:53 [INFO] [lib.training._xgboost_pretrained:637] Processing 2621 videos...
2025-12-14 15:17:53 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 15:17:54 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 15:17:54 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 15:17:54 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 15:17:55 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 15:17:55 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 15:17:55 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 15:17:56 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 18:12:34 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2621, 3072)
2025-12-14 18:12:34 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 18:12:34 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-14 18:12:35 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-14 18:12:36 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-14 18:12:36 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-14 18:12:36 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-14 18:12:36 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1337, scale_pos_weight=0.960
2025-12-14 18:12:36 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2096 train samples, 525 validation samples for early stopping
2025-12-14 18:12:36 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-14 18:13:32 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-14 18:13:32 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-14 18:13:32 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 18:13:33 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 18:13:34 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 18:13:34 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 18:13:34 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 18:13:34 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 18:13:35 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 18:13:35 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 18:55:45 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (656, 3072)
2025-12-14 18:55:46 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 18:55:46 [INFO] [lib.training.pipeline:536] Fold 1 - Val Loss: 0.0490, Val Acc: 0.9954, Val F1: 0.9955, Val Precision: 0.9970, Val Recall: 0.9940
2025-12-14 18:55:46 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_1
2025-12-14 18:55:46 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_1
2025-12-14 18:55:46 [INFO] [lib.training.pipeline:2070] 
Final Training - xgboost_vit_gru - Fold 2/5 (full dataset)
2025-12-14 18:55:46 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 2...
2025-12-14 18:55:46 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-14 18:55:46 [INFO] [lib.training._xgboost_pretrained:637] Processing 2621 videos...
2025-12-14 18:55:46 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 18:55:47 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 18:55:47 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 18:55:48 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 18:55:48 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 18:55:48 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 18:55:48 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 18:55:49 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 21:51:42 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2621, 3072)
2025-12-14 21:51:42 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 21:51:42 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-14 21:51:42 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-14 21:51:44 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-14 21:51:44 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-14 21:51:44 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-14 21:51:44 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1337, scale_pos_weight=0.960
2025-12-14 21:51:44 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2096 train samples, 525 validation samples for early stopping
2025-12-14 21:51:44 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-14 21:52:39 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-14 21:52:39 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-14 21:52:39 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 21:52:40 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 21:52:40 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 21:52:40 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 21:52:41 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 21:52:41 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 21:52:41 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 21:52:41 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-14 22:35:53 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (656, 3072)
2025-12-14 22:35:54 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-14 22:35:54 [INFO] [lib.training.pipeline:536] Fold 2 - Val Loss: 0.0429, Val Acc: 0.9970, Val F1: 0.9970, Val Precision: 0.9970, Val Recall: 0.9970
2025-12-14 22:35:54 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_2
2025-12-14 22:35:54 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_2
2025-12-14 22:35:54 [INFO] [lib.training.pipeline:2070] 
Final Training - xgboost_vit_gru - Fold 3/5 (full dataset)
2025-12-14 22:35:54 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 3...
2025-12-14 22:35:54 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-14 22:35:54 [INFO] [lib.training._xgboost_pretrained:637] Processing 2622 videos...
2025-12-14 22:35:54 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-14 22:35:55 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-14 22:35:56 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-14 22:35:56 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-14 22:35:56 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-14 22:35:56 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-14 22:35:56 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-14 22:35:56 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-15 01:31:29 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2622, 3072)
2025-12-15 01:31:29 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-15 01:31:29 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-15 01:31:30 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-15 01:31:31 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-15 01:31:31 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-15 01:31:31 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-15 01:31:31 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-15 01:31:31 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-15 01:31:31 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-15 01:32:26 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-15 01:32:26 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-15 01:32:26 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-15 01:32:27 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-15 01:32:28 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-15 01:32:28 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-15 01:32:28 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-15 01:32:29 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-15 01:32:29 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-15 01:32:29 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-15 02:15:48 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (655, 3072)
2025-12-15 02:15:48 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-15 02:15:48 [INFO] [lib.training.pipeline:536] Fold 3 - Val Loss: 0.0505, Val Acc: 0.9924, Val F1: 0.9925, Val Precision: 0.9940, Val Recall: 0.9910
2025-12-15 02:15:48 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_3
2025-12-15 02:15:48 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_3
2025-12-15 02:15:49 [INFO] [lib.training.pipeline:2070] 
Final Training - xgboost_vit_gru - Fold 4/5 (full dataset)
2025-12-15 02:15:49 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 4...
2025-12-15 02:15:49 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-15 02:15:49 [INFO] [lib.training._xgboost_pretrained:637] Processing 2622 videos...
2025-12-15 02:15:49 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-15 02:15:50 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-15 02:15:50 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-15 02:15:50 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-15 02:15:51 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-15 02:15:51 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-15 02:15:51 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-15 02:15:51 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-15 05:10:00 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2622, 3072)
2025-12-15 05:10:00 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-15 05:10:00 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-15 05:10:01 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-15 05:10:02 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-15 05:10:02 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-15 05:10:02 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-15 05:10:02 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-15 05:10:02 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-15 05:10:02 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-15 05:10:57 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-15 05:10:57 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-15 05:10:58 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-15 05:10:59 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-15 05:10:59 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-15 05:10:59 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-15 05:11:00 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-15 05:11:00 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-15 05:11:00 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-15 05:11:00 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-15 05:54:40 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (655, 3072)
2025-12-15 05:54:41 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-15 05:54:41 [INFO] [lib.training.pipeline:536] Fold 4 - Val Loss: 0.0447, Val Acc: 0.9969, Val F1: 0.9970, Val Precision: 0.9970, Val Recall: 0.9970
2025-12-15 05:54:41 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_4
2025-12-15 05:54:41 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_4
2025-12-15 05:54:41 [INFO] [lib.training.pipeline:2070] 
Final Training - xgboost_vit_gru - Fold 5/5 (full dataset)
2025-12-15 05:54:41 [INFO] [lib.training.pipeline:480] Training XGBoost model xgboost_vit_gru on fold 5...
2025-12-15 05:54:41 [INFO] [lib.training._xgboost_pretrained:636] Training XGBoost on features from vit_gru...
2025-12-15 05:54:41 [INFO] [lib.training._xgboost_pretrained:637] Processing 2622 videos...
2025-12-15 05:54:41 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-15 05:54:42 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-15 05:54:42 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-15 05:54:42 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-15 05:54:43 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-15 05:54:43 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-15 05:54:43 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-15 05:54:43 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-15 08:59:59 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (2622, 3072)
2025-12-15 09:00:00 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-15 09:00:00 [INFO] [lib.training._xgboost_pretrained:660] Removing collinear features...
2025-12-15 09:00:00 [INFO] [lib.training.feature_preprocessing:77] Removed 0 features with zero variance
2025-12-15 09:00:02 [INFO] [lib.training.feature_preprocessing:141] Removed 0 collinear features (correlation >= 0.95)
2025-12-15 09:00:02 [INFO] [lib.training.feature_preprocessing:162] Final feature count: 3072/3072 (100.0% retained)
2025-12-15 09:00:02 [INFO] [lib.training._xgboost_pretrained:667] Using 3072 features after collinearity removal
2025-12-15 09:00:02 [INFO] [lib.training._xgboost_pretrained:683] Class distribution: Class 0=1284, Class 1=1338, scale_pos_weight=0.960
2025-12-15 09:00:02 [INFO] [lib.training._xgboost_pretrained:701] Training XGBoost: 2097 train samples, 525 validation samples for early stopping
2025-12-15 09:00:02 [INFO] [lib.training._xgboost_pretrained:704] Training XGBoost with improved architecture (multi-layer + temporal pooling + class weights + early stopping)...
2025-12-15 09:00:57 [INFO] [lib.training._xgboost_pretrained:770] Early stopping: Best iteration = 200 (out of 200)
2025-12-15 09:00:57 [INFO] [lib.training._xgboost_pretrained:772] ✓ XGBoost trained on pretrained model features with enhanced feature extraction
2025-12-15 09:00:57 [INFO] [lib.training._xgboost_pretrained:522] Loading pretrained model: vit_gru (num_frames=400)
2025-12-15 09:00:58 [INFO] [timm.models._builder:217] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg2_in21k_ft_in1k)
2025-12-15 09:00:59 [INFO] [timm.models._hub:232] [timm/vit_base_patch16_224.augreg2_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-12-15 09:00:59 [INFO] [timm.layers.pos_embed:57] Resized position embedding: (14, 14) to (16, 16).
2025-12-15 09:00:59 [INFO] [lib.training._xgboost_pretrained:537] Loaded vit_gru model to GPU, cleared cache
2025-12-15 09:00:59 [INFO] [lib.training._xgboost_pretrained:554] ViT model (vit_gru) requires 256x256 input. Setting fixed_size=256 (VideoDataset will resize even with use_scaled_videos=True).
2025-12-15 09:01:00 [INFO] [lib.training._xgboost_pretrained:604] Extracting features using vit_gru (num_frames=400)...
2025-12-15 09:01:00 [INFO] [lib.training._xgboost_pretrained:101] Applied PyTorch memory optimizations for feature extraction
2025-12-15 09:43:28 [INFO] [lib.training._xgboost_pretrained:410] Extracted features shape: (655, 3072)
2025-12-15 09:43:28 [INFO] [lib.training._xgboost_pretrained:622] Cleared vit_gru model from GPU after feature extraction
2025-12-15 09:43:28 [INFO] [lib.training.pipeline:536] Fold 5 - Val Loss: 0.0463, Val Acc: 0.9985, Val F1: 0.9985, Val Precision: 1.0000, Val Recall: 0.9970
2025-12-15 09:43:28 [INFO] [lib.training._xgboost_pretrained:840] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_5
2025-12-15 09:43:28 [INFO] [lib.training.pipeline:552] Saved XGBoost model to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/fold_5
2025-12-15 09:43:29 [INFO] [lib.training.pipeline:112] Saved best model from fold 5: Copied 2 model file(s) from fold_5 to best_model
2025-12-15 09:43:29 [INFO] [lib.training.pipeline:2408] 
xgboost_vit_gru - Avg Val Loss: 0.0467, Avg Val Acc: 0.9960, Avg Val F1: 0.9961
2025-12-15 09:43:31 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/plots/cv_fold_comparison.png
2025-12-15 09:43:31 [INFO] [lib.training.pipeline:2436] Generated plots for xgboost_vit_gru in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/xgboost_vit_gru/plots
2025-12-15 09:43:31 [INFO] [lib.training.pipeline:2473] ================================================================================
2025-12-15 09:43:31 [INFO] [lib.training.pipeline:2474] Stage 5: Model Training Pipeline Completed
2025-12-15 09:43:31 [INFO] [lib.training.pipeline:2475] ================================================================================
2025-12-15 09:43:31 [INFO] [__main__:401] ================================================================================
2025-12-15 09:43:32 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-15 09:43:32 [INFO] [__main__:403] ================================================================================
2025-12-15 09:43:32 [INFO] [__main__:404] Execution time: 72883.74 seconds (1214.73 minutes)
2025-12-15 09:43:32 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-15 09:43:32 [INFO] [__main__:407] Models trained: ['xgboost_vit_gru']
2025-12-15 09:43:32 [INFO] [__main__:408] K-fold splits: 5
2025-12-15 09:43:32 [INFO] [__main__:414] ================================================================================
2025-12-15 09:43:32 [INFO] [__main__:415] Final memory statistics:
2025-12-15 09:43:32 [INFO] [__main__:416] ================================================================================
2025-12-15 09:43:32 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: after training): {'cpu_memory_mb': 12359.6328125, 'cpu_memory_gb': 12.069953918457031, 'cpu_vms_mb': 59910.28515625, 'gpu_allocated_gb': 0.009568256, 'gpu_reserved_gb': 0.046137344, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.882204672}
2025-12-15 09:43:32 [INFO] [__main__:419] ================================================================================
2025-12-15 09:43:32 [INFO] [__main__:420] Training complete!
2025-12-15 09:43:32 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-15 09:43:32 [INFO] [__main__:422] ================================================================================
