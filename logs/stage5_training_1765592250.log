2025-12-12 21:17:30 [INFO] [__main__:310] ================================================================================
2025-12-12 21:17:30 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-12 21:17:30 [INFO] [__main__:312] ================================================================================
2025-12-12 21:17:30 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-12 21:17:30 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 21:17:30 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 21:17:30 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 21:17:30 [INFO] [__main__:317] Model types: ['x3d']
2025-12-12 21:17:30 [INFO] [__main__:318] K-fold splits: 5
2025-12-12 21:17:30 [INFO] [__main__:319] Number of frames: 500
2025-12-12 21:17:30 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 21:17:30 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-12 21:17:30 [INFO] [__main__:324] Delete existing: False
2025-12-12 21:17:30 [INFO] [__main__:325] Resume mode: True
2025-12-12 21:17:30 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765592250.log
2025-12-12 21:17:30 [INFO] [__main__:333] ================================================================================
2025-12-12 21:17:30 [INFO] [__main__:334] Checking prerequisites...
2025-12-12 21:17:30 [INFO] [__main__:335] ================================================================================
2025-12-12 21:17:30 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 21:17:30 [INFO] [__main__:352] ✓ All model types are valid
2025-12-12 21:17:30 [INFO] [__main__:358] ================================================================================
2025-12-12 21:17:30 [INFO] [__main__:359] Initial memory statistics:
2025-12-12 21:17:30 [INFO] [__main__:360] ================================================================================
2025-12-12 21:17:30 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.703125, 'cpu_memory_gb': 0.7184600830078125, 'cpu_vms_mb': 10218.6484375, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-12 21:17:30 [INFO] [__main__:364] ================================================================================
2025-12-12 21:17:30 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-12 21:17:30 [INFO] [__main__:366] ================================================================================
2025-12-12 21:17:30 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-12 21:17:30 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-12 21:17:30 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-12 21:17:30 [INFO] [__main__:370] ================================================================================
2025-12-12 21:17:30 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-12 21:17:30 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:496] ================================================================================
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:497] Stage 5: Model Training Pipeline Started
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:498] ================================================================================
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:499] Model types: ['x3d']
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:500] K-fold splits: 5
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:501] Frames per video: 500
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:502] Output directory: data/stage5
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:503] Initializing pipeline...
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:265] ================================================================================
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:266] STAGE 5 PREREQUISITE VALIDATION
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:267] ================================================================================
2025-12-12 21:17:30 [INFO] [lib.training.pipeline:270] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:279] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:280]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:283] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:291] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:292]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:295] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:303] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:304]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:307] 
================================================================================
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:308] MODEL REQUIREMENTS CHECK
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:309] ================================================================================
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:333] ✓ x3d: CAN RUN
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:336] 
================================================================================
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:337] VALIDATION SUMMARY
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:338] ================================================================================
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:339] Stage 3 (scaled videos): ✓ Available
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:340]   Count: 3278 videos
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:341] Stage 2 (features): ✓ Available
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:342]   Count: 3278 feature rows
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:343] Stage 4 (scaled features): ✓ Available
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:344]   Count: 3277 feature rows
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:345] 
Runnable models: 1/1
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:346]   ['x3d']
2025-12-12 21:17:31 [INFO] [lib.training.pipeline:353] ================================================================================
2025-12-12 21:17:32 [INFO] [lib.training.pipeline:589] 
Stage 5: Loading metadata...
2025-12-12 21:17:32 [INFO] [lib.training.pipeline:615] Loaded metadata: 3278 rows
2025-12-12 21:17:32 [INFO] [lib.training.pipeline:625] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-12 21:17:32 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=832969.95GB, used=1666870.05GB (66.7%)
2025-12-12 21:17:32 [INFO] [lib.training.pipeline:657] Stage 5: Found 3278 scaled videos
2025-12-12 21:17:32 [INFO] [lib.training.pipeline:705] Enabling adaptive chunked frame loading for x3d: initial_chunk_size=30, num_frames=500. Chunk size will adapt automatically based on OOM events (AIMD algorithm).
2025-12-12 21:17:32 [INFO] [lib.training.pipeline:788] 
================================================================================
2025-12-12 21:17:32 [INFO] [lib.training.pipeline:789] Stage 5: Training model: x3d
2025-12-12 21:17:32 [INFO] [lib.training.pipeline:790] ================================================================================
2025-12-12 21:17:33 [INFO] [lib.training.pipeline:823] Grid search: 16 hyperparameter combinations to try
2025-12-12 21:17:33 [INFO] [lib.training.pipeline:831] ================================================================================
2025-12-12 21:17:33 [INFO] [lib.training.pipeline:832] HYPERPARAMETER SEARCH: Using 20% stratified sample for efficiency
2025-12-12 21:17:33 [INFO] [lib.training.pipeline:833] ================================================================================
2025-12-12 21:17:33 [INFO] [lib.training.pipeline:842] Hyperparameter search sample: 655 rows (20.0% of 3278 total)
2025-12-12 21:17:34 [INFO] [lib.training.pipeline:855] Using 5-fold stratified cross-validation on 20% sample for hyperparameter search
2025-12-12 21:17:34 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:17:34 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 1/16
2025-12-12 21:17:34 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001}
2025-12-12 21:17:34 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:17:34 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:17:34 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:17:35 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:17:35 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:17:36 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:17:43 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4f8297135d58496c9de856192c01f8bc (experiment: x3d)
2025-12-12 21:17:43 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:17:54 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:17:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:17:59 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:17:59 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:17:59 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4f8297135d58496c9de856192c01f8bc
2025-12-12 21:18:00 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:18:00 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:18:00 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:18:00 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:18:00 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:18:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 075e4f0ded4945f3877f1d6c5d426faf (experiment: x3d)
2025-12-12 21:18:00 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:18:04 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:18:04 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:18:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:18:09 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:18:09 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:18:09 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 075e4f0ded4945f3877f1d6c5d426faf
2025-12-12 21:18:10 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:18:10 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:18:10 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:18:10 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:18:10 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:18:10 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ba3d3ca3f4864a33b0d146da93ecc48b (experiment: x3d)
2025-12-12 21:18:10 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:18:15 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:18:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:18:20 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:18:30 [WARNING] [lib.training.trainer:369] Skipping batch 1 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:18:35 [WARNING] [lib.training.trainer:369] Skipping batch 2 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 144]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:18:41 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:18:42 [WARNING] [lib.training.trainer:369] Skipping batch 3 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:18:47 [WARNING] [lib.training.trainer:369] Skipping batch 4 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:18:51 [WARNING] [lib.training.trainer:369] Skipping batch 5 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:18:55 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:18:56 [WARNING] [lib.training.trainer:369] Skipping batch 6 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:01 [WARNING] [lib.training.trainer:369] Skipping batch 7 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:06 [WARNING] [lib.training.trainer:369] Skipping batch 8 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:10 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:19:22 [WARNING] [lib.training.trainer:369] Skipping batch 10 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:27 [WARNING] [lib.training.trainer:369] Skipping batch 11 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:30 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:19:31 [WARNING] [lib.training.trainer:369] Skipping batch 12 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:37 [WARNING] [lib.training.trainer:369] Skipping batch 13 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:42 [WARNING] [lib.training.trainer:369] Skipping batch 14 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:45 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:19:46 [WARNING] [lib.training.trainer:369] Skipping batch 15 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:51 [WARNING] [lib.training.trainer:369] Skipping batch 16 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:55 [WARNING] [lib.training.trainer:369] Skipping batch 17 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:19:59 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:20:00 [WARNING] [lib.training.trainer:369] Skipping batch 18 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 140]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:04 [WARNING] [lib.training.trainer:369] Skipping batch 19 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 144]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:09 [WARNING] [lib.training.trainer:369] Skipping batch 20 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:14 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:20:15 [WARNING] [lib.training.trainer:369] Skipping batch 21 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:19 [WARNING] [lib.training.trainer:369] Skipping batch 22 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:26 [WARNING] [lib.training.trainer:369] Skipping batch 23 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:30 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:20:30 [WARNING] [lib.training.trainer:369] Skipping batch 24 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:35 [WARNING] [lib.training.trainer:369] Skipping batch 25 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:46 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:20:47 [WARNING] [lib.training.trainer:369] Skipping batch 27 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:20:53 [WARNING] [lib.training.trainer:369] Skipping batch 28 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:21:00 [WARNING] [lib.training.trainer:369] Skipping batch 29 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:21:04 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:21:05 [WARNING] [lib.training.trainer:369] Skipping batch 30 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:21:09 [WARNING] [lib.training.trainer:369] Skipping batch 31 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:21:16 [WARNING] [lib.training.trainer:369] Skipping batch 32 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:21:19 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:21:20 [WARNING] [lib.training.trainer:369] Skipping batch 33 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:21:25 [WARNING] [lib.training.trainer:369] Skipping batch 34 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:21:34 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:21:46 [WARNING] [lib.training.trainer:369] Skipping batch 38 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 144]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:21:50 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:21:51 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 39: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 48.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 149.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:21:52 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 39): {'cpu_memory_mb': 4323.3359375, 'cpu_memory_gb': 4.222007751464844, 'cpu_vms_mb': 51431.7109375, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.4626432, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.465698816}
2025-12-12 21:21:52 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 48.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 149.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 21:21:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:21:59 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:21:59 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:21:59 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: ba3d3ca3f4864a33b0d146da93ecc48b
2025-12-12 21:21:59 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:21:59 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:21:59 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:21:59 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:21:59 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:21:59 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 100c96ad45ec438e8621c9d83424af68 (experiment: x3d)
2025-12-12 21:21:59 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:22:04 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:22:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:22:09 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:22:09 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:22:09 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:22:09 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 100c96ad45ec438e8621c9d83424af68
2025-12-12 21:22:10 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:22:10 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:22:10 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:22:10 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:22:10 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:22:10 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c37f7d120d3341fbbc76d658be77a281 (experiment: x3d)
2025-12-12 21:22:10 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:22:15 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:22:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:22:19 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:22:19 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:22:19 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c37f7d120d3341fbbc76d658be77a281
2025-12-12 21:22:20 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:22:20 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 2/16
2025-12-12 21:22:20 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001}
2025-12-12 21:22:20 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:22:20 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:22:20 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:22:20 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:22:20 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:22:20 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:22:20 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 63c784d4fcd04132aeae9e52900bb96e (experiment: x3d)
2025-12-12 21:22:20 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:22:24 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:22:25 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:22:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:22:30 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:22:30 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:22:30 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 63c784d4fcd04132aeae9e52900bb96e
2025-12-12 21:22:30 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:22:30 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:22:30 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:22:30 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:22:30 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:22:30 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0b0df8730f9c441891b033bd56f1fa26 (experiment: x3d)
2025-12-12 21:22:30 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:22:34 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:22:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:22:38 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:22:39 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:22:39 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:22:39 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0b0df8730f9c441891b033bd56f1fa26
2025-12-12 21:22:39 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:22:39 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:22:39 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:22:39 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:22:40 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:22:40 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9f6287209158431c8dfd617a9caccba7 (experiment: x3d)
2025-12-12 21:22:40 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:22:44 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:22:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:22:49 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:22:49 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:22:49 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9f6287209158431c8dfd617a9caccba7
2025-12-12 21:22:49 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:22:49 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:22:49 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:22:49 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:22:50 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:22:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0e7fffa6769f487fbe240d59641c774e (experiment: x3d)
2025-12-12 21:22:50 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:22:53 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:22:54 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:22:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:23:05 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 1: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:23:05 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 1): {'cpu_memory_mb': 4322.88671875, 'cpu_memory_gb': 4.221569061279297, 'cpu_vms_mb': 51431.7109375, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.439574528, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.488767488}
2025-12-12 21:23:05 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 21:23:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:23:09 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:23:10 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:23:10 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    return self.backbone(x)
           ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:23:10 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0e7fffa6769f487fbe240d59641c774e
2025-12-12 21:23:10 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:23:10 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:23:11 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:23:11 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:23:11 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:23:11 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7a19657cc7624d339bf2db8144fa049d (experiment: x3d)
2025-12-12 21:23:11 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:23:15 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:23:15 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:23:20 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:23:20 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:23:20 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7a19657cc7624d339bf2db8144fa049d
2025-12-12 21:23:20 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:23:20 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 3/16
2025-12-12 21:23:20 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-12 21:23:20 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:23:20 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:23:20 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:23:21 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:23:21 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:23:21 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:23:21 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: b2b21ac67ad9442b87239f019f57e9de (experiment: x3d)
2025-12-12 21:23:21 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:23:25 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:23:25 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:23:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:23:31 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:23:31 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:23:31 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: b2b21ac67ad9442b87239f019f57e9de
2025-12-12 21:23:31 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:23:31 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:23:31 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:23:31 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:23:32 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:23:32 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 19a641b2f44a41739b86be951d89b293 (experiment: x3d)
2025-12-12 21:23:32 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:23:36 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:23:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:23:39 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:23:49 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 1: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:23:49 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 1): {'cpu_memory_mb': 4526.67578125, 'cpu_memory_gb': 4.420581817626953, 'cpu_vms_mb': 51635.52734375, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.439574528, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.488767488}
2025-12-12 21:23:49 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 21:23:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:24:00 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:24:00 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:24:00 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 19a641b2f44a41739b86be951d89b293
2025-12-12 21:24:01 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:24:01 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:24:01 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:24:01 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:24:01 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:24:01 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ccd481ebae1f4501bee8d900e99f4265 (experiment: x3d)
2025-12-12 21:24:01 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:24:05 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:24:06 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:24:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:24:12 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 10.19 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 183.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:24:12 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6124.84375, 'cpu_memory_gb': 5.981292724609375, 'cpu_vms_mb': 53233.8125, 'gpu_allocated_gb': 16.310142464, 'gpu_reserved_gb': 16.502489088, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.425852928}
2025-12-12 21:24:12 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 10.19 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 183.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 21:24:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:24:18 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:24:18 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:24:18 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: ccd481ebae1f4501bee8d900e99f4265
2025-12-12 21:24:19 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:24:19 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:24:19 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:24:19 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:24:19 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:24:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a1ecc3b46bce4fd4b5af5d8f491af0f3 (experiment: x3d)
2025-12-12 21:24:19 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:24:23 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:24:23 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:24:24 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:24:28 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:24:28 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:24:28 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a1ecc3b46bce4fd4b5af5d8f491af0f3
2025-12-12 21:24:28 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:24:28 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:24:28 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:24:28 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:24:28 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:24:28 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a5cc1b7a552741f2ac82e92f9abb4d68 (experiment: x3d)
2025-12-12 21:24:28 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:24:33 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:24:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:24:36 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:24:37 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:24:37 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:24:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a5cc1b7a552741f2ac82e92f9abb4d68
2025-12-12 21:24:37 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:24:37 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 4/16
2025-12-12 21:24:37 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001}
2025-12-12 21:24:37 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:24:37 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:24:37 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:24:38 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:24:38 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:24:38 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:24:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5682c99872734f68bed9ad331f0c874f (experiment: x3d)
2025-12-12 21:24:38 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:24:42 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:24:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:24:52 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:24:53 [WARNING] [lib.training.trainer:369] Skipping batch 1 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:24:57 [WARNING] [lib.training.trainer:369] Skipping batch 2 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:02 [WARNING] [lib.training.trainer:369] Skipping batch 3 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:08 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:25:08 [WARNING] [lib.training.trainer:369] Skipping batch 4 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:13 [WARNING] [lib.training.trainer:369] Skipping batch 5 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:17 [WARNING] [lib.training.trainer:369] Skipping batch 6 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:21 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:25:22 [WARNING] [lib.training.trainer:369] Skipping batch 7 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:27 [WARNING] [lib.training.trainer:369] Skipping batch 8 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:31 [WARNING] [lib.training.trainer:369] Skipping batch 9 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:35 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:25:36 [WARNING] [lib.training.trainer:369] Skipping batch 10 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:41 [WARNING] [lib.training.trainer:369] Skipping batch 11 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:46 [WARNING] [lib.training.trainer:369] Skipping batch 12 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:49 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:25:50 [WARNING] [lib.training.trainer:369] Skipping batch 13 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:55 [WARNING] [lib.training.trainer:369] Skipping batch 14 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 174, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:25:59 [WARNING] [lib.training.trainer:369] Skipping batch 15 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:04 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:26:05 [WARNING] [lib.training.trainer:369] Skipping batch 16 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:11 [WARNING] [lib.training.trainer:369] Skipping batch 17 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:15 [WARNING] [lib.training.trainer:369] Skipping batch 18 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:19 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:26:20 [WARNING] [lib.training.trainer:369] Skipping batch 19 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:30 [WARNING] [lib.training.trainer:369] Skipping batch 20 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:34 [WARNING] [lib.training.trainer:369] Skipping batch 21 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:38 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:26:39 [WARNING] [lib.training.trainer:369] Skipping batch 22 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:47 [WARNING] [lib.training.trainer:369] Skipping batch 23 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:53 [WARNING] [lib.training.trainer:369] Skipping batch 24 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:26:57 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:26:58 [WARNING] [lib.training.trainer:369] Skipping batch 25 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:27:05 [WARNING] [lib.training.trainer:369] Skipping batch 26 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:27:09 [WARNING] [lib.training.trainer:369] Skipping batch 27 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 186, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:27:13 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:27:13 [WARNING] [lib.training.trainer:369] Skipping batch 28 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:27:18 [WARNING] [lib.training.trainer:369] Skipping batch 29 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 142]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:27:22 [WARNING] [lib.training.trainer:369] Skipping batch 30 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 144]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:27:27 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:27:28 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 31: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:27:28 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 31): {'cpu_memory_mb': 6127.3359375, 'cpu_memory_gb': 5.983726501464844, 'cpu_vms_mb': 53235.8125, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.439574528, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.488767488}
2025-12-12 21:27:28 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 21:27:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:27:35 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:27:35 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:27:35 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5682c99872734f68bed9ad331f0c874f
2025-12-12 21:27:36 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:27:36 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:27:36 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:27:36 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:27:37 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:27:37 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4650b93de606404d91b107e7a2a407fd (experiment: x3d)
2025-12-12 21:27:37 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:27:41 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:27:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:27:44 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:27:45 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:27:45 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:27:45 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4650b93de606404d91b107e7a2a407fd
2025-12-12 21:27:45 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:27:45 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:27:46 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:27:46 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:27:46 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:27:46 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: be0541e6b3e243cd886153fe0429ddee (experiment: x3d)
2025-12-12 21:27:46 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:27:50 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:27:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:27:55 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:27:55 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:27:55 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: be0541e6b3e243cd886153fe0429ddee
2025-12-12 21:27:55 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:27:55 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:27:55 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:27:55 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:27:55 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:27:55 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 24fa58ed65944b11826593f3a0533668 (experiment: x3d)
2025-12-12 21:27:55 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:27:59 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:28:00 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:28:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:28:04 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:28:04 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:28:04 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 24fa58ed65944b11826593f3a0533668
2025-12-12 21:28:04 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:28:04 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:28:05 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:28:05 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:28:05 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:28:05 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 29c6efd5d5454331a42a676189dff8b0 (experiment: x3d)
2025-12-12 21:28:05 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:28:09 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:28:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:28:14 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:28:15 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:28:15 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:28:15 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 29c6efd5d5454331a42a676189dff8b0
2025-12-12 21:28:15 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:28:15 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 5/16
2025-12-12 21:28:15 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001}
2025-12-12 21:28:15 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:28:15 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:28:15 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:28:15 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:28:15 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:28:15 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:28:15 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 71497e37b9e140719fe7777c5dd6a9c1 (experiment: x3d)
2025-12-12 21:28:16 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:28:20 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:28:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:28:25 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 156.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:28:26 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6127.3359375, 'cpu_memory_gb': 5.983726501464844, 'cpu_vms_mb': 53235.8125, 'gpu_allocated_gb': 16.293907968, 'gpu_reserved_gb': 16.458448896, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.46989312}
2025-12-12 21:28:26 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 156.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 21:28:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:28:30 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:28:31 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 156.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:28:31 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6127.3359375, 'cpu_memory_gb': 5.983726501464844, 'cpu_vms_mb': 53235.8125, 'gpu_allocated_gb': 16.293907968, 'gpu_reserved_gb': 16.458448896, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.46989312}
2025-12-12 21:28:31 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 156.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 21:28:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:28:37 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:28:37 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:28:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 71497e37b9e140719fe7777c5dd6a9c1
2025-12-12 21:28:37 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:28:37 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:28:38 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:28:38 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:28:38 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:28:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1ec8d5299653486182c5a3296d5b3fb4 (experiment: x3d)
2025-12-12 21:28:38 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:28:42 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:28:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:28:46 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:28:47 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:28:47 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:28:47 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1ec8d5299653486182c5a3296d5b3fb4
2025-12-12 21:28:47 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:28:47 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:28:47 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:28:47 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:28:48 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:28:48 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 002bfb79ccd94816aac8d0b8cb05fcf5 (experiment: x3d)
2025-12-12 21:28:48 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:28:52 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:28:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:28:56 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:28:56 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:28:56 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 002bfb79ccd94816aac8d0b8cb05fcf5
2025-12-12 21:28:56 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:28:56 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:28:57 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:28:57 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:28:57 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:28:57 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5b8b75abf3db401da8c4a9aa2d393c8b (experiment: x3d)
2025-12-12 21:28:57 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:29:01 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:29:01 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:29:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:29:06 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:29:06 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:29:06 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5b8b75abf3db401da8c4a9aa2d393c8b
2025-12-12 21:29:06 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:29:06 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:29:06 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:29:06 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:29:07 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:29:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2ea4577f4b82447eb57ed463d9af10aa (experiment: x3d)
2025-12-12 21:29:07 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:29:11 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:29:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:29:15 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:29:16 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:29:16 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:29:16 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2ea4577f4b82447eb57ed463d9af10aa
2025-12-12 21:29:16 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:29:16 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 6/16
2025-12-12 21:29:16 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001}
2025-12-12 21:29:16 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:29:16 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:29:16 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:29:16 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:29:16 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:29:17 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:29:17 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a22edff558ee4d469d9e94ccc7a3bb08 (experiment: x3d)
2025-12-12 21:29:17 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:29:21 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:29:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:29:25 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:29:25 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:29:25 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a22edff558ee4d469d9e94ccc7a3bb08
2025-12-12 21:29:26 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:29:26 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:29:26 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:29:26 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:29:26 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:29:26 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 531b9b9b95f24d50bad010ca9d0148a7 (experiment: x3d)
2025-12-12 21:29:26 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:29:29 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:29:30 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:29:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:29:35 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:29:35 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:29:35 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 531b9b9b95f24d50bad010ca9d0148a7
2025-12-12 21:29:35 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:29:35 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:29:35 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:29:35 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:29:35 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:29:35 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e3e9108c582642d2bcdc568a23c581e5 (experiment: x3d)
2025-12-12 21:29:35 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:29:40 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:29:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:29:46 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:29:47 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:29:47 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:29:47 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e3e9108c582642d2bcdc568a23c581e5
2025-12-12 21:29:47 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:29:47 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:29:47 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:29:47 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:29:47 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:29:47 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 56d13eaa1de64049818ea45d652e2d85 (experiment: x3d)
2025-12-12 21:29:47 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:29:52 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:29:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:29:56 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:29:56 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:29:56 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 56d13eaa1de64049818ea45d652e2d85
2025-12-12 21:29:56 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:29:56 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:29:57 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:29:57 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:29:57 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:29:57 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 93aaa011da4c4b4f8eb40cf9b9f67b33 (experiment: x3d)
2025-12-12 21:29:57 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:30:01 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:30:01 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:30:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:30:11 [WARNING] [lib.training.trainer:369] Skipping batch 1 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:30:15 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:30:16 [WARNING] [lib.training.trainer:369] Skipping batch 2 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:30:26 [WARNING] [lib.training.trainer:369] Skipping batch 3 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:30:33 [WARNING] [lib.training.trainer:369] Skipping batch 4 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:30:36 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:30:37 [WARNING] [lib.training.trainer:369] Skipping batch 5 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:30:42 [WARNING] [lib.training.trainer:369] Skipping batch 6 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 160, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:30:46 [WARNING] [lib.training.trainer:369] Skipping batch 7 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:30:56 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:30:57 [WARNING] [lib.training.trainer:369] Skipping batch 8 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:02 [WARNING] [lib.training.trainer:369] Skipping batch 9 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:19 [WARNING] [lib.training.trainer:369] Skipping batch 10 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:23 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:31:24 [WARNING] [lib.training.trainer:369] Skipping batch 11 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:29 [WARNING] [lib.training.trainer:369] Skipping batch 12 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:37 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:31:38 [WARNING] [lib.training.trainer:369] Skipping batch 14 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:43 [WARNING] [lib.training.trainer:369] Skipping batch 15 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:47 [WARNING] [lib.training.trainer:369] Skipping batch 16 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:51 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:31:52 [WARNING] [lib.training.trainer:369] Skipping batch 17 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:31:56 [WARNING] [lib.training.trainer:369] Skipping batch 18 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:32:05 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:32:06 [WARNING] [lib.training.trainer:369] Skipping batch 20 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 142]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:32:11 [WARNING] [lib.training.trainer:369] Skipping batch 21 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:32:15 [WARNING] [lib.training.trainer:369] Skipping batch 22 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:32:19 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:32:19 [WARNING] [lib.training.trainer:369] Skipping batch 23 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:32:25 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 24: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 68.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 129.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:32:25 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 24): {'cpu_memory_mb': 6129.28515625, 'cpu_memory_gb': 5.985630035400391, 'cpu_vms_mb': 53236.46875, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.44167168, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.486670336}
2025-12-12 21:32:25 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 68.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 129.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 21:32:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:32:29 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:32:29 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:32:29 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 93aaa011da4c4b4f8eb40cf9b9f67b33
2025-12-12 21:32:30 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:32:30 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 7/16
2025-12-12 21:32:30 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-12 21:32:30 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:32:30 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:32:30 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:32:30 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:32:30 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:32:30 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:32:30 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 7600881b9d4d48089b69bd57b6f5f59a (experiment: x3d)
2025-12-12 21:32:30 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:32:34 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:32:35 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:32:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:32:40 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 156.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:32:41 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6128.28515625, 'cpu_memory_gb': 5.984653472900391, 'cpu_vms_mb': 53235.46875, 'gpu_allocated_gb': 16.293907968, 'gpu_reserved_gb': 16.458448896, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.46989312}
2025-12-12 21:32:41 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 156.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 21:32:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:32:46 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 156.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:32:46 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6128.28515625, 'cpu_memory_gb': 5.984653472900391, 'cpu_vms_mb': 53235.46875, 'gpu_allocated_gb': 16.293907968, 'gpu_reserved_gb': 16.458448896, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.46989312}
2025-12-12 21:32:46 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 2/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 52.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 156.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 21:32:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:32:50 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:32:51 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:32:51 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:32:51 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 7600881b9d4d48089b69bd57b6f5f59a
2025-12-12 21:32:51 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:32:51 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:32:51 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:32:51 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:32:52 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:32:52 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 011dd116ee254bb1b9c9cabc92f98793 (experiment: x3d)
2025-12-12 21:32:52 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:32:56 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:32:56 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:33:01 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:33:01 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:33:01 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 011dd116ee254bb1b9c9cabc92f98793
2025-12-12 21:33:01 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:33:01 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:33:01 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:33:01 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:33:02 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:33:02 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 94813944babe45d9a9f644bd81d95d00 (experiment: x3d)
2025-12-12 21:33:02 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:33:06 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:33:06 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:33:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:33:11 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:33:11 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:33:11 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 94813944babe45d9a9f644bd81d95d00
2025-12-12 21:33:11 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:33:11 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:33:11 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:33:11 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:33:12 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:33:12 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a334d0119abc4b0fb9c0aa1cf3127069 (experiment: x3d)
2025-12-12 21:33:12 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:33:16 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:33:16 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:33:20 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:33:20 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:33:20 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:33:20 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a334d0119abc4b0fb9c0aa1cf3127069
2025-12-12 21:33:21 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:33:21 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:33:21 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:33:21 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:33:21 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:33:21 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d3c3d8f6cbc8428f9a43f5bf34b6d0aa (experiment: x3d)
2025-12-12 21:33:21 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:33:25 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:33:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:33:35 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:33:35 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:33:35 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: d3c3d8f6cbc8428f9a43f5bf34b6d0aa
2025-12-12 21:33:36 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:33:36 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 8/16
2025-12-12 21:33:36 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 5e-05, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001}
2025-12-12 21:33:36 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:33:36 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:33:36 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:33:36 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:33:36 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:33:36 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:33:36 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 08f7a88c24364795af91838d410f32f9 (experiment: x3d)
2025-12-12 21:33:36 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:33:40 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:33:41 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:33:41 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:33:52 [WARNING] [lib.training.trainer:369] Skipping batch 1 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:33:56 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:33:57 [WARNING] [lib.training.trainer:369] Skipping batch 2 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:34:02 [WARNING] [lib.training.trainer:369] Skipping batch 3 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:34:06 [WARNING] [lib.training.trainer:369] Skipping batch 4 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:34:13 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:34:14 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 5: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:34:14 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 5): {'cpu_memory_mb': 6129.07421875, 'cpu_memory_gb': 5.985424041748047, 'cpu_vms_mb': 53236.46875, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.439574528, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.488767488}
2025-12-12 21:34:14 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 21:34:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:34:21 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:34:21 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:34:21 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 08f7a88c24364795af91838d410f32f9
2025-12-12 21:34:21 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:34:21 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:34:21 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:34:21 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:34:22 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:34:22 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8996907b7a404e4c941298b387a52c59 (experiment: x3d)
2025-12-12 21:34:22 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:34:26 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:34:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:34:29 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:34:30 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:34:30 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:34:30 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8996907b7a404e4c941298b387a52c59
2025-12-12 21:34:31 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:34:31 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:34:31 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:34:31 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:34:31 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:34:31 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e080e5ee4c9c48ccab8f14c0db6c5e4b (experiment: x3d)
2025-12-12 21:34:31 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:34:35 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:34:36 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:34:40 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:34:40 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:34:40 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e080e5ee4c9c48ccab8f14c0db6c5e4b
2025-12-12 21:34:40 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:34:40 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:34:40 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:34:40 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:34:41 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:34:41 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 5e19912491554e0383353b25efdf79ab (experiment: x3d)
2025-12-12 21:34:41 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:34:45 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:34:45 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:34:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:34:50 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:34:50 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:34:50 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 5e19912491554e0383353b25efdf79ab
2025-12-12 21:34:50 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:34:50 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:34:50 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:34:50 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:34:51 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:34:51 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 78979a82275740f0902d886452511d11 (experiment: x3d)
2025-12-12 21:34:51 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:34:55 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:34:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:34:59 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:34:59 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:34:59 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:34:59 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 78979a82275740f0902d886452511d11
2025-12-12 21:35:00 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:35:00 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 9/16
2025-12-12 21:35:00 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001}
2025-12-12 21:35:00 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:35:00 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:35:00 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:35:00 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:35:00 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:35:00 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:35:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 36e6e90344d64b5db1766f26433a47f6 (experiment: x3d)
2025-12-12 21:35:00 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:35:05 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:35:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:35:09 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:35:09 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:35:09 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 36e6e90344d64b5db1766f26433a47f6
2025-12-12 21:35:10 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:35:10 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:35:10 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:35:10 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:35:10 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:35:10 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8701efd2498745179833b64c73e5130e (experiment: x3d)
2025-12-12 21:35:10 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:35:13 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:35:14 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:35:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:35:19 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:35:19 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:35:19 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8701efd2498745179833b64c73e5130e
2025-12-12 21:35:20 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:35:20 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:35:20 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:35:20 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:35:20 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:35:20 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0d5d26a6fdc84efca1456403b2412535 (experiment: x3d)
2025-12-12 21:35:20 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:35:24 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:35:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:35:28 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:35:29 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:35:29 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:35:29 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0d5d26a6fdc84efca1456403b2412535
2025-12-12 21:35:29 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:35:29 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:35:29 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:35:29 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:35:30 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:35:30 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: f0b010fa42154e2087573a7ed9bdba25 (experiment: x3d)
2025-12-12 21:35:30 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:35:34 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:35:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:35:39 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:35:39 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:35:39 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: f0b010fa42154e2087573a7ed9bdba25
2025-12-12 21:35:39 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:35:39 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:35:39 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:35:39 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:35:39 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:35:39 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 93f4f5a8a3e84e5f8cf6bc8bedff60fc (experiment: x3d)
2025-12-12 21:35:39 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:35:43 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:35:44 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:35:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:35:48 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:35:48 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:35:48 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 93f4f5a8a3e84e5f8cf6bc8bedff60fc
2025-12-12 21:35:49 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:35:49 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 10/16
2025-12-12 21:35:49 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0001, 'weight_decay': 0.001}
2025-12-12 21:35:49 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:35:49 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:35:49 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:35:49 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:35:49 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:35:49 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:35:49 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9ecfb4ae929f4e43be8bb54fe7d84cdb (experiment: x3d)
2025-12-12 21:35:49 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:35:54 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:35:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:35:57 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:35:58 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:35:58 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:35:58 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9ecfb4ae929f4e43be8bb54fe7d84cdb
2025-12-12 21:35:58 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:35:58 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:35:58 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:35:58 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:35:59 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:35:59 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0d1466510be1489693cf435295c598ac (experiment: x3d)
2025-12-12 21:35:59 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:36:03 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:36:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:36:07 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:36:07 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:36:07 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0d1466510be1489693cf435295c598ac
2025-12-12 21:36:07 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:36:07 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:36:08 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:36:08 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:36:08 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:36:08 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9a834a35a6c542608c6e0af60ae9f0a1 (experiment: x3d)
2025-12-12 21:36:08 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:36:12 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:36:13 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:36:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:36:17 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:36:17 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:36:17 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9a834a35a6c542608c6e0af60ae9f0a1
2025-12-12 21:36:17 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:36:17 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:36:18 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:36:18 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:36:18 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:36:18 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: c7652b2ada304f5bba6e65308353922c (experiment: x3d)
2025-12-12 21:36:18 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:36:22 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:36:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:36:26 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:36:27 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:36:27 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:36:27 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: c7652b2ada304f5bba6e65308353922c
2025-12-12 21:36:27 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:36:27 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:36:27 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:36:27 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:36:27 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:36:28 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a5df438eba6445028ff92bbbedf845ca (experiment: x3d)
2025-12-12 21:36:28 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:36:32 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:36:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:36:36 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:36:36 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:36:36 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a5df438eba6445028ff92bbbedf845ca
2025-12-12 21:36:37 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:36:37 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 11/16
2025-12-12 21:36:37 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-12 21:36:37 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:36:37 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:36:37 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:36:37 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:36:37 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:36:37 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:36:37 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8b78c4330327469a98d63b807e56a846 (experiment: x3d)
2025-12-12 21:36:37 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:36:41 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:36:41 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:36:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:36:52 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:36:52 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:36:52 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8b78c4330327469a98d63b807e56a846
2025-12-12 21:36:53 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:36:53 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:36:53 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:36:53 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:36:53 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:36:53 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a59f669da7494622b2631344d56f58e2 (experiment: x3d)
2025-12-12 21:36:53 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:36:57 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:36:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:37:01 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:37:01 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:37:01 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:37:01 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a59f669da7494622b2631344d56f58e2
2025-12-12 21:37:02 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:37:02 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:37:02 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:37:02 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:37:02 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:37:02 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 731ad460453b411ea478debf757d01b6 (experiment: x3d)
2025-12-12 21:37:02 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:37:06 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:37:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:37:13 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:37:13 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:37:13 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 731ad460453b411ea478debf757d01b6
2025-12-12 21:37:14 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:37:14 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:37:14 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:37:14 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:37:14 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:37:14 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8f26e76d800c4631b430e7c52f56989f (experiment: x3d)
2025-12-12 21:37:14 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:37:18 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:37:19 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:37:19 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:37:25 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 10.19 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 93.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:37:25 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6130.59375, 'cpu_memory_gb': 5.986907958984375, 'cpu_vms_mb': 53237.46875, 'gpu_allocated_gb': 16.376937472, 'gpu_reserved_gb': 16.502489088, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.425852928}
2025-12-12 21:37:25 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 10.19 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 93.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 4, Current batch size: 1
2025-12-12 21:37:25 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:37:30 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:37:30 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:37:30 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8f26e76d800c4631b430e7c52f56989f
2025-12-12 21:37:30 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:37:30 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:37:30 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:37:30 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:37:31 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:37:31 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: fb6d4c5d05324fcaa2c29b9c9f69b27d (experiment: x3d)
2025-12-12 21:37:31 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:37:34 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:37:35 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:37:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:37:41 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:37:41 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:37:41 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: fb6d4c5d05324fcaa2c29b9c9f69b27d
2025-12-12 21:37:42 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:37:42 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 12/16
2025-12-12 21:37:42 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 1e-06, 'head_lr': 0.0005, 'weight_decay': 0.001}
2025-12-12 21:37:42 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:37:42 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:37:42 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:37:42 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:37:42 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:37:42 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:37:42 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1e9194ae864e40689231bebc8d56861a (experiment: x3d)
2025-12-12 21:37:42 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:37:46 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:37:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:37:52 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:37:53 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 0: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 10.19 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 93.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:37:54 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 0): {'cpu_memory_mb': 6130.765625, 'cpu_memory_gb': 5.9870758056640625, 'cpu_vms_mb': 53237.46875, 'gpu_allocated_gb': 16.376937472, 'gpu_reserved_gb': 16.502489088, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.425852928}
2025-12-12 21:37:54 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 10.19 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 93.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 21:37:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:38:00 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:38:00 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:38:00 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1e9194ae864e40689231bebc8d56861a
2025-12-12 21:38:00 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:38:00 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:38:00 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:38:00 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:38:00 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:38:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e14b249bf85b45bb8d8de98bb2a2357d (experiment: x3d)
2025-12-12 21:38:00 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:38:04 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:38:05 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:38:08 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:38:15 [WARNING] [lib.training.trainer:369] Skipping batch 1 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:38:20 [WARNING] [lib.training.trainer:369] Skipping batch 2 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 140]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:38:23 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:38:24 [WARNING] [lib.training.trainer:369] Skipping batch 3 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:38:31 [WARNING] [lib.training.trainer:369] Skipping batch 4 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:38:36 [WARNING] [lib.training.trainer:369] Skipping batch 5 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:38:40 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:38:50 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 7: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 68.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 129.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:38:50 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 7): {'cpu_memory_mb': 6130.765625, 'cpu_memory_gb': 5.9870758056640625, 'cpu_vms_mb': 53237.46875, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.44167168, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.486670336}
2025-12-12 21:38:50 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 68.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 129.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 2, Current batch size: 1
2025-12-12 21:38:50 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:38:55 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:38:55 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:38:55 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e14b249bf85b45bb8d8de98bb2a2357d
2025-12-12 21:38:55 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:38:55 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:38:55 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:38:55 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:38:55 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:38:55 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: cac9d131354c45c6bc0274dbe15d204f (experiment: x3d)
2025-12-12 21:38:55 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:38:59 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:39:00 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:39:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:39:04 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:39:04 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:39:04 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: cac9d131354c45c6bc0274dbe15d204f
2025-12-12 21:39:05 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:39:05 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:39:05 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:39:05 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:39:05 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:39:05 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1ad74b2877594363a715b9dd4f0e6fae (experiment: x3d)
2025-12-12 21:39:05 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:39:09 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:39:10 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:39:13 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:39:14 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:39:14 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:39:14 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1ad74b2877594363a715b9dd4f0e6fae
2025-12-12 21:39:14 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:39:14 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:39:15 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:39:15 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:39:15 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:39:15 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 8632074ec5dc4933af4bdbe60c49e81c (experiment: x3d)
2025-12-12 21:39:15 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:39:19 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:39:19 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:39:31 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:39:32 [WARNING] [lib.training.trainer:369] Skipping batch 1 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:39:37 [WARNING] [lib.training.trainer:369] Skipping batch 2 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:39:44 [WARNING] [lib.training.trainer:369] Skipping batch 3 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:39:50 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:39:50 [WARNING] [lib.training.trainer:369] Skipping batch 4 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:39:55 [WARNING] [lib.training.trainer:369] Skipping batch 5 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:40:00 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 6: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:40:00 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 6): {'cpu_memory_mb': 6130.7734375, 'cpu_memory_gb': 5.987083435058594, 'cpu_vms_mb': 53237.46875, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.439574528, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.488767488}
2025-12-12 21:40:00 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 5, Current batch size: 1
2025-12-12 21:40:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:40:08 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:40:09 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:40:09 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:40:09 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 8632074ec5dc4933af4bdbe60c49e81c
2025-12-12 21:40:09 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:40:09 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 13/16
2025-12-12 21:40:09 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.0001}
2025-12-12 21:40:09 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:40:09 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:40:09 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:40:10 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:40:10 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:40:10 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:40:10 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 054e0ba1979d47868a279d08e124bf6a (experiment: x3d)
2025-12-12 21:40:10 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:40:14 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:40:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:40:23 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:40:24 [WARNING] [lib.training.trainer:369] Skipping batch 1 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 144]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:40:28 [WARNING] [lib.training.trainer:369] Skipping batch 2 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:40:33 [WARNING] [lib.training.trainer:369] Skipping batch 3 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:40:37 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:40:38 [WARNING] [lib.training.trainer:369] Skipping batch 4 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:40:48 [WARNING] [lib.training.trainer:369] Skipping batch 5 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 178, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:40:52 [WARNING] [lib.training.trainer:369] Skipping batch 6 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:40:57 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:40:58 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 7: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:40:58 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 7): {'cpu_memory_mb': 6130.77734375, 'cpu_memory_gb': 5.987087249755859, 'cpu_vms_mb': 53237.46875, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.439574528, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.488767488}
2025-12-12 21:40:58 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 70.19 MiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 127.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 1, Current batch size: 1
2025-12-12 21:40:58 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:41:04 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:41:04 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:41:04 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 054e0ba1979d47868a279d08e124bf6a
2025-12-12 21:41:04 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:41:04 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:41:04 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:41:04 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:41:05 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:41:05 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a3aec4d6856247d38a58635dbb032cc9 (experiment: x3d)
2025-12-12 21:41:05 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:41:09 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:41:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:41:12 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:41:13 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:41:13 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:41:13 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a3aec4d6856247d38a58635dbb032cc9
2025-12-12 21:41:13 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:41:13 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:41:14 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:41:14 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:41:14 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:41:14 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: e2b4500e12ca4f349c4e0846319648f8 (experiment: x3d)
2025-12-12 21:41:14 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:41:18 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:41:18 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:41:23 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:41:23 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:41:23 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: e2b4500e12ca4f349c4e0846319648f8
2025-12-12 21:41:24 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:41:24 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:41:24 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:41:24 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:41:24 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:41:24 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: d536f7811f584f828f572e6a26e1b494 (experiment: x3d)
2025-12-12 21:41:24 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:41:28 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:41:28 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:41:29 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:41:33 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:41:33 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:41:33 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: d536f7811f584f828f572e6a26e1b494
2025-12-12 21:41:34 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:41:34 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:41:34 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:41:34 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:41:34 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:41:34 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 184d749af17046bcbf46a469bcfa22dd (experiment: x3d)
2025-12-12 21:41:34 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:41:39 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:41:39 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:41:45 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:41:45 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:41:45 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:41:46 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 184d749af17046bcbf46a469bcfa22dd
2025-12-12 21:41:46 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:41:46 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 14/16
2025-12-12 21:41:46 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0001, 'weight_decay': 0.001}
2025-12-12 21:41:46 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:41:46 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:41:46 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:41:46 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:41:46 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:41:46 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:41:46 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: a7844f37898245c1994bfdc460285e1a (experiment: x3d)
2025-12-12 21:41:46 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:41:51 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:41:51 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:41:56 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:41:56 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_h = max(new_h, min_spatial_size)
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:41:56 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: a7844f37898245c1994bfdc460285e1a
2025-12-12 21:41:56 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:41:56 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:41:56 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:41:56 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:41:56 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:41:56 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: cae39cec0a244ed6873c44626aef458a (experiment: x3d)
2025-12-12 21:41:56 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:42:00 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:42:00 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:42:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:42:05 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:42:05 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:42:05 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: cae39cec0a244ed6873c44626aef458a
2025-12-12 21:42:06 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:42:06 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:42:06 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:42:06 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:42:06 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:42:06 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 9b1d4c9d23c14513ae47074ab77a8810 (experiment: x3d)
2025-12-12 21:42:06 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:42:11 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:42:11 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:42:14 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:42:15 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:42:15 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:42:15 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 9b1d4c9d23c14513ae47074ab77a8810
2025-12-12 21:42:15 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:42:15 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:42:15 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:42:15 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:42:16 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:42:16 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: af30b075f924485991c842ac88adf0cb (experiment: x3d)
2025-12-12 21:42:16 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:42:20 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:42:20 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:42:37 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:42:37 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:42:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: af30b075f924485991c842ac88adf0cb
2025-12-12 21:42:38 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:42:38 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:42:38 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:42:38 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:42:38 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:42:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 1ee490d753994cba94c02ce3178b1243 (experiment: x3d)
2025-12-12 21:42:38 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:42:42 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:42:42 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:42:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:42:48 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:42:48 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:42:48 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 1ee490d753994cba94c02ce3178b1243
2025-12-12 21:42:48 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:42:48 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 15/16
2025-12-12 21:42:48 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.0001}
2025-12-12 21:42:48 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:42:48 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:42:48 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:42:48 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:42:48 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:42:48 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:42:48 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 385c1ac5c5e04eba8a3216926dab6436 (experiment: x3d)
2025-12-12 21:42:48 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:42:53 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:42:53 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:42:56 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:42:57 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:42:57 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:42:57 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 385c1ac5c5e04eba8a3216926dab6436
2025-12-12 21:42:57 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:42:57 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:42:58 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:42:58 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:42:58 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:42:58 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 71a1827444b64a9c9c375c500543eaad (experiment: x3d)
2025-12-12 21:42:58 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:43:02 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:43:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:43:06 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:43:06 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:43:06 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 71a1827444b64a9c9c375c500543eaad
2025-12-12 21:43:06 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:43:06 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:43:07 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:43:07 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:43:07 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:43:07 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 738706f3133041b1bca1c1aae028e6dc (experiment: x3d)
2025-12-12 21:43:07 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:43:11 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:43:11 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:43:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:43:21 [WARNING] [lib.training.trainer:369] Skipping batch 1 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:43:25 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:43:32 [WARNING] [lib.training.trainer:369] Skipping batch 3 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:43:38 [WARNING] [lib.training.trainer:369] Skipping batch 4 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:43:42 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:43:43 [WARNING] [lib.training.trainer:369] Skipping batch 5 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:43:50 [WARNING] [lib.training.trainer:369] Skipping batch 6 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:43:55 [WARNING] [lib.training.trainer:369] Skipping batch 7 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:43:59 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:44:00 [WARNING] [lib.training.trainer:369] Skipping batch 8 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:04 [WARNING] [lib.training.trainer:369] Skipping batch 9 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:14 [WARNING] [lib.training.trainer:369] Skipping batch 10 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:18 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:44:18 [WARNING] [lib.training.trainer:369] Skipping batch 11 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:24 [WARNING] [lib.training.trainer:369] Skipping batch 12 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:35 [WARNING] [lib.training.trainer:369] Skipping batch 13 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 142]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:39 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:44:39 [WARNING] [lib.training.trainer:369] Skipping batch 14 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:45 [WARNING] [lib.training.trainer:369] Skipping batch 15 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:49 [WARNING] [lib.training.trainer:369] Skipping batch 16 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:53 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:44:54 [WARNING] [lib.training.trainer:369] Skipping batch 17 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 144]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:44:58 [WARNING] [lib.training.trainer:369] Skipping batch 18 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:03 [WARNING] [lib.training.trainer:369] Skipping batch 19 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:08 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:45:09 [WARNING] [lib.training.trainer:369] Skipping batch 20 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:14 [WARNING] [lib.training.trainer:369] Skipping batch 21 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:18 [WARNING] [lib.training.trainer:369] Skipping batch 22 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:22 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:45:28 [WARNING] [lib.training.trainer:369] Skipping batch 24 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:32 [WARNING] [lib.training.trainer:369] Skipping batch 25 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:36 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:45:37 [WARNING] [lib.training.trainer:369] Skipping batch 26 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:42 [WARNING] [lib.training.trainer:369] Skipping batch 27 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:47 [WARNING] [lib.training.trainer:369] Skipping batch 28 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:45:51 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:45:51 [WARNING] [lib.training.trainer:369] Skipping batch 29 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:01 [WARNING] [lib.training.trainer:369] Skipping batch 31 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:05 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:46:05 [WARNING] [lib.training.trainer:369] Skipping batch 32 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:10 [WARNING] [lib.training.trainer:369] Skipping batch 33 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:15 [WARNING] [lib.training.trainer:369] Skipping batch 34 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:18 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:46:19 [WARNING] [lib.training.trainer:369] Skipping batch 35 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 186, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:25 [WARNING] [lib.training.trainer:369] Skipping batch 36 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:34 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:46:34 [WARNING] [lib.training.trainer:369] Skipping batch 38 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:42 [WARNING] [lib.training.trainer:369] Skipping batch 39 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:46:57 [WARNING] [lib.training.trainer:369] Skipping batch 40 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:00 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:47:01 [WARNING] [lib.training.trainer:369] Skipping batch 41 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:11 [WARNING] [lib.training.trainer:369] Skipping batch 42 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:27 [WARNING] [lib.training.trainer:369] Skipping batch 43 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:31 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:47:31 [WARNING] [lib.training.trainer:369] Skipping batch 44 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:37 [WARNING] [lib.training.trainer:369] Skipping batch 45 due to input dimension mismatch: input image (T: 500 H: 4 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 128, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:41 [WARNING] [lib.training.trainer:369] Skipping batch 46 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:46 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:47:47 [WARNING] [lib.training.trainer:369] Skipping batch 47 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:51 [WARNING] [lib.training.trainer:369] Skipping batch 48 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 144]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:56 [WARNING] [lib.training.trainer:369] Skipping batch 49 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:47:59 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:48:00 [WARNING] [lib.training.trainer:369] Skipping batch 50 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 136, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:05 [WARNING] [lib.training.trainer:369] Skipping batch 51 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:10 [WARNING] [lib.training.trainer:369] Skipping batch 52 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:13 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:48:14 [WARNING] [lib.training.trainer:369] Skipping batch 53 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:19 [WARNING] [lib.training.trainer:369] Skipping batch 54 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:23 [WARNING] [lib.training.trainer:369] Skipping batch 55 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:27 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:48:28 [WARNING] [lib.training.trainer:369] Skipping batch 56 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:33 [WARNING] [lib.training.trainer:369] Skipping batch 57 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:37 [WARNING] [lib.training.trainer:369] Skipping batch 58 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:41 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:48:42 [WARNING] [lib.training.trainer:369] Skipping batch 59 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:47 [WARNING] [lib.training.trainer:369] Skipping batch 60 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:52 [WARNING] [lib.training.trainer:369] Skipping batch 61 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:48:56 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:48:57 [WARNING] [lib.training.trainer:369] Skipping batch 62 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:49:03 [WARNING] [lib.training.trainer:369] Skipping batch 63 due to input dimension mismatch: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 192, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:49:07 [WARNING] [lib.training.trainer:369] Skipping batch 64 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:49:10 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:49:11 [WARNING] [lib.training.trainer:369] Skipping batch 65 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:49:16 [WARNING] [lib.training.trainer:369] Skipping batch 66 due to input dimension mismatch: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 144, 256]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:49:22 [WARNING] [lib.training.trainer:369] Skipping batch 67 due to input dimension mismatch: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 256, 144]). This may indicate videos with very small spatial dimensions.
2025-12-12 21:49:26 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:49:32 [ERROR] [lib.utils.memory:130] OOM error forward pass batch 69: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 48.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 149.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 21:49:32 [INFO] [lib.utils.memory:91] Memory stats (after OOM forward pass batch 69): {'cpu_memory_mb': 6143.8046875, 'cpu_memory_gb': 5.999809265136719, 'cpu_vms_mb': 53250.21484375, 'gpu_allocated_gb': 16.305878528, 'gpu_reserved_gb': 16.4626432, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 0.465698816}
2025-12-12 21:49:32 [WARNING] [lib.training.pipeline:1367] CUDA OOM during training (attempt 1/4): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 48.19 MiB is free. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 149.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: x3d, Fold: 3, Current batch size: 1
2025-12-12 21:49:32 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:49:37 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:49:37 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:49:37 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 738706f3133041b1bca1c1aae028e6dc
2025-12-12 21:49:37 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:49:37 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:49:37 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:49:37 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:49:38 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:49:38 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2eab235211434bce88d1188828f80b03 (experiment: x3d)
2025-12-12 21:49:38 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:49:42 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:49:43 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:49:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:49:50 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:49:50 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:49:50 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2eab235211434bce88d1188828f80b03
2025-12-12 21:49:50 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:49:50 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:49:50 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:49:50 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:49:50 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:49:51 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 0ba6a9b276c741808cb89aa407343bd7 (experiment: x3d)
2025-12-12 21:49:51 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:49:55 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:49:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:49:58 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:49:59 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:49:59 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:49:59 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 0ba6a9b276c741808cb89aa407343bd7
2025-12-12 21:49:59 [INFO] [lib.training.pipeline:868] 
================================================================================
2025-12-12 21:49:59 [INFO] [lib.training.pipeline:869] Grid Search: Hyperparameter combination 16/16
2025-12-12 21:49:59 [INFO] [lib.training.pipeline:870] Parameters: {'learning_rate': 0.0001, 'backbone_lr': 5e-06, 'head_lr': 0.0005, 'weight_decay': 0.001}
2025-12-12 21:49:59 [INFO] [lib.training.pipeline:871] ================================================================================
2025-12-12 21:49:59 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 1/5 (20% sample)
2025-12-12 21:49:59 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:49:59 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:49:59 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:50:00 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:50:00 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 20f730af4ba14d879da48b08ce96a2eb (experiment: x3d)
2025-12-12 21:50:00 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 1...
2025-12-12 21:50:04 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:50:04 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:50:08 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 1
2025-12-12 21:50:08 [ERROR] [lib.training.pipeline:1764] Error training fold 1: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:50:08 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 20f730af4ba14d879da48b08ce96a2eb
2025-12-12 21:50:09 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 2/5 (20% sample)
2025-12-12 21:50:09 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:50:09 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:50:09 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:50:09 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:50:09 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 4d8d61eb596041b78785d510a388e2bd (experiment: x3d)
2025-12-12 21:50:09 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 2...
2025-12-12 21:50:13 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:50:13 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:50:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:50:18 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 2
2025-12-12 21:50:18 [ERROR] [lib.training.pipeline:1764] Error training fold 2: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:50:18 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 4d8d61eb596041b78785d510a388e2bd
2025-12-12 21:50:18 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 3/5 (20% sample)
2025-12-12 21:50:18 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:50:18 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:50:18 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:50:19 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:50:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2bef5679e5f64bfe9d5946f74d00ddcb (experiment: x3d)
2025-12-12 21:50:19 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 3...
2025-12-12 21:50:23 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:50:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:50:27 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:50:28 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 3
2025-12-12 21:50:28 [ERROR] [lib.training.pipeline:1764] Error training fold 3: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:50:28 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 2bef5679e5f64bfe9d5946f74d00ddcb
2025-12-12 21:50:28 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 4/5 (20% sample)
2025-12-12 21:50:28 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:50:28 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:50:28 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:50:29 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:50:29 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 90317928f5064803926bfa2c011a3a51 (experiment: x3d)
2025-12-12 21:50:29 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 4...
2025-12-12 21:50:33 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:50:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:50:38 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 4
2025-12-12 21:50:38 [ERROR] [lib.training.pipeline:1764] Error training fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:50:38 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 90317928f5064803926bfa2c011a3a51
2025-12-12 21:50:38 [INFO] [lib.training.pipeline:900] 
Hyperparameter Search - x3d - Fold 5/5 (20% sample)
2025-12-12 21:50:38 [INFO] [lib.training.pipeline:1004] Training configuration - Batch size: 1, Gradient accumulation steps: 32, Effective batch size: 32
2025-12-12 21:50:39 [INFO] [lib.training.pipeline:1050] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:50:39 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:50:39 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:50:39 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 799379b6601b496fb88b2e583bbef3d4 (experiment: x3d)
2025-12-12 21:50:39 [INFO] [lib.training.pipeline:1143] Training PyTorch model x3d on fold 5...
2025-12-12 21:50:43 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:50:44 [WARNING] [lib.training.pipeline:1232] Input dimension mismatch during forward pass test for x3d: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Input shape: torch.Size([1, 3, 500, 142, 256]). This may indicate some videos have very small spatial dimensions. Training will handle this via error handling. Continuing...
2025-12-12 21:50:44 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:50:48 [ERROR] [lib.training.pipeline:1391] Runtime error during training: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7). Model: x3d, Fold: 5
2025-12-12 21:50:48 [ERROR] [lib.training.pipeline:1764] Error training fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1331, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:50:48 [INFO] [lib.mlops.mlflow_tracker:142] MLflow run ended: 799379b6601b496fb88b2e583bbef3d4
2025-12-12 21:50:49 [INFO] [lib.training.pipeline:1823] ================================================================================
2025-12-12 21:50:49 [INFO] [lib.training.pipeline:1824] FINAL TRAINING: Using full dataset with best hyperparameters
2025-12-12 21:50:49 [INFO] [lib.training.pipeline:1825] ================================================================================
2025-12-12 21:50:49 [INFO] [lib.training.pipeline:1838] Final training: Using 5-fold stratified cross-validation on full dataset (3278 rows)
2025-12-12 21:50:49 [INFO] [lib.training.pipeline:1848] Final training using default hyperparameters (no grid search)
2025-12-12 21:50:49 [INFO] [lib.training.pipeline:1852] 
Final Training - x3d - Fold 1/5 (full dataset)
2025-12-12 21:50:49 [INFO] [lib.training.pipeline:1961] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:50:49 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:50:49 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:50:49 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 85bd49027c5e4f91800b8fa750c90502 (experiment: x3d)
2025-12-12 21:50:49 [INFO] [lib.training.pipeline:2026] Training PyTorch model x3d on fold 1 (full dataset)...
2025-12-12 21:50:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:50:54 [ERROR] [lib.training.pipeline:2226] Error training final fold 1: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2032, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 6 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:50:54 [INFO] [lib.training.pipeline:1852] 
Final Training - x3d - Fold 2/5 (full dataset)
2025-12-12 21:50:54 [INFO] [lib.training.pipeline:1961] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:50:54 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:50:54 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:50:54 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: ee17714c22314e8aa328fbd3ea41ed07 (experiment: x3d)
2025-12-12 21:50:54 [INFO] [lib.training.pipeline:2026] Training PyTorch model x3d on fold 2 (full dataset)...
2025-12-12 21:50:54 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:51:12 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:51:13 [ERROR] [lib.training.pipeline:2226] Error training final fold 2: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2032, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:51:13 [INFO] [lib.training.pipeline:1852] 
Final Training - x3d - Fold 3/5 (full dataset)
2025-12-12 21:51:13 [INFO] [lib.training.pipeline:1961] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:51:13 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:51:13 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:51:13 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 94e38802fa7f4956aaa96bc6d592abf6 (experiment: x3d)
2025-12-12 21:51:13 [INFO] [lib.training.pipeline:2026] Training PyTorch model x3d on fold 3 (full dataset)...
2025-12-12 21:51:13 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:51:18 [ERROR] [lib.training.pipeline:2226] Error training final fold 3: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2032, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 8 W: 5) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:51:18 [INFO] [lib.training.pipeline:1852] 
Final Training - x3d - Fold 4/5 (full dataset)
2025-12-12 21:51:18 [INFO] [lib.training.pipeline:1961] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:51:18 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:51:19 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:51:19 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: b8a7ac4f37e8407a99ecd77a011b7e60 (experiment: x3d)
2025-12-12 21:51:19 [INFO] [lib.training.pipeline:2026] Training PyTorch model x3d on fold 4 (full dataset)...
2025-12-12 21:51:19 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:51:23 [ERROR] [lib.training.pipeline:2226] Error training final fold 4: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2032, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:51:23 [INFO] [lib.training.pipeline:1852] 
Final Training - x3d - Fold 5/5 (full dataset)
2025-12-12 21:51:23 [INFO] [lib.training.pipeline:1961] Applied PyTorch memory optimizations: expandable_segments, cudnn.benchmark=False
2025-12-12 21:51:23 [INFO] [lib.training.x3d:47] Loading X3D model from PyTorchVideo: x3d_m (pretrained=True)
2025-12-12 21:51:23 [INFO] [lib.training.x3d:106] ✓ Successfully loaded X3D model from PyTorchVideo: x3d_m
2025-12-12 21:51:23 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 2ed24fe165114a1597fbb02630faf68e (experiment: x3d)
2025-12-12 21:51:23 [INFO] [lib.training.pipeline:2026] Training PyTorch model x3d on fold 5 (full dataset)...
2025-12-12 21:51:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 21:51:28 [INFO] [lib.models.video:455] Chunk size increased from 30 to 40 (after 3 successes, increment: 10)
2025-12-12 21:51:28 [ERROR] [lib.training.pipeline:2226] Error training final fold 5: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 2032, in stage5_train_models
    model = fit(model, train_loader, val_loader, optim_cfg, train_cfg, use_differential_lr=use_differential_lr)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 684, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 331, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/x3d.py", line 210, in forward
    new_w = min_spatial_size
    ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/net.py", line 43, in forward
    x = block(x)
        ^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/head.py", line 374, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/urvim/.cache/torch/hub/facebookresearch_pytorchvideo_main/pytorchvideo/models/x3d.py", line 799, in forward
    x = self.pool(x)
        ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/pooling.py", line 898, in forward
    return F.avg_pool3d(
           ^^^^^^^^^^^^^
RuntimeError: input image (T: 500 H: 5 W: 8) smaller than kernel size (kT: 16 kH: 7 kW: 7)
2025-12-12 21:51:28 [WARNING] [lib.training.pipeline:118] No model files found in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/fold_1 to copy
2025-12-12 21:51:28 [INFO] [lib.training.pipeline:2299] 
x3d - Avg Val Loss: nan, Avg Val Acc: nan, Avg Val F1: nan
2025-12-12 21:51:30 [INFO] [lib.training.visualization:256] Saved CV fold comparison to /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/plots/cv_fold_comparison.png
2025-12-12 21:51:30 [INFO] [lib.training.pipeline:2327] Generated plots for x3d in /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5/x3d/plots
2025-12-12 21:51:30 [INFO] [lib.training.pipeline:2364] ================================================================================
2025-12-12 21:51:30 [INFO] [lib.training.pipeline:2365] Stage 5: Model Training Pipeline Completed
2025-12-12 21:51:30 [INFO] [lib.training.pipeline:2366] ================================================================================
2025-12-12 21:51:30 [INFO] [__main__:401] ================================================================================
2025-12-12 21:51:30 [INFO] [__main__:402] STAGE 5 COMPLETED SUCCESSFULLY
2025-12-12 21:51:30 [INFO] [__main__:403] ================================================================================
2025-12-12 21:51:30 [INFO] [__main__:404] Execution time: 2040.36 seconds (34.01 minutes)
2025-12-12 21:51:30 [INFO] [__main__:406] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 21:51:30 [INFO] [__main__:407] Models trained: ['x3d']
2025-12-12 21:51:30 [INFO] [__main__:408] K-fold splits: 5
2025-12-12 21:51:30 [INFO] [__main__:414] ================================================================================
2025-12-12 21:51:30 [INFO] [__main__:415] Final memory statistics:
2025-12-12 21:51:30 [INFO] [__main__:416] ================================================================================
2025-12-12 21:51:30 [INFO] [lib.utils.memory:91] Memory stats (Stage 5: after training): {'cpu_memory_mb': 6142.6796875, 'cpu_memory_gb': 5.998710632324219, 'cpu_vms_mb': 53280.76953125, 'gpu_allocated_gb': 0.01703936, 'gpu_reserved_gb': 0.396361728, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.531980288}
2025-12-12 21:51:30 [INFO] [__main__:419] ================================================================================
2025-12-12 21:51:30 [INFO] [__main__:420] Training complete!
2025-12-12 21:51:30 [INFO] [__main__:421] Results saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 21:51:30 [INFO] [__main__:422] ================================================================================
