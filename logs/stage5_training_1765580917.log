2025-12-12 18:08:37 [INFO] [__main__:310] ================================================================================
2025-12-12 18:08:37 [INFO] [__main__:311] STAGE 5: MODEL TRAINING
2025-12-12 18:08:37 [INFO] [__main__:312] ================================================================================
2025-12-12 18:08:37 [INFO] [__main__:313] Project root: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc
2025-12-12 18:08:37 [INFO] [__main__:314] Scaled metadata: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 18:08:37 [INFO] [__main__:315] Features Stage 2: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 18:08:37 [INFO] [__main__:316] Features Stage 4: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 18:08:37 [INFO] [__main__:317] Model types: ['naive_cnn']
2025-12-12 18:08:37 [INFO] [__main__:318] K-fold splits: 5
2025-12-12 18:08:37 [INFO] [__main__:319] Number of frames: 1000
2025-12-12 18:08:37 [INFO] [__main__:320] Output directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/stage5
2025-12-12 18:08:37 [INFO] [__main__:321] Experiment tracking: Enabled
2025-12-12 18:08:37 [INFO] [__main__:324] Delete existing: True
2025-12-12 18:08:37 [INFO] [__main__:325] Resume mode: True
2025-12-12 18:08:37 [INFO] [__main__:326] Log file: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/logs/stage5_training_1765580917.log
2025-12-12 18:08:37 [INFO] [__main__:333] ================================================================================
2025-12-12 18:08:37 [INFO] [__main__:334] Checking prerequisites...
2025-12-12 18:08:37 [INFO] [__main__:335] ================================================================================
2025-12-12 18:08:37 [INFO] [__main__:342] ✓ Scaled metadata file found: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 18:08:37 [INFO] [__main__:352] ✓ All model types are valid
2025-12-12 18:08:37 [INFO] [__main__:358] ================================================================================
2025-12-12 18:08:37 [INFO] [__main__:359] Initial memory statistics:
2025-12-12 18:08:37 [INFO] [__main__:360] ================================================================================
2025-12-12 18:08:37 [INFO] [lib.utils.memory:89] Memory stats (Stage 5: before training): {'cpu_memory_mb': 735.47265625, 'cpu_memory_gb': 0.7182350158691406, 'cpu_vms_mb': 10217.54296875, 'gpu_allocated_gb': 0.0, 'gpu_reserved_gb': 0.0, 'gpu_total_gb': 16.928342016, 'gpu_free_gb': 16.928342016}
2025-12-12 18:08:37 [INFO] [__main__:364] ================================================================================
2025-12-12 18:08:37 [INFO] [__main__:365] Starting Stage 5: Model Training
2025-12-12 18:08:37 [INFO] [__main__:366] ================================================================================
2025-12-12 18:08:37 [INFO] [__main__:367] Training 1 model(s) with 5-fold cross-validation
2025-12-12 18:08:37 [INFO] [__main__:368] This may take a while depending on dataset size and model complexity...
2025-12-12 18:08:37 [INFO] [__main__:369] Progress will be logged in real-time
2025-12-12 18:08:37 [INFO] [__main__:370] ================================================================================
2025-12-12 18:08:37 [INFO] [__main__:375] Calling Stage 5 training pipeline...
2025-12-12 18:08:37 [INFO] [__main__:376] This may take a while - progress will be logged in real-time
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:490] ================================================================================
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:491] Stage 5: Model Training Pipeline Started
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:492] ================================================================================
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:493] Model types: ['naive_cnn']
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:494] K-fold splits: 5
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:495] Frames per video: 1000
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:496] Output directory: data/stage5
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:497] Initializing pipeline...
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:265] ================================================================================
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:266] STAGE 5 PREREQUISITE VALIDATION
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:267] ================================================================================
2025-12-12 18:08:37 [INFO] [lib.training.pipeline:270] 
[1/3] Checking Stage 3 (scaled videos) - REQUIRED for all models...
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:279] ✓ Stage 3 metadata found: 3278 scaled videos
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:280]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/scaled_videos/scaled_metadata.arrow
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:283] 
[2/3] Checking Stage 2 (features) - REQUIRED for *_stage2 models...
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:291] ✓ Stage 2 metadata found: 3278 feature rows
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:292]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage2/features_metadata.arrow
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:295] 
[3/3] Checking Stage 4 (scaled features) - REQUIRED for *_stage2_stage4 models...
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:303] ✓ Stage 4 metadata found: 3277 feature rows
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:304]   Path: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/data/features_stage4/features_scaled_metadata.arrow
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:307] 
================================================================================
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:308] MODEL REQUIREMENTS CHECK
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:309] ================================================================================
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:333] ✓ naive_cnn: CAN RUN
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:336] 
================================================================================
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:337] VALIDATION SUMMARY
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:338] ================================================================================
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:339] Stage 3 (scaled videos): ✓ Available
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:340]   Count: 3278 videos
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:341] Stage 2 (features): ✓ Available
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:342]   Count: 3278 feature rows
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:343] Stage 4 (scaled features): ✓ Available
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:344]   Count: 3277 feature rows
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:345] 
Runnable models: 1/1
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:346]   ['naive_cnn']
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:353] ================================================================================
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:583] 
Stage 5: Loading metadata...
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:609] Loaded metadata: 3278 rows
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:619] ✓ Data validation passed: 3278 rows (> 3000 required)
2025-12-12 18:08:39 [WARNING] [lib.utils.guardrails:171] Disk usage high: free=834124.71GB, used=1665715.29GB (66.6%)
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:651] Stage 5: Found 3278 scaled videos
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:730] Stage 5: Deleting existing model results (clean mode)...
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:742] Stage 5: Deleted 0 existing model directories
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:747] 
================================================================================
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:748] Stage 5: Training model: naive_cnn
2025-12-12 18:08:39 [INFO] [lib.training.pipeline:749] ================================================================================
2025-12-12 18:08:41 [INFO] [lib.training.pipeline:773] Grid search: 36 hyperparameter combinations to try
2025-12-12 18:08:41 [INFO] [lib.training.pipeline:781] ================================================================================
2025-12-12 18:08:41 [INFO] [lib.training.pipeline:782] HYPERPARAMETER SEARCH: Using 20% stratified sample for efficiency
2025-12-12 18:08:41 [INFO] [lib.training.pipeline:783] ================================================================================
2025-12-12 18:08:41 [INFO] [lib.training.pipeline:792] Hyperparameter search sample: 655 rows (20.0% of 3278 total)
2025-12-12 18:08:44 [INFO] [lib.training.pipeline:805] Using 5-fold stratified cross-validation on 20% sample for hyperparameter search
2025-12-12 18:08:44 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:08:44 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 1/36
2025-12-12 18:08:44 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 1e-05, 'batch_size': 4, 'num_epochs': 20}
2025-12-12 18:08:44 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:08:44 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:08:44 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:08:50 [INFO] [lib.mlops.mlflow_tracker:89] MLflow run started: 57e1acdd53e948fb8170b6b089b1c17b (experiment: naive_cnn)
2025-12-12 18:08:50 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:08:59 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:09:00 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:09:14 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:09:14 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 4
2025-12-12 18:09:14 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:09:15 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:09:15 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:09:15 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:09:15 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:09:16 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:09:17 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:09:30 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:09:30 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 4
2025-12-12 18:09:30 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:09:31 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:09:31 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:09:31 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:09:31 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:09:33 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:09:33 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:09:47 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:09:47 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 4
2025-12-12 18:09:47 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:09:47 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:09:47 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:09:47 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:09:47 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:09:49 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:09:49 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:10:04 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:10:04 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 4
2025-12-12 18:10:04 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:10:04 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:10:04 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:10:04 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:10:04 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:10:06 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:10:06 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:10:20 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:10:20 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 4
2025-12-12 18:10:20 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:10:20 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:10:20 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 2/36
2025-12-12 18:10:20 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 1e-05, 'batch_size': 4, 'num_epochs': 30}
2025-12-12 18:10:20 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:10:20 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:10:20 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:10:20 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:10:20 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:10:20 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:10:23 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:10:23 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:10:35 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:10:35 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 4
2025-12-12 18:10:35 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:10:36 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:10:36 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:10:36 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:10:36 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:10:36 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:10:37 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:10:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:10:50 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:10:50 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 4
2025-12-12 18:10:50 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:10:50 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:10:50 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:10:50 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:10:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:10:50 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:10:52 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:10:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:11:05 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:11:05 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 4
2025-12-12 18:11:05 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.41 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:11:05 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:11:05 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:11:05 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:11:05 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:11:05 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:11:07 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:11:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:11:19 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:11:19 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 4
2025-12-12 18:11:19 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:11:19 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:11:19 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:11:19 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:11:19 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:11:19 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:11:21 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:11:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:11:37 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:11:37 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 4
2025-12-12 18:11:37 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.16 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:11:37 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:11:37 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 3/36
2025-12-12 18:11:37 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 1e-05, 'batch_size': 8, 'num_epochs': 20}
2025-12-12 18:11:37 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:11:37 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:11:37 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:11:37 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:11:37 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:11:37 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:11:39 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:11:40 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:12:07 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:12:07 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 8
2025-12-12 18:12:07 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:12:07 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:12:07 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:12:07 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:12:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:12:07 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:12:09 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:12:09 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:12:34 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:12:34 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 8
2025-12-12 18:12:34 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:12:35 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:12:35 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:12:35 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:12:35 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:12:35 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:12:37 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:12:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:13:00 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:13:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 8
2025-12-12 18:13:00 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:13:01 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:13:01 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:13:01 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:13:01 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:13:01 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:13:03 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:13:03 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:13:27 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:13:27 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 8
2025-12-12 18:13:27 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:13:28 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:13:28 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:13:28 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:13:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:13:28 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:13:30 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:13:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:13:58 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:13:58 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 8
2025-12-12 18:13:58 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:13:58 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:13:58 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 4/36
2025-12-12 18:13:58 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 1e-05, 'batch_size': 8, 'num_epochs': 30}
2025-12-12 18:13:58 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:13:58 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:13:58 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:13:58 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:13:58 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:13:58 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:14:00 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:14:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:14:25 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:14:25 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 8
2025-12-12 18:14:25 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:14:26 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:14:26 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:14:26 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:14:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:14:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:14:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:14:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:14:58 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:14:58 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 8
2025-12-12 18:14:58 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:14:59 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:14:59 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:14:59 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:14:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:14:59 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:15:01 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:15:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:15:24 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:15:24 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 8
2025-12-12 18:15:24 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:15:24 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:15:24 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:15:24 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:15:24 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:15:24 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:15:26 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:15:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:16:06 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 49.80 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.66 GiB is free. Including non-PyTorch memory, this process has 5.08 GiB memory in use. Of the allocated memory 4.68 GiB is allocated by PyTorch, and 33.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 204, 256]), Model num_frames: 1000
2025-12-12 18:16:06 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 49.80 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.66 GiB is free. Including non-PyTorch memory, this process has 5.08 GiB memory in use. Of the allocated memory 4.68 GiB is allocated by PyTorch, and 33.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 8
2025-12-12 18:16:06 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 49.80 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.66 GiB is free. Including non-PyTorch memory, this process has 5.08 GiB memory in use. Of the allocated memory 4.68 GiB is allocated by PyTorch, and 33.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 49.80 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.66 GiB is free. Including non-PyTorch memory, this process has 5.08 GiB memory in use. Of the allocated memory 4.68 GiB is allocated by PyTorch, and 33.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:16:06 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:16:06 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:16:06 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:16:06 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:16:06 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:16:08 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:16:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:16:33 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:16:33 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 8
2025-12-12 18:16:33 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:16:33 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:16:33 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 5/36
2025-12-12 18:16:33 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4, 'num_epochs': 20}
2025-12-12 18:16:33 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:16:33 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:16:33 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:16:33 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:16:33 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:16:33 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:16:35 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:16:35 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:16:45 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 144, 256]), Model num_frames: 1000
2025-12-12 18:16:45 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 4
2025-12-12 18:16:45 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:16:45 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:16:45 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:16:45 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:16:45 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:16:45 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:16:46 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:16:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:16:57 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:16:57 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 4
2025-12-12 18:16:57 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:16:57 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:16:57 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:16:57 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:16:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:16:57 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:16:59 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:16:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:17:09 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:17:09 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 4
2025-12-12 18:17:09 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:17:10 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:17:10 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:17:10 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:17:10 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:17:10 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:17:11 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:17:12 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:17:34 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:17:34 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 4
2025-12-12 18:17:34 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:17:35 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:17:35 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:17:35 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:17:35 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:17:35 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:17:36 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:17:37 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:17:49 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 25.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.94 GiB is free. Including non-PyTorch memory, this process has 2.79 GiB memory in use. Of the allocated memory 2.39 GiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 208, 256]), Model num_frames: 1000
2025-12-12 18:17:49 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 25.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.94 GiB is free. Including non-PyTorch memory, this process has 2.79 GiB memory in use. Of the allocated memory 2.39 GiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 4
2025-12-12 18:17:49 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 25.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.94 GiB is free. Including non-PyTorch memory, this process has 2.79 GiB memory in use. Of the allocated memory 2.39 GiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 25.39 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.94 GiB is free. Including non-PyTorch memory, this process has 2.79 GiB memory in use. Of the allocated memory 2.39 GiB is allocated by PyTorch, and 36.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:17:50 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:17:50 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 6/36
2025-12-12 18:17:50 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'batch_size': 4, 'num_epochs': 30}
2025-12-12 18:17:50 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:17:50 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:17:50 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:17:50 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:17:50 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:17:50 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:17:51 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:17:52 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:18:07 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:18:07 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 4
2025-12-12 18:18:07 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:18:07 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:18:07 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:18:07 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:18:07 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:18:07 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:18:08 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:18:08 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:18:19 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:18:19 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 4
2025-12-12 18:18:19 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:18:19 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:18:19 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:18:19 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:18:19 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:18:19 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:18:21 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:18:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:18:32 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:18:32 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 4
2025-12-12 18:18:32 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:18:32 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:18:32 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:18:32 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:18:32 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:18:32 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:18:34 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:18:34 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:18:43 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 144, 256]), Model num_frames: 1000
2025-12-12 18:18:43 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 4
2025-12-12 18:18:43 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:18:43 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:18:43 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:18:43 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:18:43 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:18:43 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:18:45 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:18:45 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:19:00 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 19.53 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.51 GiB is free. Including non-PyTorch memory, this process has 2.23 GiB memory in use. Of the allocated memory 1.84 GiB is allocated by PyTorch, and 19.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 160, 256]), Model num_frames: 1000
2025-12-12 18:19:00 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 19.53 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.51 GiB is free. Including non-PyTorch memory, this process has 2.23 GiB memory in use. Of the allocated memory 1.84 GiB is allocated by PyTorch, and 19.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 4
2025-12-12 18:19:00 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 19.53 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.51 GiB is free. Including non-PyTorch memory, this process has 2.23 GiB memory in use. Of the allocated memory 1.84 GiB is allocated by PyTorch, and 19.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 19.53 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.51 GiB is free. Including non-PyTorch memory, this process has 2.23 GiB memory in use. Of the allocated memory 1.84 GiB is allocated by PyTorch, and 19.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:19:00 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:19:00 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 7/36
2025-12-12 18:19:00 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'batch_size': 8, 'num_epochs': 20}
2025-12-12 18:19:00 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:19:00 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:19:00 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:19:00 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:19:00 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:19:00 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:19:02 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:19:02 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:19:28 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:19:28 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 8
2025-12-12 18:19:28 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 46.88 GiB. GPU 0 has a total capacity of 15.77 GiB of which 10.93 GiB is free. Including non-PyTorch memory, this process has 4.80 GiB memory in use. Of the allocated memory 4.40 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:19:28 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:19:28 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:19:28 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:19:28 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:19:28 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:19:30 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:19:30 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:19:53 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:19:53 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 8
2025-12-12 18:19:53 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:19:54 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:19:54 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:19:54 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:19:54 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:19:54 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:19:56 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:19:56 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:20:23 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:20:23 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 8
2025-12-12 18:20:23 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:20:24 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:20:24 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:20:24 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:20:24 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:20:24 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:20:26 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:20:26 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:20:53 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:20:53 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 8
2025-12-12 18:20:53 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:20:54 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:20:54 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:20:54 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:20:54 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:20:54 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:20:55 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:20:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:21:25 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:21:25 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 8
2025-12-12 18:21:25 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:21:25 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:21:25 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 8/36
2025-12-12 18:21:25 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 0.0001, 'batch_size': 8, 'num_epochs': 30}
2025-12-12 18:21:25 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:21:25 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:21:25 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:21:25 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:21:25 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:21:25 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:21:27 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:21:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:21:53 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:21:53 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 8
2025-12-12 18:21:53 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:21:54 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:21:54 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:21:54 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:21:54 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:21:54 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:21:55 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:21:55 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:22:19 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:22:19 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 8
2025-12-12 18:22:19 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:22:19 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:22:19 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:22:19 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:22:19 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:22:19 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:22:21 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:22:21 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:22:44 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 45.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.07 GiB is free. Including non-PyTorch memory, this process has 4.67 GiB memory in use. Of the allocated memory 4.27 GiB is allocated by PyTorch, and 35.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 186, 256]), Model num_frames: 1000
2025-12-12 18:22:44 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 45.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.07 GiB is free. Including non-PyTorch memory, this process has 4.67 GiB memory in use. Of the allocated memory 4.27 GiB is allocated by PyTorch, and 35.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 8
2025-12-12 18:22:44 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 45.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.07 GiB is free. Including non-PyTorch memory, this process has 4.67 GiB memory in use. Of the allocated memory 4.27 GiB is allocated by PyTorch, and 35.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 45.41 GiB. GPU 0 has a total capacity of 15.77 GiB of which 11.07 GiB is free. Including non-PyTorch memory, this process has 4.67 GiB memory in use. Of the allocated memory 4.27 GiB is allocated by PyTorch, and 35.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:22:44 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:22:44 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:22:44 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:22:44 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:22:44 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:22:46 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:22:46 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:23:11 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:23:11 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 8
2025-12-12 18:23:11 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:23:12 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:23:12 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:23:12 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 8, Gradient accumulation steps: 16, Effective batch size: 128
2025-12-12 18:23:12 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:23:12 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:23:14 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:23:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:23:39 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([8, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:23:39 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 8
2025-12-12 18:23:39 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 62.50 GiB. GPU 0 has a total capacity of 15.77 GiB of which 9.47 GiB is free. Including non-PyTorch memory, this process has 6.27 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:23:40 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:23:40 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 9/36
2025-12-12 18:23:40 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'batch_size': 4, 'num_epochs': 20}
2025-12-12 18:23:40 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:23:40 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:23:40 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:23:40 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:23:40 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:23:40 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:23:42 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:23:42 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:23:57 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:23:57 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 4
2025-12-12 18:23:57 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:23:57 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:23:57 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:23:57 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:23:57 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:23:57 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:23:58 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:23:59 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:24:12 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:24:12 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 4
2025-12-12 18:24:12 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:24:12 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:24:12 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:24:12 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:24:12 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:24:12 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:24:14 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:24:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:24:26 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:24:26 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 4
2025-12-12 18:24:26 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:24:26 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:24:26 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:24:26 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:24:26 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:24:26 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:24:28 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:24:28 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:24:41 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:24:41 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 4
2025-12-12 18:24:41 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:24:41 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:24:41 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:24:41 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:24:41 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:24:41 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:24:43 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:24:43 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:24:55 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:24:55 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 5, Batch size: 4
2025-12-12 18:24:55 [ERROR] [lib.training.pipeline:1516] Error training fold 5: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:24:55 [INFO] [lib.training.pipeline:818] 
================================================================================
2025-12-12 18:24:55 [INFO] [lib.training.pipeline:819] Grid Search: Hyperparameter combination 10/36
2025-12-12 18:24:55 [INFO] [lib.training.pipeline:820] Parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'batch_size': 4, 'num_epochs': 30}
2025-12-12 18:24:55 [INFO] [lib.training.pipeline:821] ================================================================================
2025-12-12 18:24:55 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 1/5 (20% sample)
2025-12-12 18:24:55 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 1 directory (clean mode)
2025-12-12 18:24:55 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:24:55 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:24:55 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 1...
2025-12-12 18:24:57 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:24:57 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:25:12 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 192, 256]), Model num_frames: 1000
2025-12-12 18:25:12 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 1, Batch size: 4
2025-12-12 18:25:12 [ERROR] [lib.training.pipeline:1516] Error training fold 1: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    model = fit(
            ^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    train_loss = train_one_epoch(
                 ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 23.44 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.14 GiB is free. Including non-PyTorch memory, this process has 2.60 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 24.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:25:12 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 2/5 (20% sample)
2025-12-12 18:25:12 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 2 directory (clean mode)
2025-12-12 18:25:12 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:25:12 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:25:12 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 2...
2025-12-12 18:25:14 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:25:14 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:25:25 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:25:25 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 2, Batch size: 4
2025-12-12 18:25:25 [ERROR] [lib.training.pipeline:1516] Error training fold 2: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    # Handle warmup manually
                 ^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:25:25 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 3/5 (20% sample)
2025-12-12 18:25:25 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 3 directory (clean mode)
2025-12-12 18:25:25 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:25:25 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:25:25 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 3...
2025-12-12 18:25:27 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:25:27 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:25:45 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 144, 256]), Model num_frames: 1000
2025-12-12 18:25:45 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 3, Batch size: 4
2025-12-12 18:25:45 [ERROR] [lib.training.pipeline:1516] Error training fold 3: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    # Handle warmup manually
                 ^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 17.58 GiB. GPU 0 has a total capacity of 15.77 GiB of which 13.68 GiB is free. Including non-PyTorch memory, this process has 2.05 GiB memory in use. Of the allocated memory 1.66 GiB is allocated by PyTorch, and 26.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:25:45 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 4/5 (20% sample)
2025-12-12 18:25:45 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 4 directory (clean mode)
2025-12-12 18:25:45 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:25:45 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:25:45 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 4...
2025-12-12 18:25:47 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:25:47 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
2025-12-12 18:25:59 [ERROR] [lib.training._cnn:142] Runtime error in forward pass: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Input shape: torch.Size([4, 3, 1000, 256, 256]), Model num_frames: 1000
2025-12-12 18:25:59 [ERROR] [lib.training.pipeline:1137] CUDA OOM or runtime error during training: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables). Model: naive_cnn, Fold: 4, Batch size: 4
2025-12-12 18:25:59 [ERROR] [lib.training.pipeline:1516] Error training fold 4: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/pipeline.py", line 1114, in stage5_train_models
    sample_output = model(sample_clips)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 609, in fit
    # Handle warmup manually
                 ^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/trainer.py", line 330, in train_one_epoch
    logits = model(clips)
             ^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/lib/training/_cnn.py", line 108, in forward
    x = F.relu(self.bn1(self.conv1(x)))
                        ^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 548, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/fvc/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 543, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.25 GiB. GPU 0 has a total capacity of 15.77 GiB of which 12.39 GiB is free. Including non-PyTorch memory, this process has 3.34 GiB memory in use. Of the allocated memory 2.94 GiB is allocated by PyTorch, and 34.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-12 18:25:59 [INFO] [lib.training.pipeline:833] 
Hyperparameter Search - naive_cnn - Fold 5/5 (20% sample)
2025-12-12 18:25:59 [INFO] [lib.training.pipeline:842] Deleted existing hyperparameter search fold 5 directory (clean mode)
2025-12-12 18:25:59 [INFO] [lib.training.pipeline:912] Training configuration - Batch size: 4, Gradient accumulation steps: 16, Effective batch size: 64
2025-12-12 18:25:59 [WARNING] [lib.mlops.mlflow_tracker:176] Failed to create MLflow tracker: Run with UUID 57e1acdd53e948fb8170b6b089b1c17b is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2025-12-12 18:25:59 [INFO] [lib.training.pipeline:1022] Training PyTorch model naive_cnn on fold 5...
2025-12-12 18:26:01 [INFO] [lib.training.pipeline:1064] Model forward pass test successful. Output shape: torch.Size([1, 2])
2025-12-12 18:26:01 [INFO] [lib.training.trainer:260] Warmup will be handled in training loop (2 epochs)
